This is pcl.info, produced by makeinfo version 5.2 from pcl.texi.


File: pcl.info,  Node: 19-6,  Next: Chapter 20,  Prev: 19-5,  Up: Chapter 19

Other Uses for Conditions
=========================

While conditions are mainly used for error handling, they can be used
for other purposes-you can use conditions, condition handlers, and
restarts to build a variety of protocols between low- and high-level
code.  The key to understanding the potential of conditions is to
understand that merely signaling a condition has no effect on the flow
of control.

   The primitive signaling function SIGNAL implements the mechanism of
searching for an applicable condition handler and invoking its handler
function.  The reason a handler can decline to handle a condition by
returning normally is because the call to the handler function is just a
regular function call-when the handler returns, control passes back to
SIGNAL, which then looks for another, less recently bound handler that
can handle the condition.  If SIGNAL runs out of condition handlers
before the condition is handled, it also returns normally.

   The ERROR function you've been using calls SIGNAL. If the error is
handled by a condition handler that transfers control via HANDLER-CASE
or by invoking a restart, then the call to SIGNAL never returns.  But if
SIGNAL returns, ERROR invokes the debugger by calling the function
stored in *DEBUGGER-HOOK*.  Thus, a call to ERROR can never return
normally; the condition must be handled either by a condition handler or
in the debugger.

   Another condition signaling function, WARN, provides an example of a
different kind of protocol built on the condition system.  Like ERROR,
WARN calls SIGNAL to signal a condition.  But if SIGNAL returns, WARN
doesn't invoke the debugger-it prints the condition to *ERROR-OUTPUT*
and returns NIL, allowing its caller to proceed.  WARN also establishes
a restart, MUFFLE-WARNING, around the call to SIGNAL that can be used by
a condition handler to make WARN return without printing anything.  The
restart function MUFFLE-WARNING finds and invokes its eponymous restart,
signaling a CONTROL-ERROR if no such restart is available.  Of course, a
condition signaled with WARN could also be handled in some other way-a
condition handler could "promote" a warning to an error by handling it
as if it were an error.

   For instance, in the log-parsing application, if there were ways a
log entry could be slightly malformed but still parsable, you could
write parse-log-entry to go ahead and parse the slightly defective
entries but to signal a condition with WARN when it did.  Then the
larger application could choose to let the warning print, to muffle the
warning, or to treat the warning like an error, recovering the same way
it would from a malformed-log-entry-error.

   A third error-signaling function, CERROR, provides yet another
protocol.  Like ERROR, CERROR will drop you into the debugger if the
condition it signals isn't handled.  But like WARN, it establishes a
restart before it signals the condition.  The restart, CONTINUE, causes
CERROR to return normally-if the restart is invoked by a condition
handler, it will keep you out of the debugger altogether.  Otherwise,
you can use the restart once you're in the debugger to resume the
computation immediately after the call to CERROR. The function CONTINUE
finds and invokes the CONTINUE restart if it's available and returns NIL
otherwise.

   You can also build your own protocols on SIGNAL-whenever low-level
code needs to communicate information back up the call stack to
higher-level code, the condition mechanism is a reasonable mechanism to
use.  But for most purposes, one of the standard error or warning
protocols should suffice.

   You'll use the condition system in future practical chapters, both
for regular error handling and, in Chapter 25, to help in handling a
tricky corner case of parsing ID3 files.  Unfortunately, it's the fate
of error handling to always get short shrift in programming texts-proper
error handling, or lack thereof, is often the biggest difference between
illustrative code and hardened, production-quality code.  The trick to
writing the latter has more to do with adopting a particularly rigorous
way of thinking about software than with the details of any particular
programming language constructs.  That said, if your goal is to write
that kind of software, you'll find the Common Lisp condition system is
an excellent tool for writing robust code and one that fits quite nicely
into Common Lisp's incremental development style.

   In the next chapter I'll give a quick overview of some of the 25
special operators you haven't had a chance to use yet, at least not
directly.


File: pcl.info,  Node: Chapter 20,  Next: Chapter 21,  Prev: Chapter 19,  Up: Top

20. The Special Operators
=========================

In a way, the most impressive aspect of the condition system covered in
the previous chapter is that if it wasn't already part of the language,
it could be written entirely as a user-level library.  This is possible
because Common Lisp's special operators-while none touches directly on
signaling or handling conditions-provide enough access to the underlying
machinery of the language to be able to do things such as control the
unwinding of the stack.

   In previous chapters I've discussed the most frequently used special
operators, but it's worth being familiar with the others for two
reasons.  First, some of the infrequently used special operators are
used infrequently simply because whatever need they address doesn't
arise that often.  It's good to be familiar with these special operators
so when one of them is called for, you'll at least know it exists.
Second, because the 25 special operators-along with the basic rule for
evaluating function calls and the built-in data types-provide the
foundation for the rest of the language, a passing familiarity with them
will help you understand how the language works.

   In this chapter, I'll discuss all the special operators, some briefly
and some at length, so you can see how they fit together.  I'll point
out which ones you can expect to use directly in your own code, which
ones serve as the basis for other constructs that you use all the time,
and which ones you'll rarely use directly but which can be handy in
macro-generated code.

* Menu:

* 20-1::        Controlling Evaluation
* 20-2::        Manipulating the Lexical Environment
* 20-3::        Local Flow of Control
* 20-4::        Unwinding the Stack
* 20-5::        Multiple Values
* 20-6::        EVAL-WHEN
* 20-7::        Other Special Operators


File: pcl.info,  Node: 20-1,  Next: 20-2,  Prev: Chapter 20,  Up: Chapter 20

Controlling Evaluation
======================

The first category of special operators contains the three operators
that provide basic control over the evaluation of forms.  They're QUOTE,
IF, and PROGN, and I've discussed them all already.  However, it's worth
noting how each of these special operators provides one fundamental kind
of control over the evaluation of one or more forms.  QUOTE prevents
evaluation altogether and allows you to get at s-expressions as data.
IF provides the fundamental boolean choice operation from which all
other conditional execution constructs can be built.1 And PROGN provides
the ability to sequence a number of forms.


File: pcl.info,  Node: 20-2,  Next: 20-3,  Prev: 20-1,  Up: Chapter 20

Manipulating the Lexical Environment
====================================

The largest class of special operators contains the operators that
manipulate and access the lexical environment.  LET and LET*, which I've
already discussed, are examples of special operators that manipulate the
lexical environment since they can introduce new lexical bindings for
variables.  Any construct, such as a DO or DOTIMES, that binds lexical
variables will have to expand into a LET or LET*.2 The SETQ special
operator is one that accesses the lexical environment since it can be
used to set variables whose bindings were created by LET and LET*.

   Variables, however, aren't the only thing that can be named within a
lexical scope.  While most functions are defined globally with DEFUN,
it's also possible to create local functions with the special operators
FLET and LABELS, local macros with MACROLET, and a special kind of
macro, called a symbol macro, with SYMBOL-MACROLET.

   Much like LET allows you to introduce a lexical variable whose scope
is the body of the LET, FLET and LABELS let you define a function that
can be referred to only within the scope of the FLET or LABELS form.
These special operators are handy when you need a local function that's
a bit too complex to define inline as a LAMBDA expression or that you
need to use more than once.  Both have the same basic form, which looks
like this:

   (flet (function-definition*) body-form*) and like this:

   (labels (function-definition*) body-form*) where each
function-definition has the following form:

   (name (parameter*) form*) The difference between FLET and LABELS is
that the names of the functions defined with FLET can be used only in
the body of the FLET, while the names introduced by LABELS can be used
immediately, including in the bodies of the functions defined by the
LABELS. Thus, LABELS can define recursive functions, while FLET can't.
It might seem limiting that FLET can't be used to define recursive
functions, but Common Lisp provides both FLET and LABELS because
sometimes it's useful to be able to write local functions that can call
another function of the same name, either a globally defined function or
a local function from an enclosing scope.

   Within the body of a FLET or LABELS, you can use the names of the
functions defined just like any other function, including with the
FUNCTION special operator.  Since you can use FUNCTION to get the
function object representing a function defined with FLET or LABELS, and
since a FLET or LABELS can be in the scope of other binding forms such
as LETs, these functions can be closures.

   Because the local functions can refer to variables from the enclosing
scope, they can often be written to take fewer parameters than the
equivalent helper functions.  This is particularly handy when you need
to pass a function that takes a single argument as a functional
parameter.  For example, in the following function, which you'll see
again in Chapter 25, the FLETed function, count-version, takes a single
argument, as required by walk-directory, but can also use the variable
versions, introduced by the enclosing LET:

   (defun count-versions (dir) (let ((versions (mapcar #'(lambda (x)
(cons x 0)) '(2 3 4)))) (flet ((count-version (file) (incf (cdr (assoc
(major-version (read-id3 file)) versions))))) (walk-directory dir
#'count-version :test #'mp3-p)) versions)) This function could also be
written using an anonymous function in the place of the FLETed
count-version, but giving the function a meaningful name makes it a bit
easier to read.

   And when a helper function needs to recurse, an anonymous function
just won't do.3 When you don't want to define a recursive helper
function as a global function, you can use LABELS. For example, the
following function, collect-leaves, uses the recursive helper function
walk to walk a tree and gather all the atoms in the tree into a list,
which collect-leaves then returns (after reversing it):

   (defun collect-leaves (tree) (let ((leaves ())) (labels ((walk (tree)
(cond ((null tree)) ((atom tree) (push tree leaves)) (t (walk (car
tree)) (walk (cdr tree)))))) (walk tree)) (nreverse leaves))) Notice
again how, within the walk function, you can refer to the variable,
leaves, introduced by the enclosing LET.

   FLET and LABELS are also useful operations to use in macro
expansions-a macro can expand into code that contains a FLET or LABELS
to create functions that can be used within the body of the macro.  This
technique can be used either to introduce functions that the user of the
macro will call or simply as a way of organizing the code generated by
the macro.  This, for instance, is how a function such as
CALL-NEXT-METHOD, which can be used only within a method definition,
might be defined.

   A near relative to FLET and LABELS is the special operator MACROLET,
which you can use to define local macros.  Local macros work just like
global macros defined with DEFMACRO except without cluttering the global
namespace.  When a MACROLET form is evaluated, the body forms are
evaluated with the local macro definitions in effect and possibly
shadowing global function and macro definitions or local definitions
from enclosing forms.  Like FLET and LABELS, MACROLET can be used
directly, but it's also a handy target for macro-generated code-by
wrapping some user-supplied code in a MACROLET, a macro can provide
constructs that can be used only within that code or can shadow a
globally defined macro.  You'll see an example of this latter use of
MACROLET in Chapter 31.

   Finally, one last macro-defining special operator is SYMBOL-MACROLET,
which defines a special kind of macro called, appropriately enough, a
symbol macro.  Symbol macros are like regular macros except they can't
take arguments and are referred to with a plain symbol rather than a
list form.  In other words, after you've defined a symbol macro with a
particular name, any use of that symbol in a value position will be
expanded and the resulting form evaluated in its place.  This is how
macros such as WITH-SLOTS and WITH-ACCESSORS are able to define
"variables" that access the state of a particular object under the
covers.  For instance, the following WITH-SLOTS form:

   (with-slots (x y z) foo (list x y z))) might expand into this code
that uses SYMBOL-MACROLET:

   (let ((#:g149 foo)) (symbol-macrolet ((x (slot-value #:g149 'x)) (y
(slot-value #:g149 'y)) (z (slot-value #:g149 'z))) (list x y z))) When
the expression (list x y z) is evaluated, the symbols x, y, and z will
be replaced with their expansions, such as (slot-value #:g149 'x).4

   Symbol macros are most often local, defined with SYMBOL-MACROLET, but
Common Lisp also provides a macro DEFINE-SYMBOL-MACRO that defines a
global symbol macro.  A symbol macro defined with SYMBOL-MACROLET
shadows other symbol macros of the same name defined with
DEFINE-SYMBOL-MACRO or enclosing SYMBOL-MACROLET forms.


File: pcl.info,  Node: 20-3,  Next: 20-4,  Prev: 20-2,  Up: Chapter 20

Local Flow of Control
=====================

The next four special operators I'll discuss also create and use names
in the lexical environment but for the purposes of altering the flow of
control rather than defining new functions and macros.  I've mentioned
all four of these special operators in passing because they provide the
underlying mechanisms used by other language features.  They're BLOCK,
RETURN-FROM, TAGBODY, and GO. The first two, BLOCK and RETURN-FROM, are
used together to write code that returns immediately from a section of
code-I discussed RETURN-FROM in Chapter 5 as a way to return immediately
from a function, but it's more general than that.  The other two,
TAGBODY and GO, provide a quite low-level goto construct that's the
basis for all the higher-level looping constructs you've already seen.

   The basic skeleton of a BLOCK form is this:

   (block name form*) The name is a symbol, and the forms are Lisp
forms.  The forms are evaluated in order, and the value of the last form
is returned as the value of the BLOCK unless a RETURN-FROM is used to
return from the block early.  A RETURN-FROM form, as you saw in Chapter
5, consists of the name of the block to return from and, optionally, a
form that provides a value to return.  When a RETURN-FROM is evaluated,
it causes the named BLOCK to return immediately.  If RETURN-FROM is
called with a return value form, the BLOCK will return the resulting
value; otherwise, the BLOCK evaluates to NIL.

   A BLOCK name can be any symbol, which includes NIL. Many of the
standard control construct macros, such as DO, DOTIMES, and DOLIST,
generate an expansion consisting of a BLOCK named NIL. This allows you
to use the RETURN macro, which is a bit of syntactic sugar for
(return-from nil ...), to break out of such loops.  Thus, the following
loop will print at most ten random numbers, stopping as soon as it gets
a number greater than 50:

   (dotimes (i 10) (let ((answer (random 100))) (print answer) (if (>
answer 50) (return)))) Function-defining macros such as DEFUN, FLET, and
LABELS, on the other hand, wrap their bodies in a BLOCK with the same
name as the function.  That's why you can use RETURN-FROM to return from
a function.

   TAGBODY and GO have a similar relationship to each other as BLOCK and
RETURN-FROM: a TAGBODY form defines a context in which names are defined
that can be used by GO. The skeleton of a TAGBODY is as follows:

   (tagbody tag-or-compound-form*) where each tag-or-compound-form is
either a symbol, called a tag, or a nonempty list form.  The list forms
are evaluated in order and the tags ignored, except as I'll discuss in a
moment.  After the last form of the TAGBODY is evaluated, the TAGBODY
returns NIL. Anywhere within the lexical scope of the TAGBODY you can
use the GO special operator to jump immediately to any of the tags, and
evaluation will resume with the form following the tag.  For instance,
you can write a trivial infinite loop with TAGBODY and GO like this:

   (tagbody top (print 'hello) (go top)) Note that while the tag names
must appear at the top level of the TAGBODY, not nested within other
forms, the GO special operator can appear anywhere within the scope of
the TAGBODY. This means you could write a loop that loops a random
number of times like this:

   (tagbody top (print 'hello) (when (plusp (random 10)) (go top))) An
even sillier example of TAGBODY, which shows you can have multiple tags
in a single TAGBODY, looks like this:

   (tagbody a (print 'a) (if (zerop (random 2)) (go c)) b (print 'b) (if
(zerop (random 2)) (go a)) c (print 'c) (if (zerop (random 2)) (go b)))
This form will jump around randomly printing as, bs, and cs until
eventually the last RANDOM expression returns 1 and the control falls
off the end of the TAGBODY.

   TAGBODY is rarely used directly since it's almost always easier to
write iterative constructs in terms of the existing looping macros.
It's handy, however, for translating algorithms written in other
languages into Common Lisp, either automatically or manually.  An
example of an automatic translation tool is the FORTRAN-to-Common Lisp
translator, f2cl, that translates FORTRAN source code into Common Lisp
in order to make various FORTRAN libraries available to Common Lisp
programmers.  Since many FORTRAN libraries were written before the
structured programming revolution, they're full of gotos.  The f2cl
compiler can simply translate those gotos to GOs within appropriate
TAGBODYs.5

   Similarly, TAGBODY and GO can be handy when translating algorithms
described in prose or by flowcharts-for instance, in Donald Knuth's
classic series The Art of Computer Programming, he describes algorithms
using a "recipe" format: step 1, do this; step 2, do that; step 3, go
back to step 2; and so on.  For example, on page 142 of The Art of
Computer Programming, Volume 2: Seminumerical Algorithms, Third Edition
(Addison-Wesley, 1998), he describes Algorithm S, which you'll use in
Chapter 27, in this form:

   Algorithm S (Selection sampling technique).  To select n records at
random from a set of N, where 0 < n <= N. S1.  [Initialize.]  Set t <-
0, m <- 0.  (During this algorithm, m represents the number of records
selected so far, and t is the total number of input records that we have
dealt with.)  S2.  [Generate U.] Generate a random number U, uniformly
distributed between zero and one.  S3.  [Test.]  If (N - t)U >= n - m,
go to step S5.  S4.  [Select.]  Select the next record for the sample,
and increase m and t by 1.  If m < n, go to step S2; otherwise the
sample is complete and the algorithm terminates.  S5.  [Skip.]  Skip the
next record (do not include it in the sample), increase t by 1, and go
back to step S2.  This description can be easily translated into a
Common Lisp function, after renaming a few variables, as follows:

   (defun algorithm-s (n max) ; max is N in Knuth's algorithm (let (seen
; t in Knuth's algorithm selected ; m in Knuth's algorithm u ; U in
Knuth's algorithm (records ())) ; the list where we save the records
selected (tagbody s1 (setf seen 0) (setf selected 0) s2 (setf u (random
1.0)) s3 (when (>= (* (- max seen) u) (- n selected)) (go s5)) s4 (push
seen records) (incf selected) (incf seen) (if (< selected n) (go s2)
(return-from algorithm-s (nreverse records))) s5 (incf seen) (go s2))))
It's not the prettiest code, but it's easy to verify that it's a
faithful translation of Knuth's algorithm.  But, this code, unlike
Knuth's prose description, can be run and tested.  Then you can start
refactoring, checking after each change that the function still works.6

   After pushing the pieces around a bit, you might end up with
something like this:

   (defun algorithm-s (n max) (loop for seen from 0 when (< (* (- max
seen) (random 1.0)) n) collect seen and do (decf n) until (zerop n)))
While it may not be immediately obvious that this code correctly
implements Algorithm S, if you got here via a series of functions that
all behave identically to the original literal translation of Knuth's
recipe, you'd have good reason to believe it's correct.


File: pcl.info,  Node: 20-4,  Next: 20-5,  Prev: 20-3,  Up: Chapter 20

Unwinding the Stack
===================

Another aspect of the language that special operators give you control
over is the behavior of the call stack.  For instance, while you
normally use BLOCK and TAGBODY to manage the flow of control within a
single function, you can also use them, in conjunction with closures, to
force an immediate nonlocal return from a function further down on the
stack.  That's because BLOCK names and TAGBODY tags can be closed over
by any code within the lexical scope of the BLOCK or TAGBODY. For
example, consider this function:

   (defun foo () (format t "Entering foo~%") (block a (format t "
Entering BLOCK~%") (bar #'(lambda () (return-from a))) (format t "
Leaving BLOCK~%")) (format t "Leaving foo~%")) The anonymous function
passed to bar uses RETURN-FROM to return from the BLOCK. But that
RETURN-FROM doesn't get evaluated until the anonymous function is
invoked with FUNCALL or APPLY. Now suppose bar looks like this:

   (defun bar (fn) (format t " Entering bar~%") (baz fn) (format t "
Leaving bar~%")) Still, the anonymous function isn't invoked.  Now look
at baz.

   (defun baz (fn) (format t " Entering baz~%") (funcall fn) (format t "
Leaving baz~%")) Finally the function is invoked.  But what does it mean
to RETURN-FROM a block that's several layers up on the call stack?
Turns out it works fine-the stack is unwound back to the frame where the
BLOCK was established and control returns from the BLOCK. The FORMAT
expressions in foo, bar, and baz show this:

   CL-USER> (foo) Entering foo Entering BLOCK Entering bar Entering baz
Leaving foo NIL Note that the only "Leaving .  .  ."  message that
prints is the one that appears after the BLOCK in foo.

   Because the names of blocks are lexically scoped, a RETURN-FROM
always returns from the smallest enclosing BLOCK in the lexical
environment where the RETURN-FROM form appears even if the RETURN-FROM
is executed in a different dynamic context.  For instance, bar could
also contain a BLOCK named a, like this:

   (defun bar (fn) (format t " Entering bar~%") (block a (baz fn))
(format t " Leaving bar~%")) This extra BLOCK won't change the behavior
of foo at all-the name a is resolved lexically, at compile time, not
dynamically, so the intervening block has no effect on the RETURN-FROM.
Conversely, the name of a BLOCK can be used only by RETURN-FROMs
appearing within the lexical scope of the BLOCK; there's no way for code
outside the block to return from the block except by invoking a closure
that closes over a RETURN-FROM from the lexical scope of the BLOCK.

   TAGBODY and GO work the same way, in this regard, as BLOCK and
RETURN-FROM. When you invoke a closure that contains a GO form, if the
GO is evaluated, the stack will unwind back to the appropriate TAGBODY
and then jump to the specified tag.

   BLOCK names and TAGBODY tags, however, differ from lexical variable
bindings in one important way.  As I discussed in Chapter 6, lexical
bindings have indefinite extent, meaning the bindings can stick around
even after the binding form has returned.  BLOCKs and TAGBODYs, on the
other hand, have dynamic extent-you can RETURN-FROM a BLOCK or GO to a
TAGBODY tag only while the BLOCK or TAGBODY is on the call stack.  In
other words, a closure that captures a block name or TAGBODY tag can be
passed down the stack to be invoked later, but it can't be returned up
the stack.  If you invoke a closure that tries to RETURN-FROM a BLOCK,
after the BLOCK itself has returned, you'll get an error.  Likewise,
trying to GO to a TAGBODY that no longer exists will cause an error.7

   It's unlikely you'll need to use BLOCK and TAGBODY yourself for this
kind of stack unwinding.  But you'll likely be using them indirectly
whenever you use the condition system, so understanding how they work
should help you understand better what exactly, for instance, invoking a
restart is doing.8

   CATCH and THROW are another pair of special operators that can force
the stack to unwind.  You'll use these operators even less often than
the others mentioned so far-they're holdovers from earlier Lisp dialects
that didn't have Common Lisp's condition system.  They definitely
shouldn't be confused with try/catch and try/except constructs from
languages such as Java and Python.

   CATCH and THROW are the dynamic counterparts of BLOCK and
RETURN-FROM. That is, you wrap CATCH around a body of code and then use
THROW to cause the CATCH form to return immediately with a specified
value.  The difference is that the association between a CATCH and THROW
is established dynamically-instead of a lexically scoped name, the label
for a CATCH is an object, called a catch tag, and any THROW evaluated
within the dynamic extent of the CATCH that throws that object will
unwind the stack back to the CATCH form and cause it to return
immediately.  Thus, you can write a version of the foo, bar, and baz
functions from before using CATCH and THROW instead of BLOCK and
RETURN-FROM like this:

   (defparameter *obj* (cons nil nil)) ; i.e.  some arbitrary object

   (defun foo () (format t "Entering foo~%") (catch *obj* (format t "
Entering CATCH~%") (bar) (format t " Leaving CATCH~%")) (format t
"Leaving foo~%"))

   (defun bar () (format t " Entering bar~%") (baz) (format t " Leaving
bar~%"))

   (defun baz () (format t " Entering baz~%") (throw *obj* nil) (format
t " Leaving baz~%")) Notice how it isn't necessary to pass a closure
down the stack-baz can call THROW directly.  The result is quite similar
to the earlier version.

   CL-USER> (foo) Entering foo Entering CATCH Entering bar Entering baz
Leaving foo NIL However, CATCH and THROW are almost too dynamic.  In
both the CATCH and the THROW, the tag form is evaluated, which means
their values are both determined at runtime.  Thus, if some code in bar
reassigned or rebound *obj*, the THROW in baz wouldn't throw to the same
CATCH. This makes CATCH and THROW much harder to reason about than BLOCK
and RETURN-FROM. The only advantage, which the version of foo, bar, and
baz that use CATCH and THROW demonstrates, is there's no need to pass
down a closure in order for low-level code to return from a CATCH-any
code that runs within the dynamic extent of a CATCH can cause it to
return by throwing the right object.

   In older Lisp dialects that didn't have anything like Common Lisp's
condition system, CATCH and THROW were used for error handling.
However, to keep them manageable, the catch tags were usually just
quoted symbols, so you could tell by looking at a CATCH and a THROW
whether they would hook up at runtime.  In Common Lisp you'll rarely
have any call to use CATCH and THROW since the condition system is so
much more flexible.

   The last special operator related to controlling the stack is another
one I've mentioned in passing before-UNWIND-PROTECT. UNWIND-PROTECT lets
you control what happens as the stack unwinds-to make sure that certain
code always runs regardless of how control leaves the scope of the
UNWIND-PROTECT, whether by a normal return, by a restart being invoked,
or by any of the ways discussed in this section.9 The basic skeleton of
UNWIND-PROTECT looks like this:

   (unwind-protect protected-form cleanup-form*) The single
protected-form is evaluated, and then, regardless of how it returns, the
cleanup-forms are evaluated.  If the protected-form returns normally,
then whatever it returns is returned from the UNWIND-PROTECT after the
cleanup forms run.  The cleanup forms are evaluated in the same dynamic
environment as the UNWIND-PROTECT, so the same dynamic variable
bindings, restarts, and condition handlers will be visible to code in
cleanup forms as were visible just before the UNWIND-PROTECT.

   You'll occasionally use UNWIND-PROTECT directly.  More often you'll
use it as the basis for WITH- style macros, similar to WITH-OPEN-FILE,
that evaluate any number of body forms in a context where they have
access to some resource that needs to be cleaned up after they're done,
regardless of whether they return normally or bail via a restart or
other nonlocal exit.  For example, if you were writing a database
library that defined functions open-connection and close-connection, you
might write a macro like this:10

   (defmacro with-database-connection ((var &rest open-args) &body body)
'(let ((,var (open-connection ,@open-args))) (unwind-protect (progn
,@body) (close-connection ,var)))) which lets you write code like this:

   (with-database-connection (conn :host "foo" :user "scott" :password
"tiger") (do-stuff conn) (do-more-stuff conn)) and not have to worry
about closing the database connection, since the UNWIND-PROTECT will
make sure it gets closed no matter what happens in the body of the
with-database-connection form.


File: pcl.info,  Node: 20-5,  Next: 20-6,  Prev: 20-4,  Up: Chapter 20

Multiple Values
===============

Another feature of Common Lisp that I've mentioned in passing-in Chapter
11, when I discussed GETHASH-is the ability for a single form to return
multiple values.  I'll discuss it in greater detail now.  It is,
however, slightly misplaced in a chapter on special operators since the
ability to return multiple values isn't provided by just one or two
special operators but is deeply integrated into the language.  The
operators you'll most often use when dealing with multiple values are
macros and functions, not special operators.  But it is the case that
the basic ability to get at multiple return values is provided by a
special operator, MULTIPLE-VALUE-CALL, upon which the more commonly used
MULTIPLE-VALUE-BIND macro is built.

   The key thing to understand about multiple values is that returning
multiple values is quite different from returning a list-if a form
returns multiple values, unless you do something specific to capture the
multiple values, all but the primary value will be silently discarded.
To see the distinction, consider the function GETHASH, which returns two
values: the value found in the hash table and a boolean that's NIL when
no value was found.  If it returned those two values in a list, every
time you called GETHASH you'd have to take apart the list to get at the
actual value, regardless of whether you cared about the second return
value.  Suppose you have a hash table, *h*, that contains numeric
values.  If GETHASH returned a list, you couldn't write something like
this:

   (+ (gethash 'a *h*) (gethash 'b *h*)) because + expects its arguments
to be numbers, not lists.  But because the multiple value mechanism
silently discards the secondary return value when it's not wanted, this
form works fine.

   There are two aspects to using multiple values-returning multiple
values and getting at the nonprimary values returned by forms that
return multiple values.  The starting points for returning multiple
values are the functions VALUES and VALUES-LIST. These are regular
functions, not special operators, so their arguments are passed in the
normal way.  VALUES takes a variable number of arguments and returns
them as multiple values; VALUES-LIST takes a single list and returns its
elements as multiple values.  In other words:

   (values-list x) === (apply #'values x) The mechanism by which
multiple values are returned is implementation dependent just like the
mechanism for passing arguments into functions is.  Almost all language
constructs that return the value of some subform will "pass through"
multiple values, returning all the values returned by the subform.
Thus, a function that returns the result of calling VALUES or
VALUES-LIST will itself return multiple values-and so will another
function whose result comes from calling the first function.  And so
on.11

   But when a form is evaluated in a value position, only the primary
value will be used, which is why the previous addition form works the
way you'd expect.  The special operator MULTIPLE-VALUE-CALL provides the
mechanism for getting your hands on the multiple values returned by a
form.  MULTIPLE-VALUE-CALL is similar to FUNCALL except that while
FUNCALL is a regular function and, therefore, can see and pass on only
the primary values passed to it, MULTIPLE-VALUE-CALL passes, to the
function returned by its first subform, all the values returned by the
remaining subforms.

   (funcall #'+ (values 1 2) (values 3 4)) ==> 4 (multiple-value-call
#'+ (values 1 2) (values 3 4)) ==> 10 However, it's fairly rare that
you'll simply want to pass all the values returned by a function onto
another function.  More likely, you'll want to stash the multiple values
in different variables and then do something with them.  The
MULTIPLE-VALUE-BIND macro, which you saw in Chapter 11, is the most
frequently used operator for accepting multiple return values.  Its
skeleton looks like this:

   (multiple-value-bind (variable*) values-form body-form*) The
values-form is evaluated, and the multiple values it returns are bound
to the variables.  Then the body-forms are evaluated with those bindings
in effect.  Thus:

   (multiple-value-bind (x y) (values 1 2) (+ x y)) ==> 3 Another macro,
MULTIPLE-VALUE-LIST, is even simpler-it takes a single form, evaluates
it, and collects the resulting multiple values into a list.  In other
words, it's the inverse of VALUES-LIST.

   CL-USER> (multiple-value-list (values 1 2)) (1 2) CL-USER>
(values-list (multiple-value-list (values 1 2))) 1 2 However, if you
find yourself using MULTIPLE-VALUE-LIST a lot, it may be a sign that
some function should be returning a list to start with rather than
multiple values.

   Finally, if you want to assign multiple values returned by a form to
existing variables, you can use VALUES as a SETFable place.  For
example:

   CL-USER> (defparameter *x* nil) *X* CL-USER> (defparameter *y* nil)
*Y* CL-USER> (setf (values *x* *y*) (floor (/ 57 34))) 1 23/34 CL-USER>
*x* 1 CL-USER> *y* 23/34


File: pcl.info,  Node: 20-6,  Next: 20-7,  Prev: 20-5,  Up: Chapter 20

EVAL-WHEN
=========

A special operator you'll need to understand in order to write certain
kinds of macros is EVAL-WHEN. For some reason, Lisp books often treat
EVAL-WHEN as a wizards-only topic.  But the only prerequisite to
understanding EVAL-WHEN is an understanding of how the two functions
LOAD and COMPILE-FILE interact.  And understanding EVAL-WHEN will be
important as you start writing certain kinds of more sophisticated
macros, such as the ones you'll write in Chapters 24 and 31.

   I've touched briefly on the relation between LOAD and COMPILE-FILE in
previous chapters, but it's worth reviewing again here.  The job of LOAD
is to load a file and evaluate all the top-level forms it contains.  The
job of COMPILE-FILE is to compile a source file into a FASL file, which
can then be loaded with LOAD such that (load "foo.lisp") and (load
"foo.fasl") are essentially equivalent.

   Because LOAD evaluates each form before reading the next, the side
effects of evaluating forms earlier in the file can affect how forms
later in the form are read and evaluated.  For instance, evaluating an
IN-PACKAGE form changes the value of *PACKAGE*, which will affect the
way subsequent forms are read.12 Similarly, a DEFMACRO form early in a
file can define a macro that can then be used by code later in the
file.13

   COMPILE-FILE, on the other hand, normally doesn't evaluate the forms
it's compiling; it's when the FASL is loaded that the forms-or their
compiled equivalents-will be evaluated.  However, COMPILE-FILE must
evaluate some forms, such as IN-PACKAGE and DEFMACRO forms, in order to
keep the behavior of (load "foo.lisp") and (load "foo.fasl") consistent.

   So how do macros such as IN-PACKAGE and DEFMACRO work when processed
by COMPILE-FILE? In some pre-Common Lisp versions of Lisp, the file
compiler simply knew it should evaluate certain macros in addition to
compiling them.  Common Lisp avoided the need for such kludges by
borrowing the EVAL-WHEN special operator from Maclisp.  This operator,
as its name suggests, allows you to control when specific bits of code
are evaluated.  The skeleton of an EVAL-WHEN form looks like this:

   (eval-when (situation*) body-form*) There are three possible
situations-:compile-toplevel, :load-toplevel, and :execute-and which
ones you specify controls when the body-forms will be evaluated.  An
EVAL-WHEN with multiple situations is equivalent to several EVAL-WHEN
forms, one per situation, each with the same body code.  To explain the
meaning of the three situations, I'll need to explain a bit about how
COMPILE-FILE, which is also referred to as the file compiler, goes about
compiling a file.

   To explain how COMPILE-FILE compiles EVAL-WHEN forms, I need to
introduce a distinction between compiling top-level forms and compiling
non-top-level forms.  A top-level form is, roughly speaking, one that
will be compiled into code that will be run when the FASL is loaded.
Thus, all forms that appear directly at the top level of a source file
are compiled as top-level forms.  Similarly, any forms appearing
directly in a top-level PROGN are compiled as top-level forms since the
PROGN itself doesn't do anything-it just groups together its subforms,
which will be run when the FASL is loaded.14 Similarly, forms appearing
directly in a MACROLET or SYMBOL-MACROLET are compiled as top-level
forms because after the compiler has expanded the local macros or symbol
macros, there will be no remnant of the MACROLET or SYMBOL-MACROLET in
the compiled code.  Finally, the expansion of a top-level macro form
will be compiled as a top-level form.

   Thus, a DEFUN appearing at the top level of a source file is a
top-level form-the code that defines the function and associates it with
its name will run when the FASL is loaded-but the forms within the body
of the function, which won't run until the function is called, aren't
top-level forms.  Most forms are compiled the same when compiled as
top-level and non-top-level forms, but the semantics of an EVAL-WHEN
depend on whether it's being compiled as a top- level form, compiled as
a non-top-level form, or simply evaluated, combined with what situations
are listed in its situation list.

   The situations :compile-toplevel and :load-toplevel control the
meaning of an EVAL-WHEN compiled as a top-level form.  When
:compile-toplevel is present, the file compiler will evaluate the
subforms at compile time.  When :load-toplevel is present, it will
compile the subforms as top-level forms.  If neither of these situations
is present in a top-level EVAL-WHEN, the compiler ignores it.

   When an EVAL-WHEN is compiled as a non-top-level form, it's either
compiled like a PROGN, if the :execute situation is specified, or
ignored.  Similarly, an evaluated EVAL-WHEN-which includes top-level
EVAL-WHENs in a source file processed by LOAD and EVAL-WHENs evaluated
at compile time because they appear as subforms of a top-level EVAL-WHEN
with the :compile-toplevel situation-is treated like a PROGN if :execute
is present and ignored otherwise.

   Thus, a macro such as IN-PACKAGE can have the necessary effect at
both compile time and when loading from source by expanding into an
EVAL-WHEN like the following:

   (eval-when (:compile-toplevel :load-toplevel :execute) (setf
*package* (find-package "PACKAGE-NAME"))) *PACKAGE* will be set at
compile time because of the :compile-toplevel situation, set when the
FASL is loaded because of :load-toplevel, and set when the source is
loaded because of the :execute.

   There are two ways you're most likely to use EVAL-WHEN. One is if you
want to write macros that need to save some information at compile time
to be used when generating the expansion of other macro forms in the
same file.  This typically arises with definitional macros where a
definition early in a file can affect the code generated for a
definition later in the same file.  You'll write this kind of macro in
Chapter 24.

   The other time you might need EVAL-WHEN is if you want to put the
definition of a macro and helper functions it uses in the same file as
code that uses the macro.  DEFMACRO already includes an EVAL-WHEN in its
expansion so the macro definition is immediately available to be used
later in the file.  But DEFUN normally doesn't make function definitions
available at compile time.  But if you use a macro in the same file as
it's defined in, you need the macro and any functions it uses to be
defined.  If you wrap the DEFUNs of any helper functions used by the
macro in an EVAL-WHEN with :compile-toplevel, the definitions will be
available when the macro's expansion function runs.  You'll probably
want to include :load-toplevel and :execute as well since the macros
will also need the function definitions after the file is compiled and
loaded or if you load the source instead of compiling.


File: pcl.info,  Node: 20-7,  Next: Chapter 21,  Prev: 20-6,  Up: Chapter 20

Other Special Operators
=======================

The four remaining special operators, LOCALLY, THE, LOAD-TIME-VALUE, and
PROGV, all allow you to get at parts of the underlying language that
can't be accessed any other way.  LOCALLY and THE are part of Common
Lisp's declaration system, which is used to communicate things to the
compiler that don't affect the meaning of your code but that may help
the compiler generate better code-faster, clearer error messages, and so
on.15 I'll discuss declarations briefly in Chapter 32.

   The other two, LOAD-TIME-VALUE and PROGV, are infrequently used, and
explaining the reason why you might ever want to use them would take
longer than explaining what they do.  So I'll just tell you what they do
so you know they're there.  Someday you'll hit on one of those rare
times when they're just the thing, and then you'll be ready.

   LOAD-TIME-VALUE is used, as its name suggests, to create a value
that's determined at load time.  When the file compiler compiles code
that contains a LOAD-TIME-VALUE form, it arranges to evaluate the first
subform once, when the FASL is loaded, and for the code containing the
LOAD-TIME-VALUE form to refer to that value.  In other words, instead of
writing this:

   (defvar *loaded-at* (get-universal-time))

   (defun when-loaded () *loaded-at*) you can write the following:

   (defun when-loaded () (load-time-value (get-universal-time))) In code
not processed by COMPILE-FILE, LOAD-TIME-VALUE is evaluated once when
the code is compiled, which may be when you explicitly compile a
function with COMPILE or earlier because of implicit compilation
performed by the implementation in the course of evaluating the code.
In uncompiled code, LOAD-TIME-VALUE evaluates its form each time it's
evaluated.

   Finally, PROGV creates new dynamic bindings for variables whose names
are determined at runtime.  This is mostly useful for implementing
embedded interpreters for languages with dynamically scoped variables.
The basic skeleton is as follows:

   (progv symbols-list values-list body-form*) where symbols-list is a
form that evaluates to a list of symbols and values-list is a form that
evaluates to a list of values.  Each symbol is dynamically bound to the
corresponding value, and then the body-forms are evaluated.  The
difference between PROGV and LET is that because symbols-list is
evaluated at runtime, the names of the variables to bind can be
determined dynamically.  As I say, this isn't something you need to do
often.

   And that's it for special operators.  In the next chapter, I'll get
back to hard-nosed practical topics and show you how to use Common
Lisp's package system to take control of your namespaces so you can
write libraries and applications that can coexist without stomping on
each other's names.


File: pcl.info,  Node: Chapter 21,  Next: Chapter 22,  Prev: Chapter 20,  Up: Top

21. Programming in the Large: Packages and Symbols
==================================================

In Chapter 4 I discussed how the Lisp reader translates textual names
into objects to be passed to the evaluator, representing them with a
kind of object called a symbol.  It turns out that having a built-in
data type specifically for representing names is quite handy for a lot
of kinds of programming.1 That, however, isn't the topic of this
chapter.  In this chapter I'll discuss one of the more immediate and
practical aspects of dealing with names: how to avoid name conflicts
between independently developed pieces of code.

   Suppose, for instance, you're writing a program and decide to use a
third-party library.  You don't want to have to know the name of every
function, variable, class, or macro used in the internals of that
library in order to avoid conflicts between those names and the names
you use in your program.  You'd like for most of the names in the
library and the names in your program to be considered distinct even if
they happen to have the same textual representation.  At the same time,
you'd like certain names defined in the library to be readily
accessible-the names that make up its public API, which you'll want to
use in your program.

   In Common Lisp, this namespace problem boils down to a question of
controlling how the reader translates textual names into symbols: if you
want two occurrences of the same name to be considered the same by the
evaluator, you need to make sure the reader uses the same symbol to
represent each name.  Conversely, if you want two names to be considered
distinct, even if they happen to have the same textual name, you need
the reader to create different symbols to represent each name.

* Menu:

* 21-1::        How the Reader Uses Packages
* 21-2::        A Bit of Package and Symbol Vocabulary
* 21-3::        Three Standard Packages
* 21-4::        Defining Your Own Packages
* 21-5::        Packaging Reusable Libraries
* 21-6::        Importing Individual Names
* 21-7::        Packaging Mechanics
* 21-8::        Package Gotchas


File: pcl.info,  Node: 21-1,  Next: 21-2,  Prev: Chapter 21,  Up: Chapter 21

How the Reader Uses Packages
============================

In Chapter 4 I discussed briefly how the Lisp reader translates names
into symbols, but I glossed over most of the details-now it's time to
take a closer look at what actually happens.

   I'll start by describing the syntax of names understood by the reader
and how that syntax relates to packages.  For the moment you can think
of a package as a table that maps strings to symbols.  As you'll see in
the next section, the actual mapping is slightly more flexible than a
simple lookup table but not in ways that matter much to the reader.
Each package also has a name, which can be used to find the package
using the function FIND-PACKAGE.

   The two key functions that the reader uses to access the
name-to-symbol mappings in a package are FIND-SYMBOL and INTERN. Both
these functions take a string and, optionally, a package.  If not
supplied, the package argument defaults to the value of the global
variable *PACKAGE*, also called the current package.

   FIND-SYMBOL looks in the package for a symbol with the given string
for a name and returns it, or NIL if no symbol is found.  INTERN also
will return an existing symbol; otherwise it creates a new symbol with
the string as its name and adds it to the package.

   Most names you use are unqualified, names that contain no colons.
When the reader reads such a name, it translates it to a symbol by
converting any unescaped letters to uppercase and passing the resulting
string to INTERN. Thus, each time the reader reads the same name in the
same package, it'll get the same symbol object.  This is important
because the evaluator uses the object identity of symbols to determine
which function, variable, or other program element a given symbol refers
to.  Thus, the reason an expression such as (hello-world) results in
calling a particular hello-world function is because the reader returns
the same symbol when it reads the function call as it did when it read
the DEFUN form that defined the function.

   A name containing either a single colon or a double colon is a
package-qualified name.  When the reader reads a package-qualified name,
it splits the name on the colon(s) and uses the first part as the name
of a package and the second part as the name of the symbol.  The reader
looks up the appropriate package and uses it to translate the symbol
name to a symbol object.

   A name containing only a single colon must refer to an external
symbol-one the package exports for public use.  If the named package
doesn't contain a symbol with a given name, or if it does but it hasn't
been exported, the reader signals an error.  A double-colon name can
refer to any symbol from the named package, though it's usually a bad
idea-the set of exported symbols defines a package's public interface,
and if you don't respect the package author's decision about what names
to make public and which ones to keep private, you're asking for trouble
down the road.  On the other hand, sometimes a package author will
neglect to export a symbol that really ought to be public.  In that
case, a double-colon name lets you get work done without having to wait
for the next version of the package to be released.

   Two other bits of symbol syntax the reader understands are those for
keyword symbols and uninterned symbols.  Keyword symbols are written
with names starting with a colon.  Such symbols are interned in the
package named KEYWORD and automatically exported.  Additionally, when
the reader interns a symbol in the KEYWORD, it also defines a constant
variable with the symbol as both its name and value.  This is why you
can use keywords in argument lists without quoting them-when they appear
in a value position, they evaluate to themselves.  Thus:

   (eql ':foo :foo) ==> T The names of keyword symbols, like all
symbols, are converted to all uppercase by the reader before they're
interned.  The name doesn't include the leading colon.

   (symbol-name :foo) ==> "FOO" Uninterned symbols are written with a
leading #:.  These names (minus the #:) are converted to uppercase as
normal and then translated into symbols, but the symbols aren't interned
in any package; each time the reader reads a #: name, it creates a new
symbol.  Thus:

   (eql '#:foo '#:foo) ==> NIL You'll rarely, if ever, write this syntax
yourself, but will sometimes see it when you print an s-expression
containing symbols returned by the function GENSYM.

   (gensym) ==> #:G3128


File: pcl.info,  Node: 21-2,  Next: 21-3,  Prev: 21-1,  Up: Chapter 21

A Bit of Package and Symbol Vocabulary
======================================

As I mentioned previously, the mapping from names to symbols implemented
by a package is slightly more flexible than a simple lookup table.  At
its core, every package contains a name-to-symbol lookup table, but a
symbol can be made accessible via an unqualified name in a given package
in other ways.  To talk sensibly about these other mechanisms, you'll
need a little bit of vocabulary.

   To start with, all the symbols that can be found in a given package
using FIND-SYMBOL are said to be accessible in that package.  In other
words, the accessible symbols in a package are those that can be
referred to with unqualified names when the package is current.

   A symbol can be accessible in two ways.  The first is for the
package's name-to-symbol table to contain an entry for the symbol, in
which case the symbol is said to be present in the package.  When the
reader interns a new symbol in a package, it's added to the package's
name-to-symbol table.  The package in which a symbol is first interned
is called the symbol's home package.

   The other way a symbol can be accessible in a package is if the
package inherits it.  A package inherits symbols from other packages by
using the other packages.  Only external symbols in the used packages
are inherited.  A symbol is made external in a package by exporting it.
In addition to causing it to be inherited by using packages, exporting a
symbol also-as you saw in the previous section-makes it possible to
refer to the symbol using a single-colon qualified name.

   To keep the mappings from names to symbols deterministic, the package
system allows only one symbol to be accessible in a given package for
each name.  That is, a package can't have a present symbol and an
inherited symbol with the same name or inherit two different symbols,
from different packages, with the same name.  However, you can resolve
conflicts by making one of the accessible symbols a shadowing symbol,
which makes the other symbols of the same name inaccessible.  In
addition to its name-to-symbol table, each package maintains a list of
shadowing symbols.

   An existing symbol can be imported into another package by adding it
to the package's name-to-symbol table.  Thus, the same symbol can be
present in multiple packages.  Sometimes you'll import symbols simply
because you want them to be accessible in the importing package without
using their home package.  Other times you'll import a symbol because
only present symbols can be exported or be shadowing symbols.  For
instance, if a package needs to use two packages that have external
symbols of the same name, one of the symbols must be imported into the
using package in order to be added to its shadowing list and make the
other symbol inaccessible.

   Finally, a present symbol can be uninterned from a package, which
causes it to be removed from the name-to-symbol table and, if it's a
shadowing symbol, from the shadowing list.  You might unintern a symbol
from a package to resolve a conflict between the symbol and an external
symbol from a package you want to use.  A symbol that isn't present in
any package is called an uninterned symbol, can no longer be read by the
reader, and will be printed using the #:foo syntax.


File: pcl.info,  Node: 21-3,  Next: 21-4,  Prev: 21-2,  Up: Chapter 21

Three Standard Packages
=======================

In the next section I'll show you how to define your own packages,
including how to make one package use another and how to export, shadow,
and import symbols.  But first let's look at a few packages you've been
using already.  When you first start Lisp, the value of *PACKAGE* is
typically the COMMON-LISP-USER package, also known as CL-USER.2 CL-USER
uses the package COMMON-LISP, which exports all the names defined by the
language standard.  Thus, when you type an expression at the REPL, all
the names of standard functions, macros, variables, and so on, will be
translated to the symbols exported from COMMON-LISP, and all other names
will be interned in the COMMON-LISP-USER package.  For example, the name
*PACKAGE* is exported from COMMON-LISP-if you want to see the value of
*PACKAGE*, you can type this:

   CL-USER> *package* #<The COMMON-LISP-USER package> because
COMMON-LISP-USER uses COMMON-LISP. Or you can use a package-qualified
name.

   CL-USER> common-lisp:*package* #<The COMMON-LISP-USER package> You
can even use COMMON-LISP's nickname, CL.

   CL-USER> cl:*package* #<The COMMON-LISP-USER package> But *X* isn't a
symbol in COMMON-LISP, so you if type this:

   CL-USER> (defvar *x* 10) *X* the reader reads DEFVAR as the symbol
from the COMMON-LISP package and *X* as a symbol in COMMON-LISP-USER.

   The REPL can't start in the COMMON-LISP package because you're not
allowed to intern new symbols in it; COMMON-LISP-USER serves as a
"scratch" package where you can create your own names while still having
easy access to all the symbols in COMMON-LISP.3 Typically, all packages
you'll define will also use COMMON-LISP, so you don't have to write
things like this:

   (cl:defun (x) (cl:+ x 2)) The third standard package is the KEYWORD
package, the package the Lisp reader uses to intern names starting with
colon.  Thus, you can also refer to any keyword symbol with an explicit
package qualification of keyword like this:

   CL-USER> :a :A CL-USER> keyword:a :A CL-USER> (eql :a keyword:a) T


File: pcl.info,  Node: 21-4,  Next: 21-5,  Prev: 21-3,  Up: Chapter 21

Defining Your Own Packages
==========================

Working in COMMON-LISP-USER is fine for experiments at the REPL, but
once you start writing actual programs you'll want to define new
packages so different programs loaded into the same Lisp environment
don't stomp on each other's names.  And when you write libraries that
you intend to use in different contexts, you'll want to define separate
packages and then export the symbols that make up the libraries' public
APIs.

   However, before you start defining packages, it's important to
understand one thing about what packages do not do.  Packages don't
provide direct control over who can call what function or access what
variable.  They provide you with basic control over namespaces by
controlling how the reader translates textual names into symbol objects,
but it isn't until later, in the evaluator, that the symbol is
interpreted as the name of a function or variable or whatever else.
Thus, it doesn't make sense to talk about exporting a function or a
variable from a package.  You can export symbols to make certain names
easier to refer to, but the package system doesn't allow you to restrict
how those names are used.4

   With that in mind, you can start looking at how to define packages
and tie them together.  You define new packages with the macro
DEFPACKAGE, which allows you to not only create the package but to
specify what packages it uses, what symbols it exports, and what symbols
it imports from other packages and to resolve conflicts by creating
shadowing symbols.5

   I'll describe the various options in terms of how you might use
packages while writing a program that organizes e-mail messages into a
searchable database.  The program is purely hypothetical, as are the
libraries I'll refer to-the point is to look at how the packages used in
such a program might be structured.

   The first package you'd need is one to provide a namespace for the
application-you want to be able to name your functions, variables, and
so on, without having to worry about name collisions with unrelated
code.  So you'd define a new package with DEFPACKAGE.

   If the application is simple enough to be written with no libraries
beyond the facilities provided by the language itself, you could define
a simple package like this:

   (defpackage :com.gigamonkeys.email-db (:use :common-lisp)) This
defines a package, named COM.GIGAMONKEYS.EMAIL-DB, that inherits all the
symbols exported by the COMMON-LISP package.6

   You actually have several choices of how to represent the names of
packages and, as you'll see, the names of symbols in a DEFPACKAGE.
Packages and symbols are named with strings.  However, in a DEFPACKAGE
form, you can specify the names of packages and symbols with string
designators.  A string designator is either a string, which designates
itself; a symbol, which designates its name; or a character, which
designates a one-character string containing just the character.  Using
keyword symbols, as in the previous DEFPACKAGE, is a common style that
allows you to write the names in lowercase-the reader will convert the
names to uppercase for you.  You could also write the DEFPACKAGE with
strings, but then you have to write them in all uppercase, because the
true names of most symbols and packages are in fact uppercase because of
the case conversion performed by the reader.7

   (defpackage "COM.GIGAMONKEYS.EMAIL-DB" (:use "COMMON-LISP")) You
could also use nonkeyword symbols-the names in DEFPACKAGE aren't
evaluated-but then the very act of reading the DEFPACKAGE form would
cause those symbols to be interned in the current package, which at the
very least will pollute that namespace and may also cause problems later
if you try to use the package.8

   To read code in this package, you need to make it the current package
with the IN-PACKAGE macro:

   (in-package :com.gigamonkeys.email-db) If you type this expression at
the REPL, it will change the value of *PACKAGE*, affecting how the REPL
reads subsequent expressions, until you change it with another call to
IN-PACKAGE. Similarly, if you include an IN-PACKAGE in a file that's
loaded with LOAD or compiled with COMPILE-FILE, it will change the
package, affecting the way subsequent expressions in the file are read.9

   With the current package set to the COM.GIGAMONKEYS.EMAIL-DB package,
other than names inherited from the COMMON-LISP package, you can use any
name you want for whatever purpose you want.  Thus, you could define a
new hello-world function that could coexist with the hello-world
function previously defined in COMMON-LISP-USER. Here's the behavior of
the existing function:

   CL-USER> (hello-world) hello, world NIL Now you can switch to the new
package using IN-PACKAGE.10 Notice how the prompt changes-the exact form
is determined by the development environment, but in SLIME the default
prompt consists of an abbreviated version of the package name.

   CL-USER> (in-package :com.gigamonkeys.email-db) #<The
COM.GIGAMONKEYS.EMAIL-DB package> EMAIL-DB> You can define a new
hello-world in this package:

   EMAIL-DB> (defun hello-world () (format t "hello from EMAIL-DB
package~%")) HELLO-WORLD And test it, like this:

   EMAIL-DB> (hello-world) hello from EMAIL-DB package NIL Now switch
back to CL-USER.

   EMAIL-DB> (in-package :cl-user) #<The COMMON-LISP-USER package>
CL-USER> And the old function is undisturbed.

   CL-USER> (hello-world) hello, world NIL


File: pcl.info,  Node: 21-5,  Next: 21-6,  Prev: 21-4,  Up: Chapter 21

Packaging Reusable Libraries
============================

While working on the e-mail database, you might write several functions
related to storing and retrieving text that don't have anything in
particular to do with e-mail.  You might realize that those functions
could be useful in other programs and decide to repackage them as a
library.  You should define a new package, but this time you'll export
certain names to make them available to other packages.

   (defpackage :com.gigamonkeys.text-db (:use :common-lisp) (:export
:open-db :save :store)) Again, you use the COMMON-LISP package, because
you'll need access to standard functions within COM.GIGAMONKEYS.TEXT-DB.
The :export clause specifies names that will be external in
COM.GIGAMONKEYS.TEXT-DB and thus accessible in packages that :use it.
Therefore, after you've defined this package, you can change the
definition of the main application package to the following:

   (defpackage :com.gigamonkeys.email-db (:use :common-lisp
:com.gigamonkeys.text-db)) Now code written in COM.GIGAMONKEYS.EMAIL-DB
can use unqualified names to refer to the exported symbols from both
COMMON-LISP and COM.GIGAMONKEYS.TEXT-DB. All other names will continue
to be interned directly in the COM.GIGAMONKEYS.EMAIL-DB package.


File: pcl.info,  Node: 21-6,  Next: 21-7,  Prev: 21-5,  Up: Chapter 21

Importing Individual Names
==========================

Now suppose you find a third-party library of functions for manipulating
e-mail messages.  The names used in the library's API are exported from
the package COM.ACME.EMAIL, so you could :use that package to get easy
access to those names.  But suppose you need to use only one function
from this library, and other exported symbols conflict with names you
already use (or plan to use) in our own code.11 In this case, you can
import the one symbol you need with an :import-from clause in the
DEFPACKAGE. For instance, if the name of the function you want to use is
parse-email-address, you can change the DEFPACKAGE to this:

   (defpackage :com.gigamonkeys.email-db (:use :common-lisp
:com.gigamonkeys.text-db) (:import-from :com.acme.email
:parse-email-address)) Now anywhere the name parse-email-address appears
in code read in the COM.GIGAMONKEYS.EMAIL-DB package, it will be read as
the symbol from COM.ACME.EMAIL. If you need to import more than one
symbol from a single package, you can include multiple names after the
package name in a single :import-from clause.  A DEFPACKAGE can also
include multiple :import-from clauses in order to import symbols from
different packages.

   Occasionally you'll run into the opposite situation-a package may
export a bunch of names you want to use and a few you don't.  Rather
than listing all the symbols you do want to use in an :import-from
clause, you can instead :use the package and then list the names you
don't want to inherit in a :shadow clause.  For instance, suppose the
COM.ACME.TEXT package exports a bunch of names of functions and classes
used in text processing.  Further suppose that most of these functions
and classes are ones you'll want to use in your code, but one of the
names, build-index, conflicts with a name you've already used.  You can
make the build-index from COM.ACME.TEXT inaccessible by shadowing it.

   (defpackage :com.gigamonkeys.email-db (:use :common-lisp
:com.gigamonkeys.text-db :com.acme.text) (:import-from :com.acme.email
:parse-email-address) (:shadow :build-index)) The :shadow clause causes
a new symbol named BUILD-INDEX to be created and added directly to
COM.GIGAMONKEYS.EMAIL-DB's name-to-symbol map.  Now if the reader reads
the name BUILD-INDEX, it will translate it to the symbol in
COM.GIGAMONKEYS.EMAIL-DB's map, rather than the one that would otherwise
be inherited from COM.ACME.TEXT. The new symbol is also added to a
shadowing symbols list that's part of the COM.GIGAMONKEYS.EMAIL-DB
package, so if you later use another package that also exports a
BUILD-INDEX symbol, the package system will know there's no
conflict-that you want the symbol from COM.GIGAMONKEYS.EMAIL-DB to be
used rather than any other symbols with the same name inherited from
other packages.

   A similar situation can arise if you want to use two packages that
export the same name.  In this case the reader won't know which
inherited name to use when it reads the textual name.  In such
situations you must resolve the ambiguity by shadowing the conflicting
names.  If you don't need to use the name from either package, you could
shadow the name with a :shadow clause, creating a new symbol with the
same name in your package.  But if you actually want to use one of the
inherited symbols, then you need to resolve the ambiguity with a
:shadowing-import-from clause.  Like an :import-from clause, a
:shadowing-import-from clause consists of a package name followed by the
names to import from that package.  For instance, if COM.ACME.TEXT
exports a name SAVE that conflicts with the name exported from
COM.GIGAMONKEYS.TEXT-DB, you could resolve the ambiguity with the
following DEFPACKAGE:

   (defpackage :com.gigamonkeys.email-db (:use :common-lisp
:com.gigamonkeys.text-db :com.acme.text) (:import-from :com.acme.email
:parse-email-address) (:shadow :build-index) (:shadowing-import-from
:com.gigamonkeys.text-db :save))


File: pcl.info,  Node: 21-7,  Next: 21-8,  Prev: 21-6,  Up: Chapter 21

Packaging Mechanics
===================

That covers the basics of how to use packages to manage namespaces in
several common situations.  However, another level of how to use
packages is worth discussing-the raw mechanics of how to organize code
that uses different packages.  In this section I'll discuss a few rules
of thumb about how to organize code-where to put your DEFPACKAGE forms
relative to the code that uses your packages via IN-PACKAGE.

   Because packages are used by the reader, a package must be defined
before you can LOAD or COMPILE-FILE a file that contains an IN-PACKAGE
expression switching to that package.  Packages also must be defined
before other DEFPACKAGE forms can refer to them.  For instance, if
you're going to :use COM.GIGAMONKEYS.TEXT-DB in
COM.GIGAMONKEYS.EMAIL-DB, then COM.GIGAMONKEYS.TEXT-DB's DEFPACKAGE must
be evaluated before the DEFPACKAGE of COM.GIGAMONKEYS.EMAIL-DB.

   The best first step toward making sure packages exist when they need
to is to put all your DEFPACKAGEs in files separate from the code that
needs to be read in those packages.  Some folks like to create a
foo-package.lisp file for each individual package, and others create a
single packages.lisp that contains all the DEFPACKAGE forms for a group
of related packages.  Either approach is reasonable, though the
one-file-per-package approach also requires that you arrange to load the
individual files in the right order according to the interpackage
dependencies.

   Either way, once all the DEFPACKAGE forms have been separated from
the code that will be read in the packages they define, you can arrange
to LOAD the files containing the DEFPACKAGEs before you compile or load
any of the other files.  For simple programs you can do this by hand:
simply LOAD the file or files containing the DEFPACKAGE forms, possibly
compiling them with COMPILE-FILE first.  Then LOAD the files that use
those packages, again optionally compiling them first with COMPILE-FILE.
Note, however, that the packages don't exist until you LOAD the package
definitions, either the source or the files produced by COMPILE-FILE.
Thus, if you're compiling everything, you must still LOAD all the
package definitions before you can COMPILE-FILE any files to be read in
the packages.

   Doing these steps by hand will get tedious after a while.  For simple
programs you can automate the steps by writing a file, load.lisp, that
contains the appropriate LOAD and COMPILE-FILE calls in the right order.
Then you can just LOAD that file.  For more complex programs you'll want
to use a system definition facility to manage loading and compiling
files in the right order.12

   The other key rule of thumb is that each file should contain exactly
one IN-PACKAGE form, and it should be the first form in the file other
than comments.  Files containing DEFPACKAGE forms should start with
(in-package "COMMON-LISP-USER"), and all other files should contain an
IN-PACKAGE of one of your packages.

   If you violate this rule and switch packages in the middle of a file,
you'll confuse human readers who don't notice the second IN-PACKAGE.
Also, many Lisp development environments, particularly Emacs-based ones
such as SLIME, look for an IN-PACKAGE to determine the package they
should use when communicating with Common Lisp.  Multiple IN-PACKAGE
forms per file may confuse these tools as well.

   On the other hand, it's fine to have multiple files read in the same
package, each with an identical IN-PACKAGE form.  It's just a matter of
how you like to organize your code.

   The other bit of packaging mechanics has to do with how to name
packages.  Package names live in a flat namespace-package names are just
strings, and different packages must have textually distinct names.
Thus, you have to consider the possibility of conflicts between package
names.  If you're using only packages you developed yourself, then you
can probably get away with using short names for your packages.  But if
you're planning to use third-party libraries or to publish your code for
use by other programmers, then you need to follow a naming convention
that will minimize the possibility of name collisions between different
packages.  Many Lispers these days are adopting Java-style names, like
the ones used in this chapter, consisting of a reversed Internet domain
name followed by a dot and a descriptive string.


File: pcl.info,  Node: 21-8,  Next: Chapter 22,  Prev: 21-7,  Up: Chapter 21

Package Gotchas
===============

Once you're familiar with packages, you won't spend a bunch of time
thinking about them.  There's just not that much to them.  However, a
couple of gotchas that bite most new Lisp programmers make the package
system seem more complicated and unfriendly than it really is.

   The number-one gotcha arises most commonly when playing around at the
REPL. You'll be looking at some library that defines certain interesting
functions.  You'll try to call one of the functions like this:

   CL-USER> (foo) and get dropped into the debugger with this error:

   attempt to call 'FOO' which is an undefined function.  [Condition of
type UNDEFINED-FUNCTION]

   Restarts: 0: [TRY-AGAIN] Try calling FOO again.  1: [RETURN-VALUE]
Return a value instead of calling FOO. 2: [USE-VALUE] Try calling a
function other than FOO. 3: [STORE-VALUE] Setf the symbol-function of
FOO and call it again.  4: [ABORT] Abort handling SLIME request.  5:
[ABORT] Abort entirely from this (lisp) process.  Ah, of course-you
forgot to use the library's package.  So you quit the debugger and try
to USE-PACKAGE the library's package in order to get access to the name
FOO so you can call the function.

   CL-USER> (use-package :foolib) But that drops you back into the
debugger with this error message:

   Using package 'FOOLIB' results in name conflicts for these symbols:
FOO [Condition of type PACKAGE-ERROR]

   Restarts: 0: [CONTINUE] Unintern the conflicting symbols from the
'COMMON-LISP-USER' package.  1: [ABORT] Abort handling SLIME request.
2: [ABORT] Abort entirely from this (lisp) process.  Huh?  The problem
is the first time you called foo, the reader read the name foo and
interned it in CL-USER before the evaluator got hold of it and
discovered that this newly interned symbol isn't the name of a function.
This new symbol then conflicts with the symbol of the same name exported
from the FOOLIB package.  If you had remembered to USE-PACKAGE FOOLIB
before you tried to call foo, the reader would have read foo as the
inherited symbol and not interned a foo symbol in CL-USER.

   However, all isn't lost, because the first restart offered by the
debugger will patch things up in just the right way: it will unintern
the foo symbol from COMMON-LISP-USER, putting the CL-USER package back
to the state it was in before you called foo, allowing the USE-PACKAGE
to proceed and allowing for the inherited foo to be available in
CL-USER.

   This kind of problem can also occur when loading and compiling files.
For instance, if you defined a package, MY-APP, for code that was going
to use functions with names from the FOOLIB package, but forgot to :use
FOOLIB, when you compile the files with an (in-package :my-app) in them,
the reader will intern new symbols in MY-APP for the names that were
supposed to be read as symbols from FOOLIB. When you try to run the
compiled code, you'll get undefined function errors.  If you then try to
redefine the MY-APP package to :use FOOLIB, you'll get the conflicting
symbols error.  The solution is the same: select the restart to unintern
the conflicting symbols from MY-APP. You'll then need to recompile the
code in the MY-APP package so it will refer to the inherited names.

   The next gotcha is essentially the reverse of the first gotcha.  In
this case, you'd have defined a package-again, let's say it's
MY-APP-that uses another package, say, FOOLIB. Now you start writing
code in the MY-APP package.  Although you used FOOLIB in order to be
able to refer to the foo function, FOOLIB may export other symbols as
well.  If you use one of those exported symbols-say, bar-as the name of
a function in your own code, Lisp won't complain.  Instead, the name of
your function will be the symbol exported by FOOLIB, which will clobber
the definition of bar from FOOLIB.

   This gotcha is more insidious because it doesn't cause an error-from
the evaluator's point of view it's just being asked to associate a new
function with an old name, something that's perfectly legal.  It's
suspect only because the code doing the redefining was read with a
different value for *PACKAGE* than the name's package.  But the
evaluator doesn't necessarily know that.  However, in most Lisps you'll
get an warning about "redefining BAR, originally defined in?".  You
should heed those warnings.  If you clobber a definition from a library,
you can restore it by reloading the library code with LOAD.13

   The last package-related gotcha is, by comparison, quite trivial, but
it bites most Lisp programmers at least a few times: you define a
package that uses COMMON-LISP and maybe a few libraries.  Then at the
REPL you change to that package to play around.  Then you decide to quit
Lisp altogether and try to call (quit).  However, quit isn't a name from
the COMMON-LISP package-it's defined by the implementation in some
implementation-specific package that happens to be used by
COMMON-LISP-USER. The solution is simple-change packages back to CL-USER
to quit.  Or use the SLIME REPL shortcut quit, which will also save you
from having to remember that in certain Common Lisp implementations the
function to quit is exit, not quit.

   You're almost done with your tour of Common Lisp.  In the next
chapter I'll discuss the details of the extended LOOP macro.  After
that, the rest of the book is devoted to "practicals": a spam filter, a
library for parsing binary files, and various parts of a streaming MP3
server with a Web interface.


File: pcl.info,  Node: Chapter 22,  Next: Chapter 23,  Prev: Chapter 21,  Up: Top

22. LOOP for Black Belts
========================

In Chapter 7 I briefly discussed the extended LOOP macro.  As I
mentioned then, LOOP provides what is essentially a special-purpose
language just for writing iteration constructs.

   This might seem like a lot of bother-inventing a whole language just
for writing loops.  But if you think about the ways loops are used in
programs, it actually makes a fair bit of sense.  Any program of any
size at all will contain quite a number of loops.  And while they won't
all be the same, they won't all be unique either; patterns will emerge,
particularly if you include the code immediately preceding and following
the loops-patterns of how things are set up for the loop, patterns in
what gets done in the loop proper, and patterns in what gets done after
the loop.  The LOOP language captures these patterns so you can express
them directly.

   The LOOP macro has a lot of parts-one of the main complaints of
LOOP's detractors is that it's too complex.  In this chapter, I'll
tackle LOOP head on, giving you a systematic tour of the various parts
and how they fit together.

* Menu:

* 22-1::     The Parts of a LOOP
* 22-2::     Iteration Control
* 22-3::     Counting Loops
* 22-4::     Looping Over Collections and Packages
* 22-5::     Equals-Then Iteration
* 22-6::     Local Variables
* 22-7::     Destructuring Variables
* 22-8::     Value Accumulation
* 22-9::     Unconditional Execution
* 22-10::    Conditional Execution
* 22-11::    Setting Up and Tearing Down
* 22-12::    Termination Tests
* 22-13::    Putting It All Together


File: pcl.info,  Node: 22-1,  Next: 22-2,  Prev: Chapter 22,  Up: Chapter 22

The Parts of a LOOP
===================

You can do the following in a LOOP:

   Step variables numerically and over various data structures Collect,
count, sum, minimize, and maximize values seen while looping Execute
arbitrary Lisp expressions Decide when to terminate the loop
Conditionally do any of these Additionally, LOOP provides syntax for the
following:

   Creating local variables for use within the loop Specifying arbitrary
Lisp expressions to run before and after the loop proper The basic
structure of a LOOP is a set of clauses, each of which begins with a
loop keyword.1 How each clause is parsed by the LOOP macro depends on
the keyword.  Some of the main keywords, which you saw in Chapter 7, are
for, collecting, summing, counting, do, and finally.


File: pcl.info,  Node: 22-2,  Next: 22-3,  Prev: 22-1,  Up: Chapter 22

Iteration Control
=================

Most of the so-called iteration control clauses start with the loop
keyword for, or its synonym as,2 followed by the name of a variable.
What follows after the variable name depends on the type of for clause.

   The subclauses of a for clause can iterate over the following:

   Ranges of numbers, up or down, by specified intervals The individual
items of a list The cons cells that make up a list The elements of a
vector, including subtypes such as strings and bit vectors The pairs of
a hash table The symbols in a package The results of repeatedly
evaluating a given form A single loop can have multiple for clauses with
each clause naming its own variable.  When a loop has multiple for
clauses, the loop terminates as soon as any for clause reaches its end
condition.  For instance, the following loop:

   (loop for item in list for i from 1 to 10 do (something)) will
iterate at most ten times but may stop sooner if list contains fewer
than ten items.


File: pcl.info,  Node: 22-3,  Next: 22-4,  Prev: 22-2,  Up: Chapter 22

Counting Loops
==============

Arithmetic iteration clauses control the number of times the loop body
will be executed by stepping a variable over a range of numbers,
executing the body once per step.  These clauses consist of from one to
three of the following prepositional phrases after the for (or as): the
from where phrase, the to where phrase, and the by how much phrase.

   The from where phrase specifies the initial value of the clause's
variable.  It consists of one of the prepositions from, downfrom, or
upfrom followed by a form, which supplies the initial value (a number).

   The to where phrase specifies a stopping point for the loop and
consists of one of the prepositions to, upto, below, downto, or above
followed by a form, which supplies the stopping point.  With upto and
downto, the loop body will be terminated (without executing the body
again) when the variable passes the stopping point; with below and
above, it stops one iteration earlier.The by how much phrase consists of
the prepositions by and a form, which must evaluate to a positive
number.  The variable will be stepped (up or down, as determined by the
other phrases) by this amount on each iteration or by one if it's
omitted.

   You must specify at least one of these prepositional phrases.  The
defaults are to start at zero, increment the variable by one at each
iteration, and go forever or, more likely, until some other clause
terminates the loop.  You can modify any or all of these defaults by
adding the appropriate prepositional phrases.  The only wrinkle is that
if you want decremental stepping, there's no default from where value,
so you must specify one with either from or downfrom.  So, the
following:

   (loop for i upto 10 collect i) collects the first eleven integers
(zero to ten), but the behavior of this:

   (loop for i downto -10 collect i) ; wrong is undefined.  Instead, you
need to write this:

   (loop for i from 0 downto -10 collect i) Also note that because LOOP
is a macro, which runs at compile time, it has to be able to determine
the direction to step the variable based solely on the prepositions-not
the values of the forms, which may not be known until runtime.  So, the
following:

   (loop for i from 10 to 20 ...)  works fine since the default is
incremental stepping.  But this:

   (loop for i from 20 to 10 ...)  won't know to count down from twenty
to ten.  Worse yet, it won't give you an error-it will just not execute
the loop since i is already greater than ten.  Instead, you must write
this:

   (loop for i from 20 downto 10 ...)  or this:

   (loop for i downfrom 20 to 10 ...)  Finally, if you just want a loop
that repeats a certain number of times, you can replace a clause of the
following form:

   for i from 1 to number-form with a repeat clause like this:

   repeat number-form These clauses are identical in effect except the
repeat clause doesn't create an explicit loop variable.


File: pcl.info,  Node: 22-4,  Next: 22-5,  Prev: 22-3,  Up: Chapter 22

Looping Over Collections and Packages
=====================================

The for clauses for iterating over lists are much simpler than the
arithmetic clauses.  They support only two prepositional phrases, in and
on.

   A phrase of this form:

   for var in list-form steps var over all the elements of the list
produced by evaluating list-form.

   (loop for i in (list 10 20 30 40) collect i) ==> (10 20 30 40)
Occasionally this clause is supplemented with a by phrase, which
specifies a function to use to move down the list.  The default is CDR
but can be any function that takes a list and returns a sublist.  For
instance, you could collect every other element of a list with a loop
like this:

   (loop for i in (list 10 20 30 40) by #'cddr collect i) ==> (10 30) An
on prepositional phrase is used to step var over the cons cells that
make up a list.

   (loop for x on (list 10 20 30) collect x) ==> ((10 20 30) (20 30)
(30)) This phrase too can take a by preposition:

   (loop for x on (list 10 20 30 40) by #'cddr collect x) ==> ((10 20 30
40) (30 40)) Looping over the elements of a vector (which includes
strings and bit vectors) is similar to looping over the elements of a
list except the preposition across is used instead of in.3 For instance:

   (loop for x across "abcd" collect x) ==> (#\a #\b #\c #\d) Iterating
over a hash table or package is slightly more complicated because hash
tables and packages have different sets of values you might want to
iterate over-the keys or values in a hash table and the different kinds
of symbols in a package.  Both kinds of iteration follow the same
pattern.  The basic pattern looks like this:

   (loop for var being the things in hash-or-package ...)  For hash
tables, the possible values for things are hash-keys and hash-values,
which cause var to be bound to successive values of either the keys or
the values of the hash table.  The hash-or-package form is evaluated
once to produce a value, which must be a hash table.

   To iterate over a package, things can be symbols, present-symbols,
and external-symbols, which cause var to be bound to each of the symbols
accessible in a package, each of the symbols present in a package (in
other words, interned or imported into that package), or each of the
symbols that have been exported from the package.  The hash-or-package
form is evaluated to produce the name of a package, which is looked up
as if by FIND-PACKAGE or a package object.  Synonyms are also available
for parts of the for clause.  In place of the, you can use each; you can
use of instead of in; and you can write the things in the singular (for
example, hash-key or symbol).

   Finally, since you'll often want both the keys and the values when
iterating over a hash table, the hash table clauses support a using
subclause at the end of the hash table clause.

   (loop for k being the hash-keys in h using (hash-value v) ...)  (loop
for v being the hash-values in h using (hash-key k) ...)  Both of these
loops will bind k to each key in the hash table and v to the
corresponding value.  Note that the first element of the using subclause
must be in the singular form.4


File: pcl.info,  Node: 22-5,  Next: 22-6,  Prev: 22-4,  Up: Chapter 22

Equals-Then Iteration
=====================

If none of the other for clauses supports exactly the form of variable
stepping you need, you can take complete control over stepping with an
equals-then clause.  This clause is similar to the binding clauses in a
DO loop but cast in a more Algolish syntax.  The template is as follows:

   (loop for var = initial-value-form [ then step-form ] ...)  As usual,
var is the name of the variable to be stepped.  Its initial value is
obtained by evaluating initial-value-form once before the first
iteration.  In each subsequent iteration, step-form is evaluated, and
its value becomes the new value of var.  With no then part to the
clause, the initial-value-form is reevaluated on each iteration to
provide the new value.  Note that this is different from a DO binding
clause with no step form.

   The step-form can refer to other loop variables, including variables
created by other for clauses later in the loop.  For instance:

   (loop repeat 5 for x = 0 then y for y = 1 then (+ x y) collect y) ==>
(1 2 4 8 16) However, note that each for clause is evaluated separately
in the order it appears.  So in the previous loop, on the second
iteration x is set to the value of y before y changes (in other words,
1).  But y is then set to the sum of its old value (still 1) and the new
value of x.  If the order of the for clauses is reversed, the results
change.

   (loop repeat 5 for y = 1 then (+ x y) for x = 0 then y collect y) ==>
(1 1 2 4 8) Often, however, you'll want the step forms for multiple
variables to be evaluated before any of the variables is given its new
value (similar to how DO steps its variables).  In that case, you can
join multiple for clauses by replacing all but the first for with and.
You saw this formulation already in the LOOP version of the Fibonacci
computation in Chapter 7.  Here's another variant, based on the two
previous examples:

   (loop repeat 5 for x = 0 then y and y = 1 then (+ x y) collect y) ==>
(1 1 2 3 5)


File: pcl.info,  Node: 22-6,  Next: 22-7,  Prev: 22-5,  Up: Chapter 22

Local Variables
===============

While the main variables needed within a loop are usually declared
implicitly in for clauses, sometimes you'll need auxiliary variables,
which you can declare with with clauses.

   with var [ = value-form ] The name var becomes the name of a local
variable that will cease to exist when the loop finishes.  If the with
clause contains an = value-form part, the variable will be initialized,
before the first iteration of the loop, to the value of value-form.

   Multiple with clauses can appear in a loop; each clause is evaluated
independently in the order it appears and the value is assigned before
proceeding to the next clause, allowing later variables to depend on the
value of already declared variables.  Mutually independent variables can
be declared in one with clause with an and between each declaration.


File: pcl.info,  Node: 22-7,  Next: 22-8,  Prev: 22-6,  Up: Chapter 22

Destructuring Variables
=======================

One handy feature of LOOP I haven't mentioned yet is the ability to
destructure list values assigned to loop variables.  This lets you take
apart the value of lists that would otherwise be assigned to a loop
variable, similar to the way DESTRUCTURING-BIND works but a bit less
elaborate.  Basically, you can replace any loop variable in a for or
with clause with a tree of symbols, and the list value that would have
been assigned to the simple variable will instead be destructured into
variables named by the symbols in the tree.  A simple example looks like
this:

   CL-USER> (loop for (a b) in '((1 2) (3 4) (5 6)) do (format t "a: ~a;
b: ~a~%" a b)) a: 1; b: 2 a: 3; b: 4 a: 5; b: 6 NIL The tree can also
include dotted lists, in which case the name after the dot acts like a
&rest parameter, being bound to a list containing any remaining elements
of the list.  This is particularly handy with for/on loops since the
value is always a list.  For instance, this LOOP (which I used in
Chapter 18 to emit a comma-delimited list):

   (loop for cons on list do (format t "~a" (car cons)) when (cdr cons)
do (format t ", ")) could also be written like this:

   (loop for (item .  rest) on list do (format t "~a" item) when rest do
(format t ", ")) If you want to ignore a value in the destructured list,
you can use NIL in place of a variable name.

   (loop for (a nil) in '((1 2) (3 4) (5 6)) collect a) ==> (1 3 5) If
the destructuring list contains more variables than there are values in
the list, the extra variables are set to NIL, making all the variables
essentially like &optional parameters.  There isn't, however, any
equivalent to &key parameters.


File: pcl.info,  Node: 22-8,  Next: 22-9,  Prev: 22-7,  Up: Chapter 22

Value Accumulation
==================

The value accumulation clauses are perhaps the most powerful part of
LOOP. While the iteration control clauses provide a concise syntax for
expressing the basic mechanics of looping, they aren't dramatically
different from the equivalent mechanisms provided by DO, DOLIST, and
DOTIMES.

   The value accumulation clauses, on the other hand, provide a concise
notation for a handful of common loop idioms having to do with
accumulating values while looping.  Each accumulation clause starts with
a verb and follows this pattern:

   verb form [ into var ] Each time through the loop, an accumulation
clause evaluates form and saves the value in a manner determined by the
verb.  With an into subclause, the value is saved into the variable
named by var.  The variable is local to the loop, as if it'd been
declared in a with clause.  With no into subclause, the accumulation
clause instead accumulates a default value for the whole loop
expression.

   The possible verbs are collect, append, nconc, count, sum, maximize,
and minimize.  Also available as synonyms are the present participle
forms: collecting, appending, nconcing, counting, summing, maximizing,
and minimizing.

   A collect clause builds up a list containing all the values of form
in the order they're seen.  This is a particularly useful construct
because the code you'd have to write to collect a list in order as
efficiently as LOOP does is more painful than you'd normally write by
hand.5 Related to collect are the verbs append and nconc.  These verbs
also accumulate values into a list, but they join the values, which must
be lists, into a single list as if by the functions APPEND or NCONC. 6

   The remaining accumulation clauses are used to accumulate numeric
values.  The verb count counts the number of times form is true, sum
collects a running total of the values of form, maximize collects the
largest value seen for form, and minimize collects the smallest.  For
instance, suppose you define a variable *random* that contains a list of
random numbers.

   (defparameter *random* (loop repeat 100 collect (random 10000))) Then
the following loop will return a list containing various summary
information about the numbers:

   (loop for i in *random* counting (evenp i) into evens counting (oddp
i) into odds summing i into total maximizing i into max minimizing i
into min finally (return (list min max total evens odds)))


File: pcl.info,  Node: 22-9,  Next: 22-10,  Prev: 22-8,  Up: Chapter 22

Unconditional Execution
=======================

As useful as the value accumulation constructs are, LOOP wouldn't be a
very good general-purpose iteration facility if there wasn't a way to
execute arbitrary Lisp code in the loop body.

   The simplest way to execute arbitrary code within a loop body is with
a do clause.  Compared to the clauses I've described so far, with their
prepositions and subclauses, do is a model of Yodaesque simplicity.7 A
do clause consists of the word do (or doing) followed by one or more
Lisp forms that are all evaluated when the do clause is.  The do clause
ends at the closing parenthesis of the loop or the next loop keyword.

   For instance, to print the numbers from one to ten, you could write
this:

   (loop for i from 1 to 10 do (print i)) Another, more dramatic, form
of immediate execution is a return clause.  This clause consists of the
word return followed by a single Lisp form, which is evaluated, with the
resulting value immediately returned as the value of the loop.

   You can also break out of a loop in a do clause using any of Lisp's
normal control flow operators, such as RETURN and RETURN-FROM. Note that
a return clause always returns from the immediately enclosing LOOP
expression, while a RETURN or RETURN-FROM in a do clause can return from
any enclosing expression.  For instance, compare the following:

   (block outer (loop for i from 0 return 100) ; 100 returned from LOOP
(print "This will print") 200) ==> 200 to this:

   (block outer (loop for i from 0 do (return-from outer 100)) ; 100
returned from BLOCK (print "This won't print") 200) ==> 100 The do and
return clauses are collectively called the unconditional execution
clauses.


File: pcl.info,  Node: 22-10,  Next: 22-11,  Prev: 22-9,  Up: Chapter 22

Conditional Execution
=====================

Because a do clause can contain arbitrary Lisp forms, you can use any
Lisp expressions you want, including control constructs such as IF and
WHEN. So, the following is one way to write a loop that prints only the
even numbers between one and ten:

   (loop for i from 1 to 10 do (when (evenp i) (print i))) However,
sometimes you'll want conditional control at the level of loop clauses.
For instance, suppose you wanted to sum only the even numbers between
one and ten using a summing clause.  You couldn't write such a loop with
a do clause because there'd be no way to "call" the sum i in the middle
of a regular Lisp form.  In cases like this, you need to use one of
LOOP's own conditional expressions like this:

   (loop for i from 1 to 10 when (evenp i) sum i) ==> 30 LOOP provides
three conditional constructs, and they all follow this basic pattern:

   conditional test-form loop-clause The conditional can be if, when, or
unless.  The test-form is any regular Lisp form, and loop-clause can be
a value accumulation clause (count, collect, and so on), an
unconditional execution clause, or another conditional execution clause.
Multiple loop clauses can be attached to a single conditional by joining
them with and.

   As an extra bit of syntactic sugar, within the first loop clause,
after the test form, you can use the variable it to refer to the value
returned by the test form.  For instance, the following loop collects
the non-NIL values found in some-hash when looking up the keys in
some-list:

   (loop for key in some-list when (gethash key some-hash) collect it) A
conditional clause is executed each time through the loop.  An if or
when clause executes its loop-clause if test-form evaluates to true.  An
unless reverses the test, executing loop-clause only when test-form is
NIL. Unlike their Common Lisp namesakes, LOOP's if and when are merely
synonyms-there's no difference in their behavior.

   All three conditional clauses can also take an else branch, which is
followed by another loop clause or multiple clauses joined by and.  When
conditional clauses are nested, the set of clauses connected to an inner
conditional clause can be closed with the word end.  The end is optional
when not needed to disambiguate a nested conditional-the end of a
conditional clause will be inferred from the end of the loop or the
start of another clause not joined by and.

   The following rather silly loop demonstrates the various forms of
LOOP conditionals.  The update-analysis function will be called each
time through the loop with the latest values of the various variables
accumulated by the clauses within the conditionals.

   (loop for i from 1 to 100 if (evenp i) minimize i into min-even and
maximize i into max-even and unless (zerop (mod i 4)) sum i into
even-not-fours-total end and sum i into even-total else minimize i into
min-odd and maximize i into max-odd and when (zerop (mod i 5)) sum i
into fives-total end and sum i into odd-total do (update-analysis
min-even max-even min-odd max-odd even-total odd-total fives-total
even-not-fours-total))


File: pcl.info,  Node: 22-11,  Next: 22-12,  Prev: 22-10,  Up: Chapter 22

Setting Up and Tearing Down
===========================

One of the key insights the designers of the LOOP language had about
actual loops "in the wild" is that the loop proper is often preceded by
a bit of code to set things up and then followed by some more code that
does something with the values computed by the loop.  A trivial example,
in Perl,8 might look like this:

   my $evens_sum = 0; my $odds_sum = 0; foreach my $i (@list_of_numbers)
{ if ($i % 2) { $odds_sum += $i; } else { $evens_sum += $i; } } if
($evens_sum > $odds_sum) { print "Sum of evens greater\n"; } else {
print "Sum of odds greater\n"; } The loop proper in this code is the
foreach statement.  But the foreach loop doesn't stand on its own: the
code in the loop body refers to variables declared in the two lines
before the loop.9 And the work the loop does is all for naught without
the if statement after the loop that actually reports the results.  In
Common Lisp, of course, the LOOP construct is an expression that returns
a value, so there's even more often a need to do something after the
loop proper, namely, generate the return value.

   So, said the LOOP designers, let's give a way to include the code
that's really part of the loop in the loop itself.  Thus, LOOP provides
two keywords, initially and finally, that introduce code to be run
outside the loop's main body.

   After the initially or finally, these clauses consist of all the Lisp
forms up to the start of the next loop clause or the end of the loop.
All the initially forms are combined into a single prologue, which runs
once, immediately after all the local loop variables are initialized and
before the body of the loop.  The finally forms are similarly combined
into a epilogue to be run after the last iteration of the loop body.
Both the prologue and epilogue code can refer to local loop variables.

   The prologue is always run, even if the loop body iterates zero
times.  The loop can return without running the epilogue if any of the
following happens:

   A return clause executes.  RETURN , RETURN-FROM, or another transfer
of control construct is called from within a Lisp form within the
body.10 The loop is terminated by an always, never, or thereis clause,
as I'll discuss in the next section.  Within the epilogue code, RETURN
or RETURN-FROM can be used to explicitly provide a return value for the
loop.  Such an explicit return value will take precedence over any value
that might otherwise be provided by an accumulation or termination test
clause.

   To allow RETURN-FROM to be used to return from a specific loop
(useful when nesting LOOP expressions), you can name a LOOP with the
loop keyword named.  If a named clause appears in a loop, it must be the
first clause.  For a simple example, assume lists is a list of lists and
you want to find an item that matches some criteria in one of those
nested lists.  You could find it with a pair of nested loops like this:

   (loop named outer for list in lists do (loop for item in list do (if
(what-i-am-looking-for-p item) (return-from outer item))))


File: pcl.info,  Node: 22-12,  Next: 22-13,  Prev: 22-11,  Up: Chapter 22

Termination Tests
=================

While the for and repeat clauses provide the basic infrastructure for
controlling the number of iterations, sometimes you'll need to break out
of a loop early.  You've already seen how a return clause or a RETURN or
RETURN-FROM within a do clause can immediately terminate the loop; but
just as there are common patterns for accumulating values, there are
also common patterns for deciding when it's time to bail on a loop.
These patterns are supported in LOOP by the termination clauses, while,
until, always, never, and thereis.  They all follow the same pattern.

   loop-keyword test-form All five evaluate test-form each time through
the iteration and decide, based on the resulting value, whether to
terminate the loop.  They differ in what happens after they terminate
the loop-if they do-and how they decide.

   The loop keywords while and until introduce the "mild" termination
clauses.  When they decide to terminate the loop, control passes to the
epilogue, skipping the rest of the loop body.  The epilogue can then
return a value or do whatever it wants to finish the loop.  A while
clause terminates the loop the first time the test form is false; until,
conversely, stops it the first time the test form is true.

   Another form of mild termination is provided by the LOOP-FINISH
macro.  This is a regular Lisp form, not a loop clause, so it can be
used anywhere within the Lisp forms of a do clause.  It also causes an
immediate jump to the loop epilogue.  It can be useful when the decision
to break out of the loop can't be easily condensed into a single form
that can be used with a while or until clause.

   The other three clauses-always, never, and thereis-terminate the loop
with extreme prejudice; they immediately return from the loop, skipping
not only any subsequent loop clauses but also the epilogue.  They also
provide a default value for the loop even when they don't cause the loop
to terminate.  However, if the loop is not terminated by one of these
termination tests, the epilogue is run and can return a value other than
the default provided by the termination clauses.

   Because these clauses provide their own return values, they can't be
combined with accumulation clauses unless the accumulation clause has an
into subclause.  The compiler (or interpreter) should signal an error at
compile time if they are.The always and never clauses return only
boolean values, so they're most useful when you need to use a loop
expression as part of a predicate.  You can use always to check that the
test form is true on every iteration of the loop.  Conversely, never
tests that the test form evaluates to NIL on every iteration.  If the
test form fails (returning NIL in an always clause or non-NIL in a never
clause), the loop is immediately terminated, returning NIL. If the loop
runs to completion, the default value of T is provided.

   For instance, if you want to test that all the numbers in a list,
numbers, are even, you can write this:

   (if (loop for n in numbers always (evenp n)) (print "All numbers
even."))  Equivalently you could write the following:

   (if (loop for n in numbers never (oddp n)) (print "All numbers
even."))  A thereis clause is used to test whether the test form is ever
true.  As soon as the test form returns a non-NIL value, the loop is
terminated, returning that value.  If the loop runs to completion, the
thereis clause provides a default return value of NIL.

   (loop for char across "abc123" thereis (digit-char-p char)) ==> 1

   (loop for char across "abcdef" thereis (digit-char-p char)) ==> NIL


File: pcl.info,  Node: 22-13,  Next: Chapter 23,  Prev: 22-12,  Up: Chapter 22

Putting It All Together
=======================

Now you've seen all the main features of the LOOP facility.  You can
combine any of the clauses I've discussed as long as you abide by the
following rules:

   The named clause, if any, must be the first clause.  After the named
clause come all the initially, with, for, and repeat clauses.  Then
comes the body clauses: conditional and unconditional execution,
accumulation, and termination test.11 End with any finally clauses.  The
LOOP macro will expand into code that performs the following actions:

   Initializes all local loop variables as declared with with or for
clauses as well as those implicitly created by accumulation clauses.
The initial value forms are evaluated in the order the clauses appear in
the loop.  Execute the forms provided by any initially clauses-the
prologue-in the order they appear in the loop.  Iterate, executing the
body of the loop as described in the next paragraph.  Execute the forms
provided by any finally clauses-the epilogue-in the order they appear in
the loop.  While the loop is iterating, the body is executed by first
stepping any iteration control variables and then executing any
conditional or unconditional execution, accumulation, or termination
test clauses in the order they appear in the loop code.  If any of the
clauses in the loop body terminate the loop, the rest of the body is
skipped and the loop returns, possibly after running the epilogue.

   And that's pretty much all there is to it.12 You'll use LOOP fairly
often in the code later in this book, so it's worth having some
knowledge of it.  Beyond that, it's up to you how much you use it.

   And with that, you're ready to dive into the practical chapters that
make up the rest of the book-up first, writing a spam filter.


File: pcl.info,  Node: Chapter 23,  Next: Chapter 24,  Prev: Chapter 22,  Up: Top

23. Practical: A Spam Filter
============================

In 2002 Paul Graham, having some time on his hands after selling Viaweb
to Yahoo, wrote the essay "A Plan for Spam"1 that launched a minor
revolution in spam-filtering technology.  Prior to Graham's article,
most spam filters were written in terms of handcrafted rules: if a
message has XXX in the subject, it's probably a spam; if a message has a
more than three or more words in a row in ALL CAPITAL LETTERS, it's
probably a spam.  Graham spent several months trying to write such a
rule-based filter before realizing it was fundamentally a soul-sucking
task.

   To recognize individual spam features you have to try to get into the
mind of the spammer, and frankly I want to spend as little time inside
the minds of spammers as possible.  To avoid having to think like a
spammer, Graham decided to try distinguishing spam from nonspam, a.k.a.
ham, based on statistics gathered about which words occur in which kinds
of e-mails.  The filter would keep track of how often specific words
appear in both spam and ham messages and then use the frequencies
associated with the words in a new message to compute a probability that
it was either spam or ham.  He called his approach Bayesian filtering
after the statistical technique that he used to combine the individual
word frequencies into an overall probability.2

* Menu:

* 23-1::       The Heart of a Spam Filter
* 23-2::       Training the Filter
* 23-3::       Per-Word Statistics
* 23-4::       Combining Probabilities
* 23-5::       Inverse Chi Square
* 23-6::       Training the Filter
* 23-7::       Testing the Filter
* 23-8::       A Couple of Utility Functions
* 23-9::       Analyzing the Results
* 23-10::      What's Next


File: pcl.info,  Node: 23-1,  Next: 23-2,  Prev: Chapter 23,  Up: Chapter 23

The Heart of a Spam Filter
==========================

In this chapter, you'll implement the core of a spam-filtering engine.
You won't write a soup-to-nuts spam-filtering application; rather,
you'll focus on the functions for classifying new messages and training
the filter.

   This application is going to be large enough that it's worth defining
a new package to avoid name conflicts.  For instance, in the source code
you can download from this book's Web site, I use the package name
COM.GIGAMONKEYS.SPAM, defining a package that uses both the standard
COMMON-LISP package and the COM.GIGAMONKEYS.PATHNAMES package from
Chapter 15, like this:

   (defpackage :com.gigamonkeys.spam (:use :common-lisp
:com.gigamonkeys.pathnames)) Any file containing code for this
application should start with this line:

   (in-package :com.gigamonkeys.spam) You can use the same package name
or replace com.gigamonkeys with some domain you control.3

   You can also type this same form at the REPL to switch to this
package to test the functions you write.  In SLIME this will change the
prompt from CL-USER> to SPAM> like this:

   CL-USER> (in-package :com.gigamonkeys.spam) #<The
COM.GIGAMONKEYS.SPAM package> SPAM> Once you have a package defined, you
can start on the actual code.  The main function you'll need to
implement has a simple job-take the text of a message as an argument and
classify the message as spam, ham, or unsure.  You can easily implement
this basic function by defining it in terms of other functions that
you'll write in a moment.

   (defun classify (text) (classification (score (extract-features
text)))) Reading from the inside out, the first step in classifying a
message is to extract features to pass to the score function.  In score
you'll compute a value that can then be translated into one of three
classifications-spam, ham, or unsure-by the function classification.  Of
the three functions, classification is the simplest.  You can assume
score will return a value near 1 if the message is a spam, near 0 if
it's a ham, and near .5 if it's unclear.

   Thus, you can implement classification like this:

   (defparameter *max-ham-score* .4) (defparameter *min-spam-score* .6)

   (defun classification (score) (cond ((<= score *max-ham-score*) 'ham)
((>= score *min-spam-score*) 'spam) (t 'unsure))) The extract-features
function is almost as straightforward, though it requires a bit more
code.  For the moment, the features you'll extract will be the words
appearing in the text.  For each word, you need to keep track of the
number of times it has been seen in a spam and the number of times it
has been seen in a ham.  A convenient way to keep those pieces of data
together with the word itself is to define a class, word-feature, with
three slots.

   (defclass word-feature () ((word :initarg :word :accessor word
:initform (error "Must supply :word") :documentation "The word this
feature represents.")  (spam-count :initarg :spam-count :accessor
spam-count :initform 0 :documentation "Number of spams we have seen this
feature in.")  (ham-count :initarg :ham-count :accessor ham-count
:initform 0 :documentation "Number of hams we have seen this feature
in.")))  You'll keep the database of features in a hash table so you can
easily find the object representing a given feature.  You can define a
special variable, *feature-database*, to hold a reference to this hash
table.

   (defvar *feature-database* (make-hash-table :test #'equal)) You
should use DEFVAR rather than DEFPARAMETER because you don't want
*feature-database* to be reset if you happen to reload the file
containing this definition during development-you might have data stored
in *feature-database* that you don't want to lose.  Of course, that
means if you do want to clear out the feature database, you can't just
reevaluate the DEFVAR form.  So you should define a function
clear-database.

   (defun clear-database () (setf *feature-database* (make-hash-table
:test #'equal))) To find the features present in a given message, the
code will need to extract the individual words and then look up the
corresponding word-feature object in *feature-database*.  If
*feature-database* contains no such feature, it'll need to create a new
word-feature to represent the word.  You can encapsulate that bit of
logic in a function, intern-feature, that takes a word and returns the
appropriate feature, creating it if necessary.

   (defun intern-feature (word) (or (gethash word *feature-database*)
(setf (gethash word *feature-database*) (make-instance 'word-feature
:word word)))) You can extract the individual words from the message
text using a regular expression.  For example, using the Common Lisp
Portable Perl-Compatible Regular Expression (CL-PPCRE) library written
by Edi Weitz, you can write extract-words like this:4

   (defun extract-words (text) (delete-duplicates
(cl-ppcre:all-matches-as-strings "[a-zA-Z]{3,}" text) :test #'string=))
Now all that remains to implement extract-features is to put
extract-features and intern-feature together.  Since extract-words
returns a list of strings and you want a list with each string
translated to the corresponding word-feature, this is a perfect time to
use MAPCAR.

   (defun extract-features (text) (mapcar #'intern-feature
(extract-words text))) You can test these functions at the REPL like
this:

   SPAM> (extract-words "foo bar baz") ("foo" "bar" "baz") And you can
make sure the DELETE-DUPLICATES is working like this:

   SPAM> (extract-words "foo bar baz foo bar") ("baz" "foo" "bar") You
can also test extract-features.

   SPAM> (extract-features "foo bar baz foo bar") (#<WORD-FEATURE
 #x71ef28da> #<WORD-FEATURE  #x71e3809a> #<WORD-FEATURE  #x71ef28aa>)
However, as you can see, the default method for printing arbitrary
objects isn't very informative.  As you work on this program, it'll be
useful to be able to print word-feature objects in a less opaque way.
Luckily, as I mentioned in Chapter 17, the printing of all objects is
implemented in terms of a generic function PRINT-OBJECT, so to change
the way word-feature objects are printed, you just need to define a
method on PRINT-OBJECT that specializes on word-feature.  To make
implementing such methods easier, Common Lisp provides the macro
PRINT-UNREADABLE-OBJECT.5

   The basic form of PRINT-UNREADABLE-OBJECT is as follows:

   (print-unreadable-object (object stream-variable &key type identity)
body-form*) The object argument is an expression that evaluates to the
object to be printed.  Within the body of PRINT-UNREADABLE-OBJECT,
stream-variable is bound to a stream to which you can print anything you
want.  Whatever you print to that stream will be output by
PRINT-UNREADABLE-OBJECT and enclosed in the standard syntax for
unreadable objects, #<>.6

   PRINT-UNREADABLE-OBJECT also lets you include the type of the object
and an indication of the object's identity via the keyword parameters
type and identity.  If they're non-NIL, the output will start with the
name of the object's class and end with an indication of the object's
identity similar to what's printed by the default PRINT-OBJECT method
for STANDARD-OBJECTs.  For word-feature, you probably want to define a
PRINT-OBJECT method that includes the type but not the identity along
with the values of the word, ham-count, and spam-count slots.  Such a
method would look like this:

   (defmethod print-object ((object word-feature) stream)
(print-unreadable-object (object stream :type t) (with-slots (word
ham-count spam-count) object (format stream "~s :hams ~d :spams ~d" word
ham-count spam-count)))) Now when you test extract-features at the REPL,
you can see more clearly what features are being extracted.

   SPAM> (extract-features "foo bar baz foo bar") (#<WORD-FEATURE "baz"
:hams 0 :spams 0> #<WORD-FEATURE "foo" :hams 0 :spams 0> #<WORD-FEATURE
"bar" :hams 0 :spams 0>)


File: pcl.info,  Node: 23-2,  Next: 23-3,  Prev: 23-1,  Up: Chapter 23

Training the Filter
===================

Now that you have a way to keep track of individual features, you're
almost ready to implement score.  But first you need to write the code
you'll use to train the spam filter so score will have some data to use.
You'll define a function, train, that takes some text and a symbol
indicating what kind of message it is-ham or spam-and that increments
either the ham count or the spam count of all the features present in
the text as well as a global count of hams or spams processed.  Again,
you can take a top-down approach and implement it in terms of other
functions that don't yet exist.

   (defun train (text type) (dolist (feature (extract-features text))
(increment-count feature type)) (increment-total-count type)) You've
already written extract-features, so next up is increment-count, which
takes a word-feature and a message type and increments the appropriate
slot of the feature.  Since there's no reason to think that the logic of
incrementing these counts is going to change for different kinds of
objects, you can write this as a regular function.7 Because you defined
both ham-count and spam-count with an :accessor option, you can use INCF
and the accessor functions created by DEFCLASS to increment the
appropriate slot.

   (defun increment-count (feature type) (ecase type (ham (incf
(ham-count feature))) (spam (incf (spam-count feature))))) The ECASE
construct is a variant of CASE, both of which are similar to case
statements in Algol-derived languages (renamed switch in C and its
progeny).  They both evaluate their first argument-the key form-and then
find the clause whose first element-the key-is the same value according
to EQL. In this case, that means the variable type is evaluated,
yielding whatever value was passed as the second argument to
increment-count.

   The keys aren't evaluated.  In other words, the value of type will be
compared to the literal objects read by the Lisp reader as part of the
ECASE form.  In this function, that means the keys are the symbols ham
and spam, not the values of any variables named ham and spam.  So, if
increment-count is called like this:

   (increment-count some-feature 'ham) the value of type will be the
symbol ham, and the first branch of the ECASE will be evaluated and the
feature's ham count incremented.  On the other hand, if it's called like
this:

   (increment-count some-feature 'spam) then the second branch will run,
incrementing the spam count.  Note that the symbols ham and spam are
quoted when calling increment-count since otherwise they'd be evaluated
as the names of variables.  But they're not quoted when they appear in
ECASE since ECASE doesn't evaluate the keys.8

   The E in ECASE stands for "exhaustive" or "error," meaning ECASE
should signal an error if the key value is anything other than one of
the keys listed.  The regular CASE is looser, returning NIL if no
matching clause is found.

   To implement increment-total-count, you need to decide where to store
the counts; for the moment, two more special variables, *total-spams*
and *total-hams*, will do fine.

   (defvar *total-spams* 0) (defvar *total-hams* 0)

   (defun increment-total-count (type) (ecase type (ham (incf
*total-hams*)) (spam (incf *total-spams*)))) You should use DEFVAR to
define these two variables for the same reason you used it with
*feature-database*-they'll hold data built up while you run the program
that you don't necessarily want to throw away just because you happen to
reload your code during development.  But you'll want to reset those
variables if you ever reset *feature-database*, so you should add a few
lines to clear-database as shown here:

   (defun clear-database () (setf *feature-database* (make-hash-table
:test #'equal) *total-spams* 0 *total-hams* 0))


File: pcl.info,  Node: 23-3,  Next: 23-4,  Prev: 23-2,  Up: Chapter 23

Per-Word Statistics
===================

The heart of a statistical spam filter is, of course, the functions that
compute statistics-based probabilities.  The mathematical nuances9 of
why exactly these computations work are beyond the scope of this
book-interested readers may want to refer to several papers by Gary
Robinson.10 I'll focus rather on how they're implemented.

   The starting point for the statistical computations is the set of
measured values-the frequencies stored in *feature-database*,
*total-spams*, and *total-hams*.  Assuming that the set of messages
trained on is statistically representative, you can treat the observed
frequencies as probabilities of the same features showing up in hams and
spams in future messages.

   The basic plan is to classify a message by extracting the features it
contains, computing the individual probability that a given message
containing the feature is a spam, and then combining all the individual
probabilities into a total score for the message.  Messages with many
"spammy" features and few "hammy" features will receive a score near 1,
and messages with many hammy features and few spammy features will score
near 0.

   The first statistical function you need is one that computes the
basic probability that a message containing a given feature is a spam.
By one point of view, the probability that a given message containing
the feature is a spam is the ratio of spam messages containing the
feature to all messages containing the feature.  Thus, you could compute
it this way:

   (defun spam-probability (feature) (with-slots (spam-count ham-count)
feature (/ spam-count (+ spam-count ham-count)))) The problem with the
value computed by this function is that it's strongly affected by the
overall probability that any message will be a spam or a ham.  For
instance, suppose you get nine times as much ham as spam in general.  A
completely neutral feature will then appear in one spam for every nine
hams, giving you a spam probability of 1/10 according to this function.

   But you're more interested in the probability that a given feature
will appear in a spam message, independent of the overall probability of
getting a spam or ham.  Thus, you need to divide the spam count by the
total number of spams trained on and the ham count by the total number
of hams.  To avoid division-by-zero errors, if either of *total-spams*
or *total-hams* is zero, you should treat the corresponding frequency as
zero.  (Obviously, if the total number of either spams or hams is zero,
then the corresponding per-feature count will also be zero, so you can
treat the resulting frequency as zero without ill effect.)

   (defun spam-probability (feature) (with-slots (spam-count ham-count)
feature (let ((spam-frequency (/ spam-count (max 1 *total-spams*)))
(ham-frequency (/ ham-count (max 1 *total-hams*)))) (/ spam-frequency (+
spam-frequency ham-frequency))))) This version suffers from another
problem-it doesn't take into account the number of messages analyzed to
arrive at the per-word probabilities.  Suppose you've trained on 2,000
messages, half spam and half ham.  Now consider two features that have
appeared only in spams.  One has appeared in all 1,000 spams, while the
other appeared only once.  According to the current definition of
spam-probability, the appearance of either feature predicts that a
message is spam with equal probability, namely, 1.

   However, it's still quite possible that the feature that has appeared
only once is actually a neutral feature-it's obviously rare in either
spams or hams, appearing only once in 2,000 messages.  If you trained on
another 2,000 messages, it might very well appear one more time, this
time in a ham, making it suddenly a neutral feature with a spam
probability of .5.

   So it seems you might like to compute a probability that somehow
factors in the number of data points that go into each feature's
probability.  In his papers, Robinson suggested a function based on the
Bayesian notion of incorporating observed data into prior knowledge or
assumptions.  Basically, you calculate a new probability by starting
with an assumed prior probability and a weight to give that assumed
probability before adding new information.  Robinson's function is this:

   (defun bayesian-spam-probability (feature &optional
(assumed-probability 1/2) (weight 1)) (let ((basic-probability
(spam-probability feature)) (data-points (+ (spam-count feature)
(ham-count feature)))) (/ (+ (* weight assumed-probability) (*
data-points basic-probability)) (+ weight data-points)))) Robinson
suggests values of 1/2 for assumed-probability and 1 for weight.  Using
those values, a feature that has appeared in one spam and no hams has a
bayesian-spam-probability of 0.75, a feature that has appeared in 10
spams and no hams has a bayesian-spam-probability of approximately
0.955, and one that has matched in 1,000 spams and no hams has a spam
probability of approximately 0.9995.


File: pcl.info,  Node: 23-4,  Next: 23-5,  Prev: 23-3,  Up: Chapter 23

Combining Probabilities
=======================

Now that you can compute the bayesian-spam-probability of each
individual feature you find in a message, the last step in implementing
the score function is to find a way to combine a bunch of individual
probabilities into a single value between 0 and 1.

   If the individual feature probabilities were independent, then it'd
be mathematically sound to multiply them together to get a combined
probability.  But it's unlikely they actually are independent-certain
features are likely to appear together, while others never do.11

   Robinson proposed using a method for combining probabilities invented
by the statistician R. A. Fisher.  Without going into the details of
exactly why his technique works, it's this: First you combine the
probabilities by multiplying them together.  This gives you a number
nearer to 0 the more low probabilities there were in the original set.
Then take the log of that number and multiply by -2.  Fisher showed in
1950 that if the individual probabilities were independent and drawn
from a uniform distribution between 0 and 1, then the resulting value
would be on a chi-square distribution.  This value and twice the number
of probabilities can be fed into an inverse chi-square function, and
it'll return the probability that reflects the likelihood of obtaining a
value that large or larger by combining the same number of randomly
selected probabilities.  When the inverse chi-square function returns a
low probability, it means there was a disproportionate number of low
probabilities (either a lot of relatively low probabilities or a few
very low probabilities) in the individual probabilities.

   To use this probability in determining whether a given message is a
spam, you start with a null hypothesis, a straw man you hope to knock
down.  The null hypothesis is that the message being classified is in
fact just a random collection of features.  If it were, then the
individual probabilities-the likelihood that each feature would appear
in a spam-would also be random.  That is, a random selection of features
would usually contain some features with a high probability of appearing
in spam and other features with a low probability of appearing in spam.
If you were to combine these randomly selected probabilities according
to Fisher's method, you should get a middling combined value, which the
inverse chi-square function will tell you is quite likely to arise just
by chance, as, in fact, it would have.  But if the inverse chi-square
function returns a very low probability, it means it's unlikely the
probabilities that went into the combined value were selected at random;
there were too many low probabilities for that to be likely.  So you can
reject the null hypothesis and instead adopt the alternative hypothesis
that the features involved were drawn from a biased sample-one with few
high spam probability features and many low spam probability features.
In other words, it must be a ham message.

   However, the Fisher method isn't symmetrical since the inverse
chi-square function returns the probability that a given number of
randomly selected probabilities would combine to a value as large or
larger than the one you got by combining the actual probabilities.  This
asymmetry works to your advantage because when you reject the null
hypothesis, you know what the more likely hypothesis is.  When you
combine the individual spam probabilities via the Fisher method, and it
tells you there's a high probability that the null hypothesis is
wrong-that the message isn't a random collection of words-then it means
it's likely the message is a ham.  The number returned is, if not
literally the probability that the message is a ham, at least a good
measure of its "hamminess."  Conversely, the Fisher combination of the
individual ham probabilities gives you a measure of the message's
"spamminess."

   To get a final score, you need to combine those two measures into a
single number that gives you a combined hamminess-spamminess score
ranging from 0 to 1.  The method recommended by Robinson is to add half
the difference between the hamminess and spamminess scores to 1/2, in
other words, to average the spamminess and 1 minus the hamminess.  This
has the nice effect that when the two scores agree (high spamminess and
low hamminess, or vice versa) you'll end up with a strong indicator near
either 0 or 1.  But when the spamminess and hamminess scores are both
high or both low, then you'll end up with a final value near 1/2, which
you can treat as an "uncertain" classification.

   The score function that implements this scheme looks like this:

   (defun score (features) (let ((spam-probs ()) (ham-probs ())
(number-of-probs 0)) (dolist (feature features) (unless (untrained-p
feature) (let ((spam-prob (float (bayesian-spam-probability feature)
0.0d0))) (push spam-prob spam-probs) (push (- 1.0d0 spam-prob)
ham-probs) (incf number-of-probs)))) (let ((h (- 1 (fisher spam-probs
number-of-probs))) (s (- 1 (fisher ham-probs number-of-probs)))) (/ (+
(- 1 h) s) 2.0d0)))) You take a list of features and loop over them,
building up two lists of probabilities, one listing the probabilities
that a message containing each feature is a spam and the other that a
message containing each feature is a ham.  As an optimization, you can
also count the number of probabilities while looping over them and pass
the count to fisher to avoid having to count them again in fisher
itself.  The value returned by fisher will be low if the individual
probabilities contained too many low probabilities to have come from
random text.  Thus, a low fisher score for the spam probabilities means
there were many hammy features; subtracting that score from 1 gives you
a probability that the message is a ham.  Conversely, subtracting the
fisher score for the ham probabilities gives you the probability that
the message was a spam.  Combining those two probabilities gives you an
overall spamminess score between 0 and 1.

   Within the loop, you can use the function untrained-p to skip
features extracted from the message that were never seen during
training.  These features will have spam counts and ham counts of zero.
The untrained-p function is trivial.

   (defun untrained-p (feature) (with-slots (spam-count ham-count)
feature (and (zerop spam-count) (zerop ham-count)))) The only other new
function is fisher itself.  Assuming you already had an
inverse-chi-square function, fisher is conceptually simple.

   (defun fisher (probs number-of-probs) "The Fisher computation
described by Robinson."  (inverse-chi-square (* -2 (log (reduce #'*
probs))) (* 2 number-of-probs))) Unfortunately, there's a small problem
with this straightforward implementation.  While using REDUCE is a
concise and idiomatic way of multiplying a list of numbers, in this
particular application there's a danger the product will be too small a
number to be represented as a floating-point number.  In that case, the
result will underflow to zero.  And if the product of the probabilities
underflows, all bets are off because taking the LOG of zero will either
signal an error or, in some implementation, result in a special
negative-infinity value, which will render all subsequent calculations
essentially meaningless.  This is particularly unfortunate in this
function because the Fisher method is most sensitive when the input
probabilities are low-near zero-and therefore in the most danger of
causing the multiplication to underflow.

   Luckily, you can use a bit of high-school math to avoid this problem.
Recall that the log of a product is the same as the sum of the logs of
the factors.  So instead of multiplying all the probabilities and then
taking the log, you can sum the logs of each probability.  And since
REDUCE takes a :key keyword parameter, you can use it to perform the
whole calculation.  Instead of this:

   (log (reduce #'* probs)) write this:

   (reduce #'+ probs :key #'log)


File: pcl.info,  Node: 23-5,  Next: 23-6,  Prev: 23-4,  Up: Chapter 23

Inverse Chi Square
==================

The implementation of inverse-chi-square in this section is a fairly
straightforward translation of a version written in Python by Robinson.
The exact mathematical meaning of this function is beyond the scope of
this book, but you can get an intuitive sense of what it does by
thinking about how the values you pass to fisher will affect the result:
the more low probabilities you pass to fisher, the smaller the product
of the probabilities will be.  The log of a small product will be a
negative number with a large absolute value, which is then multiplied by
-2, making it an even larger positive number.  Thus, the more low
probabilities were passed to fisher, the larger the value it'll pass to
inverse-chi-square.  Of course, the number of probabilities involved
also affects the value passed to inverse-chi-square.  Since
probabilities are, by definition, less than or equal to 1, the more
probabilities that go into a product, the smaller it'll be and the
larger the value passed to inverse-chi-square.  Thus, inverse-chi-square
should return a low probability when the Fisher combined value is
abnormally large for the number of probabilities that went into it.  The
following function does exactly that:

   (defun inverse-chi-square (value degrees-of-freedom) (assert (evenp
degrees-of-freedom)) (min (loop with m = (/ value 2) for i below (/
degrees-of-freedom 2) for prob = (exp (- m)) then (* prob (/ m i))
summing prob) 1.0)) Recall from Chapter 10 that EXP raises e to the
argument given.  Thus, the larger value is, the smaller the initial
value of prob will be.  But that initial value will then be adjusted
upward slightly for each degree of freedom as long as m is greater than
the number of degrees of freedom.  Since the value returned by
inverse-chi-square is supposed to be another probability, it's important
to clamp the value returned with MIN since rounding errors in the
multiplication and exponentiation may cause the LOOP to return a sum
just a shade over 1.


File: pcl.info,  Node: 23-6,  Next: 23-7,  Prev: 23-5,  Up: Chapter 23

Training the Filter
===================

Since you wrote classify and train to take a string argument, you can
test them easily at the REPL. If you haven't yet, you should switch to
the package in which you've been writing this code by evaluating an
IN-PACKAGE form at the REPL or using the SLIME shortcut change-package.
To use the SLIME shortcut, type a comma at the REPL and then type the
name at the prompt.  Pressing Tab while typing the package name will
autocomplete based on the packages your Lisp knows about.  Now you can
invoke any of the functions that are part of the spam application.  You
should first make sure the database is empty.

   SPAM> (clear-database) Now you can train the filter with some text.

   SPAM> (train "Make money fast" 'spam) And then see what the
classifier thinks.

   SPAM> (classify "Make money fast") SPAM SPAM> (classify "Want to go
to the movies?")  UNSURE While ultimately all you care about is the
classification, it'd be nice to be able to see the raw score too.  The
easiest way to get both values without disturbing any other code is to
change classification to return multiple values.

   (defun classification (score) (values (cond ((<= score
*max-ham-score*) 'ham) ((>= score *min-spam-score*) 'spam) (t 'unsure))
score)) You can make this change and then recompile just this one
function.  Because classify returns whatever classification returns,
it'll also now return two values.  But since the primary return value is
the same, callers of either function who expect only one value won't be
affected.  Now when you test classify, you can see exactly what score
went into the classification.

   SPAM> (classify "Make money fast") SPAM 0.863677101854273D0 SPAM>
(classify "Want to go to the movies?")  UNSURE 0.5D0 And now you can see
what happens if you train the filter with some more ham text.

   SPAM> (train "Do you have any money for the movies?"  'ham) 1 SPAM>
(classify "Make money fast") SPAM 0.7685351219857626D0 It's still spam
but a bit less certain since money was seen in ham text.

   SPAM> (classify "Want to go to the movies?")  HAM
0.17482223132078922D0 And now this is clearly recognizable ham thanks to
the presence of the word movies, now a hammy feature.

   However, you don't really want to train the filter by hand.  What
you'd really like is an easy way to point it at a bunch of files and
train it on them.  And if you want to test how well the filter actually
works, you'd like to then use it to classify another set of files of
known types and see how it does.  So the last bit of code you'll write
in this chapter will be a test harness that tests the filter on a corpus
of messages of known types, using a certain fraction for training and
then measuring how accurate the filter is when classifying the
remainder.


File: pcl.info,  Node: 23-7,  Next: 23-8,  Prev: 23-6,  Up: Chapter 23

Testing the Filter
==================

To test the filter, you need a corpus of messages of known types.  You
can use messages lying around in your inbox, or you can grab one of the
corpora available on the Web.  For instance, the SpamAssassin corpus12
contains several thousand messages hand classified as spam, easy ham,
and hard ham.  To make it easy to use whatever files you have, you can
define a test rig that's driven off an array of file/type pairs.  You
can define a function that takes a filename and a type and adds it to
the corpus like this:

   (defun add-file-to-corpus (filename type corpus) (vector-push-extend
(list filename type) corpus)) The value of corpus should be an
adjustable vector with a fill pointer.  For instance, you can make a new
corpus like this:

   (defparameter *corpus* (make-array 1000 :adjustable t :fill-pointer
0)) If you have the hams and spams already segregated into separate
directories, you might want to add all the files in a directory as the
same type.  This function, which uses the list-directory function from
Chapter 15, will do the trick:

   (defun add-directory-to-corpus (dir type corpus) (dolist (filename
(list-directory dir)) (add-file-to-corpus filename type corpus))) For
instance, suppose you have a directory mail containing two
subdirectories, spam and ham, each containing messages of the indicated
type; you can add all the files in those two directories to *corpus*
like this:

   SPAM> (add-directory-to-corpus "mail/spam/" 'spam *corpus*) NIL SPAM>
(add-directory-to-corpus "mail/ham/" 'ham *corpus*) NIL Now you need a
function to test the classifier.  The basic strategy will be to select a
random chunk of the corpus to train on and then test the corpus by
classifying the remainder of the corpus, comparing the classification
returned by the classify function to the known classification.  The main
thing you want to know is how accurate the classifier is-what percentage
of the messages are classified correctly?  But you'll probably also be
interested in what messages were misclassified and in what
direction-were there more false positives or more false negatives?  To
make it easy to perform different analyses of the classifier's behavior,
you should define the testing functions to build a list of raw results,
which you can then analyze however you like.

   The main testing function might look like this:

   (defun test-classifier (corpus testing-fraction) (clear-database)
(let* ((shuffled (shuffle-vector corpus)) (size (length corpus))
(train-on (floor (* size (- 1 testing-fraction))))) (train-from-corpus
shuffled :start 0 :end train-on) (test-from-corpus shuffled :start
train-on))) This function starts by clearing out the feature database.13
Then it shuffles the corpus, using a function you'll implement in a
moment, and figures out, based on the testing-fraction parameter, how
many messages it'll train on and how many it'll reserve for testing.
The two helper functions train-from-corpus and test-from-corpus will
both take :start and :end keyword parameters, allowing them to operate
on a subsequence of the given corpus.

   The train-from-corpus function is quite simple-simply loop over the
appropriate part of the corpus, use DESTRUCTURING-BIND to extract the
filename and type from the list found in each element, and then pass the
text of the named file and the type to train.  Since some mail messages,
such as those with attachments, are quite large, you should limit the
number of characters it'll take from the message.  It'll obtain the text
with a function start-of-file, which you'll implement in a moment, that
takes a filename and a maximum number of characters to return.
train-from-corpus looks like this:

   (defparameter *max-chars* (* 10 1024))

   (defun train-from-corpus (corpus &key (start 0) end) (loop for idx
from start below (or end (length corpus)) do (destructuring-bind (file
type) (aref corpus idx) (train (start-of-file file *max-chars*) type))))
The test-from-corpus function is similar except you want to return a
list containing the results of each classification so you can analyze
them after the fact.  Thus, you should capture both the classification
and score returned by classify and then collect a list of the filename,
the actual type, the type returned by classify, and the score.  To make
the results more human readable, you can include keywords in the list to
indicate which values are which.

   (defun test-from-corpus (corpus &key (start 0) end) (loop for idx
from start below (or end (length corpus)) collect (destructuring-bind
(file type) (aref corpus idx) (multiple-value-bind (classification
score) (classify (start-of-file file *max-chars*)) (list :file file
:type type :classification classification :score score)))))


File: pcl.info,  Node: 23-8,  Next: 23-9,  Prev: 23-7,  Up: Chapter 23

A Couple of Utility Functions
=============================

To finish the implementation of test-classifier, you need to write the
two utility functions that don't really have anything particularly to do
with spam filtering, shuffle-vector and start-of-file.

   An easy and efficient way to implement shuffle-vector is using the
Fisher-Yates algorithm.14 You can start by implementing a function,
nshuffle-vector, that shuffles a vector in place.  This name follows the
same naming convention of other destructive functions such as NCONC and
NREVERSE. It looks like this:

   (defun nshuffle-vector (vector) (loop for idx downfrom (1- (length
vector)) to 1 for other = (random (1+ idx)) do (unless (= idx other)
(rotatef (aref vector idx) (aref vector other)))) vector) The
nondestructive version simply makes a copy of the original vector and
passes it to the destructive version.

   (defun shuffle-vector (vector) (nshuffle-vector (copy-seq vector)))
The other utility function, start-of-file, is almost as straightforward
with just one wrinkle.  The most efficient way to read the contents of a
file into memory is to create an array of the appropriate size and use
READ-SEQUENCE to fill it in.  So it might seem you could make a
character array that's either the size of the file or the maximum number
of characters you want to read, whichever is smaller.  Unfortunately, as
I mentioned in Chapter 14, the function FILE-LENGTH isn't entirely well
defined when dealing with character streams since the number of
characters encoded in a file can depend on both the character encoding
used and the particular text in the file.  In the worst case, the only
way to get an accurate measure of the number of characters in a file is
to actually read the whole file.  Thus, it's ambiguous what FILE-LENGTH
should do when passed a character stream; in most implementations,
FILE-LENGTH always returns the number of octets in the file, which may
be greater than the number of characters that can be read from the file.

   However, READ-SEQUENCE returns the number of characters actually
read.  So, you can attempt to read the number of characters reported by
FILE-LENGTH and return a substring if the actual number of characters
read was smaller.

   (defun start-of-file (file max-chars) (with-open-file (in file) (let*
((length (min (file-length in) max-chars)) (text (make-string length))
(read (read-sequence text in))) (if (< read length) (subseq text 0 read)
text))))


File: pcl.info,  Node: 23-9,  Next: 23-10,  Prev: 23-8,  Up: Chapter 23

Analyzing the Results
=====================

Now you're ready to write some code to analyze the results generated by
test-classifier.  Recall that test-classifier returns the list returned
by test-from-corpus in which each element is a plist representing the
result of classifying one file.  This plist contains the name of the
file, the actual type of the file, the classification, and the score
returned by classify.  The first bit of analytical code you should write
is a function that returns a symbol indicating whether a given result
was correct, a false positive, a false negative, a missed ham, or a
missed spam.  You can use DESTRUCTURING-BIND to pull out the :type and
:classification elements of an individual result list (using
&allow-other-keys to tell DESTRUCTURING-BIND to ignore any other
key/value pairs it sees) and then use nested ECASE to translate the
different pairings into a single symbol.

   (defun result-type (result) (destructuring-bind (&key type
classification &allow-other-keys) result (ecase type (ham (ecase
classification (ham 'correct) (spam 'false-positive) (unsure
'missed-ham))) (spam (ecase classification (ham 'false-negative) (spam
'correct) (unsure 'missed-spam)))))) You can test out this function at
the REPL.

   SPAM> (result-type '(:FILE #p"foo" :type ham :classification ham
:score 0)) CORRECT SPAM> (result-type '(:FILE #p"foo" :type spam
:classification spam :score 0)) CORRECT SPAM> (result-type '(:FILE
#p"foo" :type ham :classification spam :score 0)) FALSE-POSITIVE SPAM>
(result-type '(:FILE #p"foo" :type spam :classification ham :score 0))
FALSE-NEGATIVE SPAM> (result-type '(:FILE #p"foo" :type ham
:classification unsure :score 0)) MISSED-HAM SPAM> (result-type '(:FILE
#p"foo" :type spam :classification unsure :score 0)) MISSED-SPAM Having
this function makes it easy to slice and dice the results of
test-classifier in a variety of ways.  For instance, you can start by
defining predicate functions for each type of result.

   (defun false-positive-p (result) (eql (result-type result)
'false-positive))

   (defun false-negative-p (result) (eql (result-type result)
'false-negative))

   (defun missed-ham-p (result) (eql (result-type result) 'missed-ham))

   (defun missed-spam-p (result) (eql (result-type result)
'missed-spam))

   (defun correct-p (result) (eql (result-type result) 'correct)) With
those functions, you can easily use the list and sequence manipulation
functions I discussed in Chapter 11 to extract and count particular
kinds of results.

   SPAM> (count-if #'false-positive-p *results*) 6 SPAM> (remove-if-not
#'false-positive-p *results*) ((:FILE #p"ham/5349" :TYPE HAM
:CLASSIFICATION SPAM :SCORE 0.9999983107355541d0) (:FILE #p"ham/2746"
:TYPE HAM :CLASSIFICATION SPAM :SCORE 0.6286468956619795d0) (:FILE
#p"ham/3427" :TYPE HAM :CLASSIFICATION SPAM :SCORE 0.9833753501352983d0)
(:FILE #p"ham/7785" :TYPE HAM :CLASSIFICATION SPAM :SCORE
0.9542788587998488d0) (:FILE #p"ham/1728" :TYPE HAM :CLASSIFICATION SPAM
:SCORE 0.684339162891261d0) (:FILE #p"ham/10581" :TYPE HAM
:CLASSIFICATION SPAM :SCORE 0.9999924537959615d0)) You can also use the
symbols returned by result-type as keys into a hash table or an alist.
For instance, you can write a function to print a summary of the counts
and percentages of each type of result using an alist that maps each
type plus the extra symbol total to a count.

   (defun analyze-results (results) (let* ((keys '(total correct
false-positive false-negative missed-ham missed-spam)) (counts (loop for
x in keys collect (cons x 0)))) (dolist (item results) (incf (cdr (assoc
'total counts))) (incf (cdr (assoc (result-type item) counts)))) (loop
with total = (cdr (assoc 'total counts)) for (label .  count) in counts
do (format t "~&~@(~a~):~20t~5d~,5t: ~6,2f%~%" label count (* 100 (/
count total)))))) This function will give output like this when passed a
list of results generated by test-classifier:

   SPAM> (analyze-results *results*) Total: 3761 : 100.00% Correct: 3689
: 98.09% False-positive: 4 : 0.11% False-negative: 9 : 0.24% Missed-ham:
19 : 0.51% Missed-spam: 40 : 1.06% NIL And as a last bit of analysis you
might want to look at why an individual message was classified the way
it was.  The following functions will show you:

   (defun explain-classification (file) (let* ((text (start-of-file file
*max-chars*)) (features (extract-features text)) (score (score
features)) (classification (classification score))) (show-summary file
text classification score) (dolist (feature (sorted-interesting
features)) (show-feature feature))))

   (defun show-summary (file text classification score) (format t "~&~a"
file) (format t "~2%~a~2%" text) (format t "Classified as ~a with score
of ~,5f~%" classification score))

   (defun show-feature (feature) (with-slots (word ham-count spam-count)
feature (format t "~&~2t~a~30thams: ~5d; spams: ~5d;~,10tprob: ~,f~%"
word ham-count spam-count (bayesian-spam-probability feature))))

   (defun sorted-interesting (features) (sort (remove-if #'untrained-p
features) #'< :key #'bayesian-spam-probability))


File: pcl.info,  Node: 23-10,  Next: Chapter 24,  Prev: 23-9,  Up: Chapter 23

What's Next
===========

Obviously, you could do a lot more with this code.  To turn it into a
real spam-filtering application, you'd need to find a way to integrate
it into your normal e-mail infrastructure.  One approach that would make
it easy to integrate with almost any e-mail client is to write a bit of
code to act as a POP3 proxy-that's the protocol most e-mail clients use
to fetch mail from mail servers.  Such a proxy would fetch mail from
your real POP3 server and serve it to your mail client after either
tagging spam with a header that your e-mail client's filters can easily
recognize or simply putting it aside.  Of course, you'd also need a way
to communicate with the filter about misclassifications-as long as
you're setting it up as a server, you could also provide a Web
interface.  I'll talk about how to write Web interfaces in Chapter 26,
and you'll build one, for a different application, in Chapter 29.

   Or you might want to work on improving the basic classification-a
likely place to start is to make extract-features more sophisticated.
In particular, you could make the tokenizer smarter about the internal
structure of e-mail-you could extract different kinds of features for
words appearing in the body versus the message headers.  And you could
decode various kinds of message encoding such as base 64 and quoted
printable since spammers often try to obfuscate their message with those
encodings.

   But I'll leave those improvements to you.  Now you're ready to head
down the path of building a streaming MP3 server, starting by writing a
general-purpose library for parsing binary files.


File: pcl.info,  Node: Chapter 24,  Next: Chapter 25,  Prev: Chapter 23,  Up: Top

24. Practical: Parsing Binary Files
===================================

In this chapter I'll show you how to build a library that you can use to
write code for reading and writing binary files.  You'll use this
library in Chapter 25 to write a parser for ID3 tags, the mechanism used
to store metadata such as artist and album names in MP3 files.  This
library is also an example of how to use macros to extend the language
with new constructs, turning it into a special-purpose language for
solving a particular problem, in this case reading and writing binary
data.  Because you'll develop the library a bit at a time, including
several partial versions, it may seem you're writing a lot of code.  But
when all is said and done, the whole library is fewer than 150 lines of
code, and the longest macro is only 20 lines long.

* Menu:

* 24-1::       Binary Files
* 24-2::       Binary Format Basics
* 24-3::       Strings in Binary Files
* 24-4::       Composite Structures
* 24-5::       Designing the Macros
* 24-6::       Making the Dream a Reality
* 24-7::       Reading Binary Objects
* 24-8::       Writing Binary Objects
* 24-9::       Adding Inheritance and Tagged Structures
* 24-10::      Keeping Track of Inherited Slots
* 24-11::      Tagged Structures
* 24-12::      Primitive Binary Types
* 24-13::      The Current Object Stack


File: pcl.info,  Node: 24-1,  Next: 24-2,  Prev: Chapter 24,  Up: Chapter 24

Binary Files
============

At a sufficiently low level of abstraction, all files are "binary" in
the sense that they just contain a bunch of numbers encoded in binary
form.  However, it's customary to distinguish between text files, where
all the numbers can be interpreted as characters representing
human-readable text, and binary files, which contain data that, if
interpreted as characters, yields nonprintable characters.1

   Binary file formats are usually designed to be both compact and
efficient to parse-that's their main advantage over text-based formats.
To meet both those criteria, they're usually composed of on-disk
structures that are easily mapped to data structures that a program
might use to represent the same data in memory.2

   The library will give you an easy way to define the mapping between
the on-disk structures defined by a binary file format and in-memory
Lisp objects.  Using the library, it should be easy to write a program
that can read a binary file, translating it into Lisp objects that you
can manipulate, and then write back out to another properly formatted
binary file.


File: pcl.info,  Node: 24-2,  Next: 24-3,  Prev: 24-1,  Up: Chapter 24

Binary Format Basics
====================

The starting point for reading and writing binary files is to open the
file for reading or writing individual bytes.  As I discussed in Chapter
14, both OPEN and WITH-OPEN-FILE accept a keyword argument,
:element-type, that controls the basic unit of transfer for the stream.
When you're dealing with binary files, you'll specify (unsigned-byte 8).
An input stream opened with such an :element-type will return an integer
between 0 and 255 each time it's passed to READ-BYTE. Conversely, you
can write bytes to an (unsigned-byte 8) output stream by passing numbers
between 0 and 255 to WRITE-BYTE.

   Above the level of individual bytes, most binary formats use a
smallish number of primitive data types-numbers encoded in various ways,
textual strings, bit fields, and so on-which are then composed into more
complex structures.  So your first task is to define a framework for
writing code to read and write the primitive data types used by a given
binary format.

   To take a simple example, suppose you're dealing with a binary format
that uses an unsigned 16-bit integer as a primitive data type.  To read
such an integer, you need to read the two bytes and then combine them
into a single number by multiplying one byte by 256, a.k.a.  2^8, and
adding it to the other byte.  For instance, assuming the binary format
specifies that such 16-bit quantities are stored in big-endian3 form,
with the most significant byte first, you can read such a number with
this function:

   (defun read-u2 (in) (+ (* (read-byte in) 256) (read-byte in)))
However, Common Lisp provides a more convenient way to perform this kind
of bit twiddling.  The function LDB, whose name stands for load byte,
can be used to extract and set (with SETF) any number of contiguous bits
from an integer.4 The number of bits and their position within the
integer is specified with a byte specifier created with the BYTE
function.  BYTE takes two arguments, the number of bits to extract (or
set) and the position of the rightmost bit where the least significant
bit is at position zero.  LDB takes a byte specifier and the integer
from which to extract the bits and returns the positive integer
represented by the extracted bits.  Thus, you can extract the least
significant octet of an integer like this:

   (ldb (byte 8 0) #xabcd) ==> 205 ; 205 is #xcd To get the next octet,
you'd use a byte specifier of (byte 8 8) like this:

   (ldb (byte 8 8) #xabcd) ==> 171 ; 171 is #xab You can use LDB with
SETF to set the specified bits of an integer stored in a SETFable place.

   CL-USER> (defvar *num* 0) *NUM* CL-USER> (setf (ldb (byte 8 0) *num*)
128) 128 CL-USER> *num* 128 CL-USER> (setf (ldb (byte 8 8) *num*) 255)
255 CL-USER> *num* 65408 Thus, you can also write read-u2 like this:5

   (defun read-u2 (in) (let ((u2 0)) (setf (ldb (byte 8 8) u2)
(read-byte in)) (setf (ldb (byte 8 0) u2) (read-byte in)) u2)) To write
a number out as a 16-bit integer, you need to extract the individual
8-bit bytes and write them one at a time.  To extract the individual
bytes, you just need to use LDB with the same byte specifiers.

   (defun write-u2 (out value) (write-byte (ldb (byte 8 8) value) out)
(write-byte (ldb (byte 8 0) value) out)) Of course, you can also encode
integers in many other ways-with different numbers of bytes, with
different endianness, and in signed and unsigned format.


File: pcl.info,  Node: 24-3,  Next: 24-4,  Prev: 24-2,  Up: Chapter 24

Strings in Binary Files
=======================

Textual strings are another kind of primitive data type you'll find in
many binary formats.  When you read files one byte at a time, you can't
read and write strings directly-you need to decode and encode them one
byte at a time, just as you do with binary-encoded numbers.  And just as
you can encode an integer in several ways, you can encode a string in
many ways.  To start with, the binary format must specify how individual
characters are encoded.

   To translate bytes to characters, you need to know both what
character code and what character encoding you're using.  A character
code defines a mapping from positive integers to characters.  Each
number in the mapping is called a code point.  For instance, ASCII is a
character code that maps the numbers from 0-127 to particular characters
used in the Latin alphabet.  A character encoding, on the other hand,
defines how the code points are represented as a sequence of bytes in a
byte-oriented medium such as a file.  For codes that use eight or fewer
bits, such as ASCII and ISO-8859-1, the encoding is trivial-each numeric
value is encoded as a single byte.

   Nearly as straightforward are pure double-byte encodings, such as
UCS-2, which map between 16-bit values and characters.  The only reason
double-byte encodings can be more complex than single-byte encodings is
that you may also need to know whether the 16-bit values are supposed to
be encoded in big-endian or little-endian format.

   Variable-width encodings use different numbers of octets for
different numeric values, making them more complex but allowing them to
be more compact in many cases.  For instance, UTF-8, an encoding
designed for use with the Unicode character code, uses a single octet to
encode the values 0-127 while using up to four octets to encode values
up to 1,114,111.6

   Since the code points from 0-127 map to the same characters in
Unicode as they do in ASCII, a UTF-8 encoding of text consisting only of
characters also in ASCII is the same as the ASCII encoding.  On the
other hand, texts consisting mostly of characters requiring four bytes
in UTF-8 could be more compactly encoded in a straight double-byte
encoding.

   Common Lisp provides two functions for translating between numeric
character codes and character objects: CODE-CHAR, which takes an numeric
code and returns as a character, and CHAR-CODE, which takes a character
and returns its numeric code.  The language standard doesn't specify
what character encoding an implementation must use, so there's no
guarantee you can represent every character that can possibly be encoded
in a given file format as a Lisp character.  However, almost all
contemporary Common Lisp implementations use ASCII, ISO-8859-1, or
Unicode as their native character code.  Because Unicode is a superset
ofISO-8859-1, which is in turn a superset of ASCII, if you're using a
Unicode Lisp, CODE-CHAR and CHAR-CODE can be used directly for
translating any of those three character codes.7

   In addition to specifying a character encoding, a string encoding
must also specify how to encode the length of the string.  Three
techniques are typically used in binary file formats.

   The simplest is to not encode it but to let it be implicit in the
position of the string in some larger structure: a particular element of
a file may always be a string of a certain length, or a string may be
the last element of a variable-length data structure whose overall size
determines how many bytes are left to read as string data.  Both these
techniques are used in ID3 tags, as you'll see in the next chapter.

   The other two techniques can be used to encode variable-length
strings without relying on context.  One is to encode the length of the
string followed by the character data-the parser reads an integer value
(in some specified integer format) and then reads that number of
characters.  Another is to write the character data followed by a
delimiter that can't appear in the string such as a null character.

   The different representations have different advantages and
disadvantages, but when you're dealing with already specified binary
formats, you won't have any control over which encoding is used.
However, none of the encodings is particularly more difficult to read
and write than any other.  Here, as an example, is a function that reads
a null-terminated ASCII string, assuming your Lisp implementation uses
ASCII or one of its supersets such as ISO-8859-1 or full Unicode as its
native character encoding:

   (defconstant +null+ (code-char 0))

   (defun read-null-terminated-ascii (in) (with-output-to-string (s)
(loop for char = (code-char (read-byte in)) until (char= char +null+) do
(write-char char s)))) The WITH-OUTPUT-TO-STRING macro, which I
mentioned in Chapter 14, is an easy way to build up a string when you
don't know how long it'll be.  It creates a STRING-STREAM and binds it
to the variable name specified, s in this case.  All characters written
to the stream are collected into a string, which is then returned as the
value of the WITH-OUTPUT-TO-STRING form.

   To write a string back out, you just need to translate the characters
back to numeric values that can be written with WRITE-BYTE and then
write the null terminator after the string contents.

   (defun write-null-terminated-ascii (string out) (loop for char across
string do (write-byte (char-code char) out)) (write-byte (char-code
+null+) out)) As these examples show, the main intellectual
challenge-such as it is-of reading and writing primitive elements of
binary files is understanding how exactly to interpret the bytes that
appear in a file and to map them to Lisp data types.  If a binary file
format is well specified, this should be a straightforward proposition.
Actually writing functions to read and write a particular encoding is,
as they say, a simple matter of programming.

   Now you can turn to the issue of reading and writing more complex
on-disk structures and how to map them to Lisp objects.


File: pcl.info,  Node: 24-4,  Next: 24-5,  Prev: 24-3,  Up: Chapter 24

Composite Structures
====================

Since binary formats are usually used to represent data in a way that
makes it easy to map to in-memory data structures, it should come as no
surprise that composite on-disk structures are usually defined in ways
similar to the way programming languages define in-memory structures.
Usually a composite on-disk structure will consist of a number of named
parts, each of which is itself either a primitive type such as a number
or a string, another composite structure, or possibly a collection of
such values.

   For instance, an ID3 tag defined in the 2.2 version of the
specification consists of a header made up of a three-character
ISO-8859-1 string, which is always "ID3"; two one-byte unsigned integers
that specify the major version and revision of the specification; eight
bits worth of boolean flags; and four bytes that encode the size of the
tag in an encoding particular to the ID3 specification.  Following the
header is a list of frames, each of which has its own internal
structure.  After the frames are as many null bytes as are necessary to
pad the tag out to the size specified in the header.

   If you look at the world through the lens of object orientation,
composite structures look a lot like classes.  For instance, you could
write a class to represent an ID3 tag.

   (defclass id3-tag () ((identifier :initarg :identifier :accessor
identifier) (major-version :initarg :major-version :accessor
major-version) (revision :initarg :revision :accessor revision) (flags
:initarg :flags :accessor flags) (size :initarg :size :accessor size)
(frames :initarg :frames :accessor frames))) An instance of this class
would make a perfect repository to hold the data needed to represent an
ID3 tag.  You could then write functions to read and write instances of
this class.  For example, assuming the existence of certain other
functions for reading the appropriate primitive data types, a
read-id3-tag function might look like this:

   (defun read-id3-tag (in) (let ((tag (make-instance 'id3-tag)))
(with-slots (identifier major-version revision flags size frames) tag
(setf identifier (read-iso-8859-1-string in :length 3)) (setf
major-version (read-u1 in)) (setf revision (read-u1 in)) (setf flags
(read-u1 in)) (setf size (read-id3-encoded-size in)) (setf frames
(read-id3-frames in :tag-size size))) tag)) The write-id3-tag function
would be structured similarly-you'd use the appropriate write-*
functions to write out the values stored in the slots of the id3-tag
object.

   It's not hard to see how you could write the appropriate classes to
represent all the composite data structures in a specification along
with read-foo and write-foo functions for each class and for necessary
primitive types.  But it's also easy to tell that all the reading and
writing functions are going to be pretty similar, differing only in the
specifics of what types they read and the names of the slots they store
them in.  It's particularly irksome when you consider that in the ID3
specification it takes about four lines of text to specify the structure
of an ID3 tag, while you've already written eighteen lines of code and
haven't even written write-id3-tag yet.

   What you'd really like is a way to describe the structure of
something like an ID3 tag in a form that's as compressed as the
specification's pseudocode yet that can also be expanded into code that
defines the id3-tag class and the functions that translate between bytes
on disk and instances of the class.  Sounds like a job for a macro.


File: pcl.info,  Node: 24-5,  Next: 24-6,  Prev: 24-4,  Up: Chapter 24

Designing the Macros
====================

Since you already have a rough idea what code your macros will need to
generate, the next step, according to the process for writing a macro I
outlined in Chapter 8, is to switch perspectives and think about what a
call to the macro should look like.  Since the goal is to be able to
write something as compressed as the pseudocode in the ID3
specification, you can start there.  The header of an ID3 tag is
specified like this:

   ID3/file identifier "ID3" ID3 version $02 00 ID3 flags %xx000000 ID3
size 4 * %0xxxxxxx In the notation of the specification, this means the
"file identifier" slot of an ID3 tag is the string "ID3" in ISO-8859-1
encoding.  The version consists of two bytes, the first of which-for
this version of the specification-has the value 2 and the second of
which-again for this version of the specification-is 0.  The flags slot
is eight bits, of which all but the first two are 0, and the size
consists of four bytes, each of which has a 0 in the most significant
bit.

   Some information isn't captured by this pseudocode.  For instance,
exactly how the four bytes that encode the size are to be interpreted is
described in a few lines of prose.  Likewise, the spec describes in
prose how the frame and subsequent padding is stored after this header.
But most of what you need to know to be able to write code to read and
write an ID3 tag is specified by this pseudocode.  Thus, you ought to be
able to write an s-expression version of this pseudocode and have it
expanded into the class and function definitions you'd otherwise have to
write by hand-something, perhaps, like this:

   (define-binary-class id3-tag ((file-identifier (iso-8859-1-string
:length 3)) (major-version u1) (revision u1) (flags u1) (size
id3-tag-size) (frames (id3-frames :tag-size size)))) The basic idea is
that this form defines a class id3-tag similar to the way you could with
DEFCLASS, but instead of specifying things such as :initarg and
:accessors, each slot specification consists of the name of the
slot-file-identifier, major-version, and so on-and information about how
that slot is represented on disk.  Since this is just a bit of
fantasizing, you don't have to worry about exactly how the macro
define-binary-class will know what to do with expressions such as
(iso-8859-1-string :length 3), u1, id3-tag-size, and (id3-frames
:tag-size size); as long as each expression contains the information
necessary to know how to read and write a particular data encoding, you
should be okay.


File: pcl.info,  Node: 24-6,  Next: 24-7,  Prev: 24-5,  Up: Chapter 24

Making the Dream a Reality
==========================

Okay, enough fantasizing about good-looking code; now you need to get to
work writing define-binary-class-writing the code that will turn that
concise expression of what an ID3 tag looks like into code that can
represent one in memory, read one off disk, and write it back out.

   To start with, you should define a package for this library.  Here's
the package file that comes with the version you can download from the
book's Web site:

   (in-package :cl-user)

   (defpackage :com.gigamonkeys.binary-data (:use :common-lisp
:com.gigamonkeys.macro-utilities) (:export :define-binary-class
:define-tagged-binary-class :define-binary-type :read-value :write-value
:*in-progress-objects* :parent-of-type :current-binary-object :+null+))
The COM.GIGAMONKEYS.MACRO-UTILITIES package contains the with-gensyms
and once-only macros from Chapter 8.

   Since you already have a handwritten version of the code you want to
generate, it shouldn't be too hard to write such a macro.  Just take it
in small pieces, starting with a version of define-binary-class that
generates just the DEFCLASS form.

   If you look back at the define-binary-class form, you'll see that it
takes two arguments, the name id3-tag and a list of slot specifiers,
each of which is itself a two-item list.  From those pieces you need to
build the appropriate DEFCLASS form.  Clearly, the biggest difference
between the define-binary-class form and a proper DEFCLASS form is in
the slot specifiers.  A single slot specifier from define-binary-class
looks something like this:

   (major-version u1) But that's not a legal slot specifier for a
DEFCLASS. Instead, you need something like this:

   (major-version :initarg :major-version :accessor major-version) Easy
enough.  First define a simple function to translate a symbol to the
corresponding keyword symbol.

   (defun as-keyword (sym) (intern (string sym) :keyword)) Now define a
function that takes a define-binary-class slot specifier and returns a
DEFCLASS slot specifier.

   (defun slot->defclass-slot (spec) (let ((name (first spec))) '(,name
:initarg ,(as-keyword name) :accessor ,name))) You can test this
function at the REPL after switching to your new package with a call to
IN-PACKAGE.

   BINARY-DATA> (slot->defclass-slot '(major-version u1)) (MAJOR-VERSION
:INITARG :MAJOR-VERSION :ACCESSOR MAJOR-VERSION) Looks good.  Now the
first version of define-binary-class is trivial.

   (defmacro define-binary-class (name slots) '(defclass ,name ()
,(mapcar #'slot->defclass-slot slots))) This is simple template-style
macro-define-binary-class generates a DEFCLASS form by interpolating the
name of the class and a list of slot specifiers constructed by applying
slot->defclass-slot to each element of the list of slots specifiers from
the define-binary-class form.

   To see exactly what code this macro generates, you can evaluate this
expression at the REPL.

   (macroexpand-1 '(define-binary-class id3-tag ((identifier
(iso-8859-1-string :length 3)) (major-version u1) (revision u1) (flags
u1) (size id3-tag-size) (frames (id3-frames :tag-size size))))) The
result, slightly reformatted here for better readability, should look
familiar since it's exactly the class definition you wrote by hand
earlier:

   (defclass id3-tag () ((identifier :initarg :identifier :accessor
identifier) (major-version :initarg :major-version :accessor
major-version) (revision :initarg :revision :accessor revision) (flags
:initarg :flags :accessor flags) (size :initarg :size :accessor size)
(frames :initarg :frames :accessor frames)))


File: pcl.info,  Node: 24-7,  Next: 24-8,  Prev: 24-6,  Up: Chapter 24

Reading Binary Objects
======================

Next you need to make define-binary-class also generate a function that
can read an instance of the new class.  Looking back at the read-id3-tag
function you wrote before, this seems a bit trickier, as the
read-id3-tag wasn't quite so regular-to read each slot's value, you had
to call a different function.  Not to mention, the name of the function,
read-id3-tag, while derived from the name of the class you're defining,
isn't one of the arguments to define-binary-class and thus isn't
available to be interpolated into a template the way the class name was.

   You could deal with both of those problems by devising and following
a naming convention so the macro can figure out the name of the function
to call based on the name of the type in the slot specifier.  However,
this would require define-binary-class to generate the name
read-id3-tag, which is possible but a bad idea.  Macros that create
global definitions should generally use only names passed to them by
their callers; macros that generate names under the covers can cause
hard-to-predict-and hard-to-debug-name conflicts when the generated
names happen to be the same as names used elsewhere.8

   You can avoid both these inconveniences by noticing that all the
functions that read a particular type of value have the same fundamental
purpose, to read a value of a specific type from a stream.  Speaking
colloquially, you might say they're all instances of a single generic
operation.  And the colloquial use of the word generic should lead you
directly to the solution to your problem: instead of defining a bunch of
independent functions, all with different names, you can define a single
generic function, read-value, with methods specialized to read different
types of values.

   That is, instead of defining functions read-iso-8859-1-string and
read-u1, you can define read-value as a generic function taking two
required arguments, a type and a stream, and possibly some keyword
arguments.

   (defgeneric read-value (type stream &key) (:documentation "Read a
value of the given type from the stream."))  By specifying &key without
any actual keyword parameters, you allow different methods to define
their own &key parameters without requiring them to do so.  This does
mean every method specialized on read-value will have to include either
&key or an &rest parameter in its parameter list to be compatible with
the generic function.

   Then you'll define methods that use EQL specializers to specialize
the type argument on the name of the type you want to read.

   (defmethod read-value ((type (eql 'iso-8859-1-string)) in &key
length) ...)

   (defmethod read-value ((type (eql 'u1)) in &key) ...)  Then you can
make define-binary-class generate a read-value method specialized on the
type name id3-tag, and that method can be implemented in terms of calls
to read-value with the appropriate slot types as the first argument.
The code you want to generate is going to look like this:

   (defmethod read-value ((type (eql 'id3-tag)) in &key) (let ((object
(make-instance 'id3-tag))) (with-slots (identifier major-version
revision flags size frames) object (setf identifier (read-value
'iso-8859-1-string in :length 3)) (setf major-version (read-value 'u1
in)) (setf revision (read-value 'u1 in)) (setf flags (read-value 'u1
in)) (setf size (read-value 'id3-encoded-size in)) (setf frames
(read-value 'id3-frames in :tag-size size))) object)) So, just as you
needed a function to translate a define-binary-class slot specifier to a
DEFCLASS slot specifier in order to generate the DEFCLASS form, now you
need a function that takes a define-binary-class slot specifier and
generates the appropriate SETF form, that is, something that takes this:

   (identifier (iso-8859-1-string :length 3)) and returns this:

   (setf identifier (read-value 'iso-8859-1-string in :length 3))
However, there's a difference between this code and the DEFCLASS slot
specifier: it includes a reference to a variable in-the method parameter
from the read-value method-that wasn't derived from the slot specifier.
It doesn't have to be called in, but whatever name you use has to be the
same as the one used in the method's parameter list and in the other
calls to read-value.  For now you can dodge the issue of where that name
comes from by defining slot->read-value to take a second argument of the
name of the stream variable.

   (defun slot->read-value (spec stream) (destructuring-bind (name (type
&rest args)) (normalize-slot-spec spec) '(setf ,name (read-value ',type
,stream ,@args)))) The function normalize-slot-spec normalizes the
second element of the slot specifier, converting a symbol like u1 to the
list (u1) so the DESTRUCTURING-BIND can parse it.  It looks like this:

   (defun normalize-slot-spec (spec) (list (first spec) (mklist (second
spec))))

   (defun mklist (x) (if (listp x) x (list x))) You can test
slot->read-value with each type of slot specifier.

   BINARY-DATA> (slot->read-value '(major-version u1) 'stream) (SETF
MAJOR-VERSION (READ-VALUE 'U1 STREAM)) BINARY-DATA> (slot->read-value
'(identifier (iso-8859-1-string :length 3)) 'stream) (SETF IDENTIFIER
(READ-VALUE 'ISO-8859-1-STRING STREAM :LENGTH 3)) With these functions
you're ready to add read-value to define-binary-class.  If you take the
handwritten read-value method and strip out anything that's tied to a
particular class, you're left with this skeleton:

   (defmethod read-value ((type (eql ...))  stream &key) (let ((object
(make-instance ...)))  (with-slots (...)  object ...  object))) All you
need to do is add this skeleton to the define-binary-class template,
replacing ellipses with code that fills in the skeleton with the
appropriate names and code.  You'll also want to replace the variables
type, stream, and object with gensymed names to avoid potential
conflicts with slot names,9 which you can do with the with-gensyms macro
from Chapter 8.

   Also, because a macro must expand into a single form, you need to
wrap some form around the DEFCLASS and DEFMETHOD. PROGN is the customary
form to use for macros that expand into multiple definitions because of
the special treatment it gets from the file compiler when appearing at
the top level of a file, as I discussed in Chapter 20.

   So, you can change define-binary-class as follows:

   (defmacro define-binary-class (name slots) (with-gensyms (typevar
objectvar streamvar) '(progn (defclass ,name () ,(mapcar
#'slot->defclass-slot slots))

   (defmethod read-value ((,typevar (eql ',name)) ,streamvar &key) (let
((,objectvar (make-instance ',name))) (with-slots ,(mapcar #'first
slots) ,objectvar ,@(mapcar #'(lambda (x) (slot->read-value x
streamvar)) slots)) ,objectvar)))))


File: pcl.info,  Node: 24-8,  Next: 24-9,  Prev: 24-7,  Up: Chapter 24

Writing Binary Objects
======================

Generating code to write out an instance of a binary class will proceed
similarly.  First you can define a write-value generic function.

   (defgeneric write-value (type stream value &key) (:documentation
"Write a value as the given type to the stream."))  Then you define a
helper function that translates a define-binary-class slot specifier
into code that writes out the slot using write-value.  As with the
slot->read-value function, this helper function needs to take the name
of the stream variable as an argument.

   (defun slot->write-value (spec stream) (destructuring-bind (name
(type &rest args)) (normalize-slot-spec spec) '(write-value ',type
,stream ,name ,@args))) Now you can add a write-value template to the
define-binary-class macro.

   (defmacro define-binary-class (name slots) (with-gensyms (typevar
objectvar streamvar) '(progn (defclass ,name () ,(mapcar
#'slot->defclass-slot slots))

   (defmethod read-value ((,typevar (eql ',name)) ,streamvar &key) (let
((,objectvar (make-instance ',name))) (with-slots ,(mapcar #'first
slots) ,objectvar ,@(mapcar #'(lambda (x) (slot->read-value x
streamvar)) slots)) ,objectvar))

   (defmethod write-value ((,typevar (eql ',name)) ,streamvar ,objectvar
&key) (with-slots ,(mapcar #'first slots) ,objectvar ,@(mapcar #'(lambda
(x) (slot->write-value x streamvar)) slots))))))


File: pcl.info,  Node: 24-9,  Next: 24-10,  Prev: 24-8,  Up: Chapter 24

Adding Inheritance and Tagged Structures
========================================

While this version of define-binary-class will handle stand-alone
structures, binary file formats often define on-disk structures that
would be natural to model with subclasses and superclasses.  So you
might want to extend define-binary-class to support inheritance.

   A related technique used in many binary formats is to have several
on-disk structures whose exact type can be determined only by reading
some data that indicates how to parse the following bytes.  For
instance, the frames that make up the bulk of an ID3 tag all share a
common header structure consisting of a string identifier and a length.
To read a frame, you need to read the identifier and use its value to
determine what kind of frame you're looking at and thus how to parse the
body of the frame.

   The current define-binary-class macro has no way to handle this kind
of reading-you could use define-binary-class to define a class to
represent each kind of frame, but you'd have no way to know what type of
frame to read without reading at least the identifier.  And if other
code reads the identifier in order to determine what type to pass to
read-value, then that will break read-value since it's expecting to read
all the data that makes up the instance of the class it instantiates.

   You can solve this problem by adding inheritance to
define-binary-class and then writing another macro,
define-tagged-binary-class, for defining "abstract" classes that aren't
instantiated directly but that can be specialized on by read-value
methods that know how to read enough data to determine what kind of
class to create.

   The first step to adding inheritance to define-binary-class is to add
a parameter to the macro to accept a list of superclasses.

   (defmacro define-binary-class (name (&rest superclasses) slots) ...
Then, in the DEFCLASS template, interpolate that value instead of the
empty list.

   (defclass ,name ,superclasses ...)  However, there's a bit more to it
than that.  You also need to change the read-value and write-value
methods so the methods generated when defining a superclass can be used
by the methods generated as part of a subclass to read and write
inherited slots.

   The current way read-value works is particularly problematic since it
instantiates the object before filling it in-obviously, you can't have
the method responsible for reading the superclass's fields instantiate
one object while the subclass's method instantiates and fills in a
different object.

   You can fix that problem by splitting read-value into two parts-one
responsible for instantiating the correct kind of object and another
responsible for filling slots in an existing object.  On the writing
side it's a bit simpler, but you can use the same technique.

   So you'll define two new generic functions, read-object and
write-object, that will both take an existing object and a stream.
Methods on these generic functions will be responsible for reading or
writing the slots specific to the class of the object on which they're
specialized.

   (defgeneric read-object (object stream) (:method-combination progn
:most-specific-last) (:documentation "Fill in the slots of object from
stream."))

   (defgeneric write-object (object stream) (:method-combination progn
:most-specific-last) (:documentation "Write out the slots of object to
the stream."))  Defining these generic functions to use the PROGN method
combination with the option :most-specific-last allows you to define
methods that specialize object on each binary class and have them deal
only with the slots actually defined in that class; the PROGN method
combination will combine all the applicable methods so the method
specialized on the least specific class in the hierarchy runs first,
reading or writing the slots defined in that class, then the method
specialized on next least specific subclass, and so on.  And since all
the heavy lifting for a specific class is now going to be done by
read-object and write-object, you don't even need to define specialized
read-value and write-value methods; you can define default methods that
assume the type argument is the name of a binary class.

   (defmethod read-value ((type symbol) stream &key) (let ((object
(make-instance type))) (read-object object stream) object))

   (defmethod write-value ((type symbol) stream value &key) (assert
(typep value type)) (write-object value stream)) Note how you can use
MAKE-INSTANCE as a generic object factory-while you normally call
MAKE-INSTANCE with a quoted symbol as the first argument because you
normally know exactly what class you want to instantiate, you can use
any expression that evaluates to a class name such as, in this case, the
type parameter in the read-value method.

   The actual changes to define-binary-class to define methods on
read-object and write-object rather than read-value and write-value are
fairly minor.

   (defmacro define-binary-class (name superclasses slots) (with-gensyms
(objectvar streamvar) '(progn (defclass ,name ,superclasses ,(mapcar
#'slot->defclass-slot slots))

   (defmethod read-object progn ((,objectvar ,name) ,streamvar)
(with-slots ,(mapcar #'first slots) ,objectvar ,@(mapcar #'(lambda (x)
(slot->read-value x streamvar)) slots)))

   (defmethod write-object progn ((,objectvar ,name) ,streamvar)
(with-slots ,(mapcar #'first slots) ,objectvar ,@(mapcar #'(lambda (x)
(slot->write-value x streamvar)) slots))))))


File: pcl.info,  Node: 24-10,  Next: 24-11,  Prev: 24-9,  Up: Chapter 24

Keeping Track of Inherited Slots
================================

This definition will work for many purposes.  However, it doesn't handle
one fairly common situation, namely, when you have a subclass that needs
to refer to inherited slots in its own slot specifications.  For
instance, with the current definition of define-binary-class, you can
define a single class like this:

   (define-binary-class generic-frame () ((id (iso-8859-1-string :length
3)) (size u3) (data (raw-bytes :bytes size)))) The reference to size in
the specification of data works the way you'd expect because the
expressions that read and write the data slot are wrapped in a
WITH-SLOTS that lists all the object's slots.  However, if you try to
split that class into two classes like this:

   (define-binary-class frame () ((id (iso-8859-1-string :length 3))
(size u3)))

   (define-binary-class generic-frame (frame) ((data (raw-bytes :bytes
size)))) you'll get a compile-time warning when you compile the
generic-frame definition and a runtime error when you try to use it
because there will be no lexically apparent variable size in the
read-object and write-object methods specialized on generic-frame.

   What you need to do is keep track of the slots defined by each binary
class and then include inherited slots in the WITH-SLOTS forms in the
read-object and write-object methods.

   The easiest way to keep track of information like this is to hang it
off the symbol that names the class.  As I discussed in Chapter 21,
every symbol object has an associated property list, which can be
accessed via the functions SYMBOL-PLIST and GET. You can associate
arbitrary key/value pairs with a symbol by adding them to its property
list with SETF of GET. For instance, if the binary class foo defines
three slots-x, y, and z-you can keep track of that fact by adding a
slots key to the symbol foo's property list with the value (x y z) with
this expression:

   (setf (get 'foo 'slots) '(x y z)) You want this bookkeeping to happen
as part of evaluating the define-binary-class of foo.  However, it's not
clear where to put the expression.  If you evaluate it when you compute
the macro's expansion, it'll get evaluated when you compile the
define-binary-class form but not if you later load a file that contains
the resulting compiled code.  On the other hand, if you include the
expression in the expansion, then it won't be evaluated during
compilation, which means if you compile a file with several
define-binary-class forms, none of the information about what classes
define what slots will be available until the whole file is loaded,
which is too late.

   This is what the special operator EVAL-WHEN I discussed in Chapter 20
is for.  By wrapping a form in an EVAL-WHEN, you can control whether
it's evaluated at compile time, when the compiled code is loaded, or
both.  For cases like this where you want to squirrel away some
information during the compilation of a macro form that you also want to
be available after the compiled form is loaded, you should wrap it in an
EVAL-WHEN like this:

   (eval-when (:compile-toplevel :load-toplevel :execute) (setf (get
'foo 'slots) '(x y z))) and include the EVAL-WHEN in the expansion
generated by the macro.  Thus, you can save both the slots and the
direct superclasses of a binary class by adding this form to the
expansion generated by define-binary-class:

   (eval-when (:compile-toplevel :load-toplevel :execute) (setf (get
',name 'slots) ',(mapcar #'first slots)) (setf (get ',name
'superclasses) ',superclasses)) Now you can define three helper
functions for accessing this information.  The first simply returns the
slots directly defined by a binary class.  It's a good idea to return a
copy of the list since you don't want other code to modify the list of
slots after the binary class has been defined.

   (defun direct-slots (name) (copy-list (get name 'slots))) The next
function returns the slots inherited from other binary classes.

   (defun inherited-slots (name) (loop for super in (get name
'superclasses) nconc (direct-slots super) nconc (inherited-slots
super))) Finally, you can define a function that returns a list
containing the names of all directly defined and inherited slots.

   (defun all-slots (name) (nconc (direct-slots name) (inherited-slots
name))) When you're computing the expansion of a
define-generic-binary-class form, you want to generate a WITH-SLOTS form
that contains the names of all the slots defined in the new class and
all its superclasses.  However, you can't use all-slots while you're
generating the expansion since the information won't be available until
after the expansion is compiled.  Instead, you should use the following
function, which takes the list of slot specifiers and superclasses
passed to define-generic-binary-class and uses them to compute the list
of all the new class's slots:

   (defun new-class-all-slots (slots superclasses) (nconc (mapcan
#'all-slots superclasses) (mapcar #'first slots))) With these functions
defined, you can change define-binary-class to store the information
about the class currently being defined and to use the already stored
information about the superclasses' slots to generate the WITH-SLOTS
forms you want like this:

   (defmacro define-binary-class (name (&rest superclasses) slots)
(with-gensyms (objectvar streamvar) '(progn (eval-when
(:compile-toplevel :load-toplevel :execute) (setf (get ',name 'slots)
',(mapcar #'first slots)) (setf (get ',name 'superclasses)
',superclasses))

   (defclass ,name ,superclasses ,(mapcar #'slot->defclass-slot slots))

   (defmethod read-object progn ((,objectvar ,name) ,streamvar)
(with-slots ,(new-class-all-slots slots superclasses) ,objectvar
,@(mapcar #'(lambda (x) (slot->read-value x streamvar)) slots)))

   (defmethod write-object progn ((,objectvar ,name) ,streamvar)
(with-slots ,(new-class-all-slots slots superclasses) ,objectvar
,@(mapcar #'(lambda (x) (slot->write-value x streamvar)) slots))))))


File: pcl.info,  Node: 24-11,  Next: 24-12,  Prev: 24-10,  Up: Chapter 24

Tagged Structures
=================

With the ability to define binary classes that extend other binary
classes, you're ready to define a new macro for defining classes to
represent "tagged" structures.  The strategy for reading tagged
structures will be to define a specialized read-value method that knows
how to read the values that make up the start of the structure and then
use those values to determine what subclass to instantiate.  It'll then
make an instance of that class with MAKE-INSTANCE, passing the already
read values as initargs, and pass the object to read-object, allowing
the actual class of the object to determine how the rest of the
structure is read.

   The new macro, define-tagged-binary-class, will look like
define-binary-class with the addition of a :dispatch option used to
specify a form that should evaluate to the name of a binary class.  The
:dispatch form will be evaluated in a context where the names of the
slots defined by the tagged class are bound to variables that hold the
values read from the file.  The class whose name it returns must accept
initargs corresponding to the slot names defined by the tagged class.
This is easily ensured if the :dispatch form always evaluates to the
name of a class that subclasses the tagged class.

   For instance, supposing you have a function, find-frame-class, that
will map a string identifier to a binary class representing a particular
kind of ID3 frame, you might define a tagged binary class, id3-frame,
like this:

   (define-tagged-binary-class id3-frame () ((id (iso-8859-1-string
:length 3)) (size u3)) (:dispatch (find-frame-class id))) The expansion
of a define-tagged-binary-class will contain a DEFCLASS and a
write-object method just like the expansion of define-binary-class, but
instead of a read-object method it'll contain a read-value method that
looks like this:

   (defmethod read-value ((type (eql 'id3-frame)) stream &key) (let ((id
(read-value 'iso-8859-1-string stream :length 3)) (size (read-value 'u3
stream))) (let ((object (make-instance (find-frame-class id) :id id
:size size))) (read-object object stream) object))) Since the expansions
of define-tagged-binary-class and define-binary-class are going to be
identical except for the read method, you can factor out the common bits
into a helper macro, define-generic-binary-class, that accepts the read
method as a parameter and interpolates it.

   (defmacro define-generic-binary-class (name (&rest superclasses)
slots read-method) (with-gensyms (objectvar streamvar) '(progn
(eval-when (:compile-toplevel :load-toplevel :execute) (setf (get ',name
'slots) ',(mapcar #'first slots)) (setf (get ',name 'superclasses)
',superclasses))

   (defclass ,name ,superclasses ,(mapcar #'slot->defclass-slot slots))

   ,read-method

   (defmethod write-object progn ((,objectvar ,name) ,streamvar)
(declare (ignorable ,streamvar)) (with-slots ,(new-class-all-slots slots
superclasses) ,objectvar ,@(mapcar #'(lambda (x) (slot->write-value x
streamvar)) slots)))))) Now you can define both define-binary-class and
define-tagged-binary-class to expand into a call to
define-generic-binary-class.  Here's a new version of
define-binary-class that generates the same code as the earlier version
when it's fully expanded:

   (defmacro define-binary-class (name (&rest superclasses) slots)
(with-gensyms (objectvar streamvar) '(define-generic-binary-class ,name
,superclasses ,slots (defmethod read-object progn ((,objectvar ,name)
,streamvar) (declare (ignorable ,streamvar)) (with-slots
,(new-class-all-slots slots superclasses) ,objectvar ,@(mapcar #'(lambda
(x) (slot->read-value x streamvar)) slots)))))) And here's
define-tagged-binary-class along with two new helper functions it uses:

   (defmacro define-tagged-binary-class (name (&rest superclasses) slots
&rest options) (with-gensyms (typevar objectvar streamvar)
'(define-generic-binary-class ,name ,superclasses ,slots (defmethod
read-value ((,typevar (eql ',name)) ,streamvar &key) (let* ,(mapcar
#'(lambda (x) (slot->binding x streamvar)) slots) (let ((,objectvar
(make-instance ,@(or (cdr (assoc :dispatch options)) (error "Must supply
:dispatch form."))  ,@(mapcan #'slot->keyword-arg slots)))) (read-object
,objectvar ,streamvar) ,objectvar))))))

   (defun slot->binding (spec stream) (destructuring-bind (name (type
&rest args)) (normalize-slot-spec spec) '(,name (read-value ',type
,stream ,@args))))

   (defun slot->keyword-arg (spec) (let ((name (first spec)))
'(,(as-keyword name) ,name)))


File: pcl.info,  Node: 24-12,  Next: 24-13,  Prev: 24-11,  Up: Chapter 24

Primitive Binary Types
======================

While define-binary-class and define-tagged-binary-class make it easy to
define composite structures, you still have to write read-value and
write-value methods for primitive data types by hand.  You could decide
to live with that, specifying that users of the library need to write
appropriate methods on read-value and write-value to support the
primitive types used by their binary classes.

   However, rather than having to document how to write a suitable
read-value/write-value pair, you can provide a macro to do it
automatically.  This also has the advantage of making the abstraction
created by define-binary-class less leaky.  Currently,
define-binary-class depends on having methods on read-value and
write-value defined in a particular way, but that's really just an
implementation detail.  By defining a macro that generates the
read-value and write-value methods for primitive types, you hide those
details behind an abstraction you control.  If you decide later to
change the implementation of define-binary-class, you can change your
primitive-type-defining macro to meet the new requirements without
requiring any changes to code that uses the binary data library.

   So you should define one last macro, define-binary-type, that will
generate read-value and write-value methods for reading values
represented by instances of existing classes, rather than by classes
defined with define-binary-class.

   For a concrete example, consider a type used in the id3-tag class, a
fixed-length string encoded in ISO-8859-1 characters.  I'll assume, as I
did earlier, that the native character encoding of your Lisp is
ISO-8859-1 or a superset, so you can use CODE-CHAR and CHAR-CODE to
translate bytes to characters and back.

   As always, your goal is to write a macro that allows you to express
only the essential information needed to generate the required code.  In
this case, there are four pieces of essential information: the name of
the type, iso-8859-1-string; the &key parameters that should be accepted
by the read-value and write-value methods, length in this case; the code
for reading from a stream; and the code for writing to a stream.  Here's
an expression that contains those four pieces of information:

   (define-binary-type iso-8859-1-string (length) (:reader (in) (let
((string (make-string length))) (dotimes (i length) (setf (char string
i) (code-char (read-byte in)))) string)) (:writer (out string) (dotimes
(i length) (write-byte (char-code (char string i)) out)))) Now you just
need a macro that can take apart this form and put it back together in
the form of two DEFMETHODs wrapped in a PROGN. If you define the
parameter list to define-binary-type like this:

   (defmacro define-binary-type (name (&rest args) &body spec) ...  then
within the macro the parameter spec will be a list containing the reader
and writer definitions.  You can then use ASSOC to extract the elements
of spec using the tags :reader and :writer and then use
DESTRUCTURING-BIND to take apart the REST of each element.10

   From there it's just a matter of interpolating the extracted values
into the backquoted templates of the read-value and write-value methods.

   (defmacro define-binary-type (name (&rest args) &body spec)
(with-gensyms (type) '(progn ,(destructuring-bind ((in) &body body)
(rest (assoc :reader spec)) '(defmethod read-value ((,type (eql ',name))
,in &key ,@args) ,@body)) ,(destructuring-bind ((out value) &body body)
(rest (assoc :writer spec)) '(defmethod write-value ((,type (eql
',name)) ,out ,value &key ,@args) ,@body))))) Note how the backquoted
templates are nested: the outermost template starts with the backquoted
PROGN form.  That template consists of the symbol PROGN and two
comma-unquoted DESTRUCTURING-BIND expressions.  Thus, the outer template
is filled in by evaluating the DESTRUCTURING-BIND expressions and
interpolating their values.  Each DESTRUCTURING-BIND expression in turn
contains another backquoted template, which is used to generate one of
the method definitions to be interpolated in the outer template.

   With this macro defined, the define-binary-type form given previously
expands to this code:

   (progn (defmethod read-value ((#:g1618 (eql 'iso-8859-1-string)) in
&key length) (let ((string (make-string length))) (dotimes (i length)
(setf (char string i) (code-char (read-byte in)))) string)) (defmethod
write-value ((#:g1618 (eql 'iso-8859-1-string)) out string &key length)
(dotimes (i length) (write-byte (char-code (char string i)) out)))) Of
course, now that you've got this nice macro for defining binary types,
it's tempting to make it do a bit more work.  For now you should just
make one small enhancement that will turn out to be pretty handy when
you start using this library to deal with actual formats such as ID3
tags.

   ID3 tags, like many other binary formats, use lots of primitive types
that are minor variations on a theme, such as unsigned integers in one-,
two-, three-, and four-byte varieties.  You could certainly define each
of those types with define-binary-type as it stands.  Or you could
factor out the common algorithm for reading and writing n-byte unsigned
integers into helper functions.

   But suppose you had already defined a binary type, unsigned-integer,
that accepts a :bytes parameter to specify how many bytes to read and
write.  Using that type, you could specify a slot representing a
one-byte unsigned integer with a type specifier of (unsigned-integer
:bytes 1).  But if a particular binary format specifies lots of slots of
that type, it'd be nice to be able to easily define a new type-say,
u1-that means the same thing.  As it turns out, it's easy to change
define-binary-type to support two forms, a long form consisting of a
:reader and :writer pair and a short form that defines a new binary type
in terms of an existing type.  Using a short form define-binary-type,
you can define u1 like this:

   (define-binary-type u1 () (unsigned-integer :bytes 1)) which will
expand to this:

   (progn (defmethod read-value ((#:g161887 (eql 'u1)) #:g161888 &key)
(read-value 'unsigned-integer #:g161888 :bytes 1)) (defmethod
write-value ((#:g161887 (eql 'u1)) #:g161888 #:g161889 &key)
(write-value 'unsigned-integer #:g161888 #:g161889 :bytes 1))) To
support both long- and short-form define-binary-type calls, you need to
differentiate based on the value of the spec argument.  If spec is two
items long, it represents a long-form call, and the two items should be
the :reader and :writer specifications, which you extract as before.  On
the other hand, if it's only one item long, the one item should be a
type specifier, which needs to be parsed differently.  You can use ECASE
to switch on the LENGTH of spec and then parse spec and generate an
appropriate expansion for either the long form or the short form.

   (defmacro define-binary-type (name (&rest args) &body spec) (ecase
(length spec) (1 (with-gensyms (type stream value) (destructuring-bind
(derived-from &rest derived-args) (mklist (first spec)) '(progn
(defmethod read-value ((,type (eql ',name)) ,stream &key ,@args)
(read-value ',derived-from ,stream ,@derived-args)) (defmethod
write-value ((,type (eql ',name)) ,stream ,value &key ,@args)
(write-value ',derived-from ,stream ,value ,@derived-args)))))) (2
(with-gensyms (type) '(progn ,(destructuring-bind ((in) &body body)
(rest (assoc :reader spec)) '(defmethod read-value ((,type (eql ',name))
,in &key ,@args) ,@body)) ,(destructuring-bind ((out value) &body body)
(rest (assoc :writer spec)) '(defmethod write-value ((,type (eql
',name)) ,out ,value &key ,@args) ,@body)))))))


File: pcl.info,  Node: 24-13,  Next: Chapter 25,  Prev: 24-12,  Up: Chapter 24

The Current Object Stack
========================

One last bit of functionality you'll need in the next chapter is a way
to get at the binary object being read or written while reading and
writing.  More generally, when reading or writing nested composite
objects, it's useful to be able to get at any of the objects currently
being read or written.  Thanks to dynamic variables and :around methods,
you can add this enhancement with about a dozen lines of code.  To
start, you should define a dynamic variable that will hold a stack of
objects currently being read or written.

   (defvar *in-progress-objects* nil) Then you can define :around
methods on read-object and write-object that push the object being read
or written onto this variable before invoking CALL-NEXT-METHOD.

   (defmethod read-object :around (object stream) (declare (ignore
stream)) (let ((*in-progress-objects* (cons object
*in-progress-objects*))) (call-next-method)))

   (defmethod write-object :around (object stream) (declare (ignore
stream)) (let ((*in-progress-objects* (cons object
*in-progress-objects*))) (call-next-method))) Note how you rebind
*in-progress-objects* to a list with a new item on the front rather than
assigning it a new value.  This way, at the end of the LET, after
CALL-NEXT-METHOD returns, the old value of *in-progress-objects* will be
restored, effectively popping the object of the stack.

   With those two methods defined, you can provide two convenience
functions for getting at specific objects in the in-progress stack.  The
function current-binary-object will return the head of the stack, the
object whose read-object or write-object method was invoked most
recently.  The other, parent-of-type, takes an argument that should be
the name of a binary object class and returns the most recently pushed
object of that type, using the TYPEP function that tests whether a given
object is an instance of a particular type.

   (defun current-binary-object () (first *in-progress-objects*))

   (defun parent-of-type (type) (find-if #'(lambda (x) (typep x type))
*in-progress-objects*)) These two functions can be used in any code that
will be called within the dynamic extent of a read-object or
write-object call.  You'll see one example of how current-binary-object
can be used in the next chapter.11

   Now you have all the tools you need to tackle an ID3 parsing library,
so you're ready to move onto the next chapter where you'll do just that.


File: pcl.info,  Node: Chapter 25,  Next: Chapter 26,  Prev: Chapter 24,  Up: Top

25. Practical: An ID3 Parser
============================

With a library for parsing binary data, you're ready to write some code
for reading and writing an actual binary format, that of ID3 tags.  ID3
tags are used to embed metadata in MP3 audio files.  Dealing with ID3
tags will be a good test of the binary data library because the ID3
format is a true real-world format-a mix of engineering trade-offs and
idiosyncratic design choices that does, whatever else might be said
about it, get the job done.  In case you missed the file-sharing
revolution, here's a quick overview of what ID3 tags are and how they
relate to MP3 files.

   MP3, also known as MPEG Audio Layer 3, is a format for storing
compressed audio data, designed by researchers at Fraunhofer IIS and
standardized by the Moving Picture Experts Group, a joint committee of
the International Organization for Standardization (ISO) and the
International Electrotechnical Commission (IEC). However, the MP3
format, by itself, defines only how to store audio data.  That's fine as
long as all your MP3 files are managed by a single application that can
store metadata externally and keep track of which metadata goes with
which files.  However, when people started passing around individual MP3
files on the Internet, via file-sharing systems such as Napster, they
soon discovered they needed a way to embed metadata in the MP3 files
themselves.

   Because the MP3 standard was already codified and a fair bit of
software and hardware had already been written that knew how to decode
the existing MP3 format, any scheme for embedding information in an MP3
file would have to be invisible to MP3 decoders.  Enter ID3.

   The original ID3 format, invented by programmer Eric Kemp, consisted
of 128 bytes stuck on the end of an MP3 file where it'd be ignored by
most MP3 software.  It consisted of four 30-character fields, one each
for the song title, the album title, the artist name, and a comment; a
four-byte year field; and a one-byte genre code.  Kemp provided standard
meanings for the first 80 genre codes.  Nullsoft, the makers of Winamp,
a popular MP3 player, later supplemented this list with another 60 or so
genres.

   This format was easy to parse but obviously quite limited.  It had no
way to encode names longer than 30 characters; it was limited to 256
genres, and the meaning of the genre codes had to be agreed upon by all
users of ID3-aware software.  There wasn't even a way to encode the CD
track number of a particular MP3 file until another programmer, Michael
Mutschler, proposed embedding the track number in the comment field,
separated from the rest of the comment by a null byte, so existing ID3
software, which tended to read up to the first null in each of the text
fields, would ignore it.  Kemp's version is now called ID3v1, and
Mutschler's is ID3v1.1.

   Limited as they were, the version 1 proposals were at least a partial
solution to the metadata problem, so they were adopted by many MP3
ripping programs (which had to put the ID3 tag into the MP3 files) and
MP3 players (which would extract the information in the ID3 tag to
display to the user).1

   By 1998, however, the limitations were really becoming annoying, and
a new group, led by Martin Nilsson, started work on a completely new
tagging scheme, which came to be called ID3v2.  The ID3v2 format is
extremely flexible, allowing for many kinds of information to be
included, with almost no length limitations.  It also takes advantage of
certain details of the MP3 format to allow ID3v2 tags to be placed at
the beginning of an MP3 file.

   ID3v2 tags are, however, more of a challenge to parse than version 1
tags.  In this chapter, you'll use the binary data parsing library from
the previous chapter to develop code that can read and write ID3v2 tags.
Or at least you'll make a reasonable start-where ID3v1 was too simple,
ID3v2 is baroque to the point of being completely overengineered.
Implementing every nook and cranny of the specification, especially if
you want to support all three versions that have been specified, would
be a fair bit of work.  However, you can ignore many of the features in
those specifications since they're rarely used "in the wild."  For
starters, you can ignore, for now, a whole version, 2.4, since it has
not been widely adopted and mostly just adds more needless flexibility
compared to version 2.3.  I'll focus on versions 2.2 and 2.3 because
they're both widely used and are different enough from each other to
keep things interesting.

* Menu:

* 25-1::       Structure of an ID3v2 Tag
* 25-2::       Defining a Package
* 25-3::       Integer Types
* 25-4::       String Types
* 25-5::       ID3 Tag Header
* 25-6::       ID3 Frames
* 25-7::       Detecting Tag Padding
* 25-8::       Supporting Multiple Versions of ID3
* 25-9::       Versioned Frame Base Classes
* 25-10::      Versioned Concrete Frame Classes
* 25-11::      What Frames Do You Actually Need?
* 25-12::      Text Information Frames
* 25-13::      Comment Frames
* 25-14::      Extracting Information from an ID3 Tag


File: pcl.info,  Node: 25-1,  Next: 25-2,  Prev: Chapter 25,  Up: Chapter 25

Structure of an ID3v2 Tag
=========================

Before you can start cutting code, you'll need to be familiar with the
overall structure of an ID3v2 tag.  A tag starts with a header
containing information about the tag as a whole.  The first three bytes
of the header encode the string "ID3" in ISO-8859-1 characters.  In
other words, they're the bytes 73, 68, and 51.  Then comes two bytes
that encode the major version and revision of the ID3 specification to
which the tag purports to conform.  They're followed by a single byte
whose individual bits are treated as flags.  The meanings of the
individual flags depend on the version of the spec.  Some of the flags
can affect the way the rest of the tag is parsed.  The "major version"
is actually used to record the minor version of the spec, while the
"revision" is the subminor version of the spec.  Thus, the "major
version" field for a tag conforming to the 2.3.0 spec is 3.  The
revision field is always zero since each new ID3v2 spec has bumped the
minor version, leaving the subminor version at zero.  The value stored
in the major version field of the tag has, as you'll see, a dramatic
effect on how you'll parse the rest of the tag.

   The last field in the tag header is an integer, encoded in four bytes
but using only seven bits from each byte, that gives the total size of
the tag, not counting the header.  In version 2.3 tags, the header may
be followed by several extended header fields; otherwise, the remainder
of the tag data is divided into frames.  Different types of frames store
different kinds of information, from simple textual information, such as
the song name, to embedded images.  Each frame starts with a header
containing a string identifier and a size.  In version 2.3, the frame
header also contains two bytes worth of flags and, depending on the
value of one the flags, an optional one-byte code indicating how the
rest of the frame is encrypted.

   Frames are a perfect example of a tagged data structure-to know how
to parse the body of a frame, you need to read the header and use the
identifier to determine what kind of frame you're reading.

   The ID3 tag header contains no direct indication of how many frames
are in a tag-the tag header tells you how big the tag is, but since many
frames are variable length, the only way to find out how many frames the
tag contains is to read the frame data.  Also, the size given in the tag
header may be larger than the actual number of bytes of frame data; the
frames may be followed with enough null bytes to pad the tag out to the
specified size.  This makes it possible for tag editors to modify a tag
without having to rewrite the whole MP3 file.2

   So, the main issues you have to deal with are reading the ID3 header;
determining whether you're reading a version 2.2 or 2.3 tag; and reading
the frame data, stopping either when you've read the complete tag or
when you've hit the padding bytes.


File: pcl.info,  Node: 25-2,  Next: 25-3,  Prev: 25-1,  Up: Chapter 25

Defining a Package
==================

Like the other libraries you've developed so far, the code you'll write
in this chapter is worth putting in its own package.  You'll need to
refer to functions from both the binary data and pathname libraries
developed in Chapters 24 and 15 and will also want to export the names
of the functions that make up the public API to this package.  The
following package definition does all that:

   (defpackage :com.gigamonkeys.id3v2 (:use :common-lisp
:com.gigamonkeys.binary-data :com.gigamonkeys.pathnames) (:export
:read-id3 :mp3-p :id3-p :album :composer :genre :encoding-program
:artist :part-of-set :track :song :year :size :translated-genre)) As
usual, you can, and probably should, change the com.gigamonkeys part of
the package name to your own domain.


File: pcl.info,  Node: 25-3,  Next: 25-4,  Prev: 25-2,  Up: Chapter 25

Integer Types
=============

You can start by defining binary types for reading and writing several
of the primitive types used by the ID3 format, various sizes of unsigned
integers, and four kinds of strings.

   ID3 uses unsigned integers encoded in one, two, three, and four
bytes.  If you first write a general unsigned-integer binary type that
takes the number of bytes to read as an argument, you can then use the
short form of define-binary-type to define the specific types.  The
general unsigned-integer type looks like this:

   (define-binary-type unsigned-integer (bytes) (:reader (in) (loop with
value = 0 for low-bit downfrom (* 8 (1- bytes)) to 0 by 8 do (setf (ldb
(byte 8 low-bit) value) (read-byte in)) finally (return value)))
(:writer (out value) (loop for low-bit downfrom (* 8 (1- bytes)) to 0 by
8 do (write-byte (ldb (byte 8 low-bit) value) out)))) Now you can use
the short form of define-binary-type to define one type for each size of
integer used in the ID3 format like this:

   (define-binary-type u1 () (unsigned-integer :bytes 1))
(define-binary-type u2 () (unsigned-integer :bytes 2))
(define-binary-type u3 () (unsigned-integer :bytes 3))
(define-binary-type u4 () (unsigned-integer :bytes 4)) Another type
you'll need to be able to read and write is the 28-bit value used in the
header.  This size is encoded using 28 bits rather than a multiple of 8,
such as 32 bits, because an ID3 tag can't contain the byte #xff followed
by a byte with the top 3 bits on because that pattern has a special
meaning to MP3 decoders.  None of the other fields in the ID3 header
could possibly contain such a byte sequence, but if you encoded the tag
size as a regular unsigned-integer, it might.  To avoid that
possibility, the size is encoded using only the bottom seven bits of
each byte, with the top bit always zero.3

   Thus, it can be read and written a lot like an unsigned-integer
except the size of the byte specifier you pass to LDB should be seven
rather than eight.  This similarity suggests that if you add a
parameter, bits-per-byte, to the existing unsigned-integer binary type,
you could then define a new type, id3-tag-size, using a short-form
define-binary-type.  The new version of unsigned-integer is just like
the old version except with bits-per-byte used everywhere the old
version hardwired the number eight.  It looks like this:

   (define-binary-type unsigned-integer (bytes bits-per-byte) (:reader
(in) (loop with value = 0 for low-bit downfrom (* bits-per-byte (1-
bytes)) to 0 by bits-per-byte do (setf (ldb (byte bits-per-byte low-bit)
value) (read-byte in)) finally (return value))) (:writer (out value)
(loop for low-bit downfrom (* bits-per-byte (1- bytes)) to 0 by
bits-per-byte do (write-byte (ldb (byte bits-per-byte low-bit) value)
out)))) The definition of id3-tag-size is then trivial.

   (define-binary-type id3-tag-size () (unsigned-integer :bytes 4
:bits-per-byte 7)) You'll also have to change the definitions of u1
through u4 to specify eight bits per byte like this:

   (define-binary-type u1 () (unsigned-integer :bytes 1 :bits-per-byte
8)) (define-binary-type u2 () (unsigned-integer :bytes 2 :bits-per-byte
8)) (define-binary-type u3 () (unsigned-integer :bytes 3 :bits-per-byte
8)) (define-binary-type u4 () (unsigned-integer :bytes 4 :bits-per-byte
8))


File: pcl.info,  Node: 25-4,  Next: 25-5,  Prev: 25-3,  Up: Chapter 25

String Types
============

The other kinds of primitive types that are ubiquitous in the ID3 format
are strings.  In the previous chapter I discussed some of the issues you
have to consider when dealing with strings in binary files, such as the
difference between character codes and character encodings.

   ID3 uses two different character codes, ISO 8859-1 and Unicode.  ISO
8859-1, also known as Latin-1, is an eight-bit character code that
extends ASCII with characters used by the languages of Western Europe.
In other words, the code points from 0-127 map to the same characters in
ASCII and ISO 8859-1, but ISO 8859-1 also provides mappings for code
points up to 255.  Unicode is a character code designed to provide a
code point for virtually every character of all the world's languages.
Unicode is a superset of ISO 8859-1 in the same way that ISO 8859-1 is a
superset of ASCII-the code points from 0-255 map to the same characters
in both ISO 8859-1 and Unicode.  (Thus, Unicode is also a superset of
ASCII.)

   Since ISO 8859-1 is an eight-bit character code, it's encoded using
one byte per character.  For Unicode strings, ID3 uses the UCS-2
encoding with a leading byte order mark.4 I'll discuss what a byte order
mark is in a moment.

   Reading and writing these two encodings isn't a problem-it's just a
question of reading and writing unsigned integers in various formats,
and you just finished writing the code to do that.  The trick is how you
translate those numeric values to Lisp character objects.

   The Lisp implementation you're using probably uses either Unicode or
ISO 8859-1 as its internal character code.  And since all the values
from 0-255 map to the same characters in both ISO 8859-1 and Unicode,
you can use Lisp's CODE-CHAR and CHAR-CODE functions to translate those
values in both character codes.  However, if your Lisp supports only ISO
8859-1, then you'll be able to represent only the first 255 Unicode
characters as Lisp characters.  In other words, in such a Lisp
implementation, if you try to process an ID3 tag that uses Unicode
strings and if any of those strings contain characters with code points
higher than 255, you'll get an error when you try to translate the code
point to a Lisp character.  For now I'll assume either you're using a
Unicode-based Lisp or you won't process any files containing characters
outside the ISO 8859-1 range.

   The other issue with encoding strings is how to know how many bytes
to interpret as character data.  ID3 uses two strategies I mentioned in
the previous chapter-some strings are terminated with a null character,
while other strings occur in positions where you can determine the
number of bytes to read, either because the string at that position is
always the same length or because the string is at the end of a
composite structure whose overall size you know.  Note, however, that
the number of bytes isn't necessarily the same as the number of
characters in the string.

   Putting all these variations together, the ID3 format uses four ways
to read and write strings-two characters crossed with two ways of
delimiting the string data.

   Obviously, much of the logic of reading and writing strings will be
quite similar.  So, you can start by defining two binary types, one for
reading strings of a specific length (in characters) and another for
reading terminated strings.  Both types take advantage of that the type
argument to read-value and write-value is just another piece of data;
you can make the type of character to read a parameter of these types.
This is a technique you'll use quite a few times in this chapter.

   (define-binary-type generic-string (length character-type) (:reader
(in) (let ((string (make-string length))) (dotimes (i length) (setf
(char string i) (read-value character-type in))) string)) (:writer (out
string) (dotimes (i length) (write-value character-type out (char string
i)))))

   (define-binary-type generic-terminated-string (terminator
character-type) (:reader (in) (with-output-to-string (s) (loop for char
= (read-value character-type in) until (char= char terminator) do
(write-char char s)))) (:writer (out string) (loop for char across
string do (write-value character-type out char) finally (write-value
character-type out terminator)))) With these types available, there's
not much to reading ISO 8859-1 strings.  Because the character-type
argument you pass to read-value and write-value of a generic-string must
be the name of a binary type, you need to define an iso-8859-1-char
binary type.  This also gives you a good place to put a bit of sanity
checking on the code points of characters you read and write.

   (define-binary-type iso-8859-1-char () (:reader (in) (let ((code
(read-byte in))) (or (code-char code) (error "Character code ~d not
supported" code)))) (:writer (out char) (let ((code (char-code char)))
(if (<= 0 code #xff) (write-byte code out) (error "Illegal character for
iso-8859-1 encoding: character: ~c with code: ~d" char code))))) Now
defining the ISO 8859-1 string types is trivial using the short form of
define-binary-type as follows:

   (define-binary-type iso-8859-1-string (length) (generic-string
:length length :character-type 'iso-8859-1-char))

   (define-binary-type iso-8859-1-terminated-string (terminator)
(generic-terminated-string :terminator terminator :character-type
'iso-8859-1-char)) Reading UCS-2 strings is only slightly more complex.
The complexity arises because you can encode a UCS-2 code point in two
ways: most significant byte first (big-endian) or least significant byte
first (little-endian).  UCS-2 strings therefore start with two extra
bytes, called the byte order mark, made up of the numeric value #xfeff
encoded in either big-endian form or little-endian form.  When reading a
UCS-2 string, you read the byte order mark and then, depending on its
value, read either big-endian or little-endian characters.  Thus, you'll
need two different UCS-2 character types.  But you need only one version
of the sanity-checking code, so you can define a parameterized binary
type like this:

   (define-binary-type ucs-2-char (swap) (:reader (in) (let ((code
(read-value 'u2 in))) (when swap (setf code (swap-bytes code))) (or
(code-char code) (error "Character code ~d not supported" code))))
(:writer (out char) (let ((code (char-code char))) (unless (<= 0 code
#xffff) (error "Illegal character for ucs-2 encoding: ~c with char-code:
~d" char code)) (when swap (setf code (swap-bytes code))) (write-value
'u2 out code)))) where the swap-bytes function can be defined as
follows, taking advantage of LDB being SETFable and thus ROTATEFable:

   (defun swap-bytes (code) (assert (<= code #xffff)) (rotatef (ldb
(byte 8 0) code) (ldb (byte 8 8) code)) code) Using ucs-2-char, you can
define two character types that will be used as the character-type
arguments to the generic string functions.

   (define-binary-type ucs-2-char-big-endian () (ucs-2-char :swap nil))

   (define-binary-type ucs-2-char-little-endian () (ucs-2-char :swap t))
Then you need a function that returns the name of the character type to
use based on the value of the byte order mark.

   (defun ucs-2-char-type (byte-order-mark) (ecase byte-order-mark
(#xfeff 'ucs-2-char-big-endian) (#xfffe 'ucs-2-char-little-endian))) Now
you can define length- and terminator-delimited string types for
UCS-2-encoded strings that read the byte order mark and use it to
determine which variant of UCS-2 character to pass as the character-type
argument to read-value and write-value.  The only other wrinkle is that
you need to translate the length argument, which is a number of bytes,
to the number of characters to read, accounting for the byte order mark.

   (define-binary-type ucs-2-string (length) (:reader (in) (let
((byte-order-mark (read-value 'u2 in)) (characters (1- (/ length 2))))
(read-value 'generic-string in :length characters :character-type
(ucs-2-char-type byte-order-mark)))) (:writer (out string) (write-value
'u2 out #xfeff) (write-value 'generic-string out string :length (length
string) :character-type (ucs-2-char-type #xfeff))))

   (define-binary-type ucs-2-terminated-string (terminator) (:reader
(in) (let ((byte-order-mark (read-value 'u2 in))) (read-value
'generic-terminated-string in :terminator terminator :character-type
(ucs-2-char-type byte-order-mark)))) (:writer (out string) (write-value
'u2 out #xfeff) (write-value 'generic-terminated-string out string
:terminator terminator :character-type (ucs-2-char-type #xfeff))))


File: pcl.info,  Node: 25-5,  Next: 25-6,  Prev: 25-4,  Up: Chapter 25

ID3 Tag Header
==============

With the basic primitive types done, you're ready to switch to a
high-level view and start defining binary classes to represent first the
ID3 tag as a whole and then the individual frames.

   If you turn first to the ID3v2.2 specification, you'll see that the
basic structure of the tag is this header:

   ID3/file identifier "ID3" ID3 version $02 00 ID3 flags %xx000000 ID3
size 4 * %0xxxxxxx followed by frame data and padding.  Since you've
already defined binary types to read and write all the fields in the
header, defining a class that can read the header of an ID3 tag is just
a matter of putting them together.

   (define-binary-class id3-tag () ((identifier (iso-8859-1-string
:length 3)) (major-version u1) (revision u1) (flags u1) (size
id3-tag-size))) If you have some MP3 files lying around, you can test
this much of the code and also see what version of ID3 tags your MP3s
contain.  First you can write a function that reads an id3-tag, as just
defined, from the beginning of a file.  Be aware, however, that ID3 tags
aren't required to appear at the beginning of a file, though these days
they almost always do.  To find an ID3 tag elsewhere in a file, you can
scan the file looking for the sequence of bytes 73, 68, 51 (in other
words, the string "ID3").5 For now you can probably get away with
assuming the tags are the first thing in the file.

   (defun read-id3 (file) (with-open-file (in file :element-type
'(unsigned-byte 8)) (read-value 'id3-tag in))) On top of this function
you can build a function that takes a filename and prints the
information in the tag header along with the name of the file.

   (defun show-tag-header (file) (with-slots (identifier major-version
revision flags size) (read-id3 file) (format t "~a ~d.~d ~8,'0b ~d bytes
- ~a~%" identifier major-version revision flags size (enough-namestring
file)))) It prints output that looks like this:

   ID3V2> (show-tag-header "/usr2/mp3/Kitka/Wintersongs/02 Byla
Cesta.mp3") ID3 2.0 00000000 2165 bytes - Kitka/Wintersongs/02 Byla
Cesta.mp3 NIL Of course, to determine what versions of ID3 are most
common in your MP3 library, it'd be handier to have a function that
returns a summary of all the MP3 files under a given directory.  You can
write one easily enough using the walk-directory function defined in
Chapter 15.  First define a helper function that tests whether a given
filename has an mp3 extension.

   (defun mp3-p (file) (and (not (directory-pathname-p file))
(string-equal "mp3" (pathname-type file)))) Then you can combine
show-tag-header and mp3-p with walk-directory to print a summary of the
ID3 header in each file under a given directory.

   (defun show-tag-headers (dir) (walk-directory dir #'show-tag-header
:test #'mp3-p)) However, if you have a lot of MP3s, you may just want a
count of how many ID3 tags of each version you have in your MP3
collection.  To get that information, you might write a function like
this:

   (defun count-versions (dir) (let ((versions (mapcar #'(lambda (x)
(cons x 0)) '(2 3 4)))) (flet ((count-version (file) (incf (cdr (assoc
(major-version (read-id3 file)) versions))))) (walk-directory dir
#'count-version :test #'mp3-p)) versions)) Another function you'll need
in Chapter 29 is one that tests whether a file actually starts with an
ID3 tag, which you can define like this:

   (defun id3-p (file) (with-open-file (in file :element-type
'(unsigned-byte 8)) (string= "ID3" (read-value 'iso-8859-1-string in
:length 3))))


File: pcl.info,  Node: 25-6,  Next: 25-7,  Prev: 25-5,  Up: Chapter 25

ID3 Frames
==========

As I discussed earlier, the bulk of an ID3 tag is divided into frames.
Each frame has a structure similar to that of the tag as a whole.  Each
frame starts with a header indicating what kind of frame it is and the
size of the frame in bytes.  The structure of the frame header changed
slightly between version 2.2 and version 2.3 of the ID3 format, and
eventually you'll have to deal with both forms.  To start, you can focus
on parsing version 2.2 frames.

   The header of a 2.2 frame consists of three bytes that encode a
three-character ISO 8859-1 string followed by a three-byte unsigned
integer, which specifies the size of the frame in bytes, excluding the
six-byte header.  The string identifies what type of frame it is, which
determines how you parse the data following the size.  This is exactly
the kind of situation for which you defined the
define-tagged-binary-class macro.  You can define a tagged class that
reads the frame header and then dispatches to the appropriate concrete
class using a function that maps IDs to a class names.

   (define-tagged-binary-class id3-frame () ((id (iso-8859-1-string
:length 3)) (size u3)) (:dispatch (find-frame-class id))) Now you're
ready to start implementing concrete frame classes.  However, the
specification defines quite a few-63 in version 2.2 and even more in
later specs.  Even considering frame types that share a common structure
to be equivalent, you'll still find 24 unique frame types in version
2.2.  But only a few of these are used "in the wild."  So rather than
immediately setting to work defining classes for each of the frame
types, you can start by writing a generic frame class that lets you read
the frames in a tag without parsing the data within the frames
themselves.  This will give you a way to find out what frames are
actually present in the MP3s you want to process.  You'll need this
class eventually anyway because the specification allows for
experimental frames that you'll need to be able to read without parsing.

   Since the size field of the frame header tells you exactly how many
bytes long the frame is, you can define a generic-frame class that
extends id3-frame and adds a single field, data, that will hold an array
of bytes.

   (define-binary-class generic-frame (id3-frame) ((data (raw-bytes
:size size)))) The type of the data field, raw-bytes, just needs to hold
an array of bytes.  You can define it like this:

   (define-binary-type raw-bytes (size) (:reader (in) (let ((buf
(make-array size :element-type '(unsigned-byte 8)))) (read-sequence buf
in) buf)) (:writer (out buf) (write-sequence buf out))) For the time
being, you'll want all frames to be read as generic-frames, so you can
define the find-frame-class function used in id3-frame's :dispatch
expression to always return generic-frame, regardless of the frame's id.

   (defun find-frame-class (id) (declare (ignore id)) 'generic-frame)
Now you need to modify id3-tag so it'll read frames after the header
fields.  There's only one tricky bit to reading the frame data: although
the tag header tells you how many bytes long the tag is, that number
includes the padding that can follow the frame data.  Since the tag
header doesn't tell you how many frames the tag contains, the only way
to tell when you've hit the padding is to look for a null byte where
you'd expect a frame identifier.

   To handle this, you can define a binary type, id3-frames, that will
be responsible for reading the remainder of a tag, creating frame
objects to represent all the frames it finds, and then skipping over any
padding.  This type will take as a parameter the tag size, which it can
use to avoid reading past the end of the tag.  But the reading code will
also need to detect the beginning of the padding that can follow the
tag's frame data.  Rather than calling read-value directly in id3-frames
:reader, you should use a function read-frame, which you'll define to
return NIL when it detects padding, otherwise returning an id3-frame
object read using read-value.  Assuming you define read-frame so it
reads only one byte past the end of the last frame in order to detect
the start of the padding, you can define the id3-frames binary type like
this:

   (define-binary-type id3-frames (tag-size) (:reader (in) (loop with
to-read = tag-size while (plusp to-read) for frame = (read-frame in)
while frame do (decf to-read (+ 6 (size frame))) collect frame finally
(loop repeat (1- to-read) do (read-byte in)))) (:writer (out frames)
(loop with to-write = tag-size for frame in frames do (write-value
'id3-frame out frame) (decf to-write (+ 6 (size frame))) finally (loop
repeat to-write do (write-byte 0 out))))) You can use this type to add a
frames slot to id3-tag.

   (define-binary-class id3-tag () ((identifier (iso-8859-1-string
:length 3)) (major-version u1) (revision u1) (flags u1) (size
id3-tag-size) (frames (id3-frames :tag-size size))))


File: pcl.info,  Node: 25-7,  Next: 25-8,  Prev: 25-6,  Up: Chapter 25

Detecting Tag Padding
=====================

Now all that remains is to implement read-frame.  This is a bit tricky
since the code that actually reads bytes from the stream is several
layers down from read-frame.

   What you'd really like to do in read-frame is read one byte and
return NIL if it's a null and otherwise read a frame with read-value.
Unfortunately, if you read the byte in read-frame, then it won't be
available to be read by read-value.6

   It turns out this is a perfect opportunity to use the condition
system-you can check for null bytes in the low-level code that reads
from the stream and signal a condition when you read a null; read-frame
can then handle the condition by unwinding the stack before more bytes
are read.  In addition to turning out to be a tidy solution to the
problem of detecting the start of the tag's padding, this is also an
example of how you can use conditions for purposes other than handling
errors.

   You can start by defining a condition type to be signaled by the
low-level code and handled by the high-level code.  This condition
doesn't need any slots-you just need a distinct class of condition so
you know no other code will be signaling or handling it.

   (define-condition in-padding () ()) Next you need to define a binary
type whose :reader reads a given number of bytes, first reading a single
byte and signaling an in-padding condition if the byte is null and
otherwise reading the remaining bytes as an iso-8859-1-string and
combining it with the first byte read.

   (define-binary-type frame-id (length) (:reader (in) (let ((first-byte
(read-byte in))) (when (= first-byte 0) (signal 'in-padding)) (let
((rest (read-value 'iso-8859-1-string in :length (1- length))))
(concatenate 'string (string (code-char first-byte)) rest)))) (:writer
(out id) (write-value 'iso-8859-1-string out id :length length))) If you
redefine id3-frame to make the type of its id slot frame-id instead of
iso-8859-1-string, the condition will be signaled whenever id3-frame's
read-value method reads a null byte instead of the beginning of a frame.

   (define-tagged-binary-class id3-frame () ((id (frame-id :length 3))
(size u3)) (:dispatch (find-frame-class id))) Now all read-frame has to
do is wrap a call to read-value in a HANDLER-CASE that handles the
in-padding condition by returning NIL.

   (defun read-frame (in) (handler-case (read-value 'id3-frame in)
(in-padding () nil))) With read-frame defined, you can now read a
complete version 2.2 ID3 tag, representing frames with instances of
generic-frame.  In the "What Frames Do You Actually Need?"  section,
you'll do some experiments at the REPL to determine what frame classes
you need to implement.  But first let's add support for version 2.3 ID3
tags.


File: pcl.info,  Node: 25-8,  Next: 25-9,  Prev: 25-7,  Up: Chapter 25

Supporting Multiple Versions of ID3
===================================

Currently, id3-tag is defined using define-binary-class, but if you want
to support multiple versions of ID3, it makes more sense to use a
define-tagged-binary-class that dispatches on the major-version value.
As it turns out, all versions of ID3v2 have the same structure up to the
size field.  So, you can define a tagged binary class like the following
that defines this basic structure and then dispatches to the appropriate
version-specific subclass:

   (define-tagged-binary-class id3-tag () ((identifier
(iso-8859-1-string :length 3)) (major-version u1) (revision u1) (flags
u1) (size id3-tag-size)) (:dispatch (ecase major-version (2
'id3v2.2-tag) (3 'id3v2.3-tag)))) Version 2.2 and version 2.3 tags
differ in two ways.  First, the header of a version 2.3 tag may be
extended with up to four optional extended header fields, as determined
by values in the flags field.  Second, the frame format changed between
version 2.2 and version 2.3, which means you'll have to use different
classes to represent version 2.2 frames and the corresponding version
2.3 frames.

   Since the new id3-tag class is based on the one you originally wrote
to represent version 2.2 tags, it's not surprising that the new
id3v2.2-tag class is trivial, inheriting most of its slots from the new
id3-tag class and adding the one missing slot, frames.  Because version
2.2 and version 2.3 tags use different frame formats, you'll have to
change the id3-frames type to be parameterized with the type of frame to
read.  For now, assume you'll do that and add a :frame-type argument to
the id3-frames type descriptor like this:

   (define-binary-class id3v2.2-tag (id3-tag) ((frames (id3-frames
:tag-size size :frame-type 'id3v2.2-frame)))) The id3v2.3-tag class is
slightly more complex because of the optional fields.  The first three
of the four optional fields are included when the sixth bit in flags is
set.  They're a four- byte integer specifying the size of the extended
header, two bytes worth of flags, and another four-byte integer
specifying how many bytes of padding are included in the tag.7 The
fourth optional field, included when the fifteenth bit of the extended
header flags is set, is a four-byte cyclic redundancy check (CRC) of the
rest of the tag.

   The binary data library doesn't provide any special support for
optional fields in a binary class, but it turns out that regular
parameterized binary types are sufficient.  You can define a type
parameterized with the name of a type and a value that indicates whether
a value of that type should actually be read or written.

   (define-binary-type optional (type if) (:reader (in) (when if
(read-value type in))) (:writer (out value) (when if (write-value type
out value)))) Using if as the parameter name looks a bit strange in that
code, but it makes the optional type descriptors quite readable.  For
instance, here's the definition of id3v2.3-tag using optional slots:

   (define-binary-class id3v2.3-tag (id3-tag) ((extended-header-size
(optional :type 'u4 :if (extended-p flags))) (extra-flags (optional
:type 'u2 :if (extended-p flags))) (padding-size (optional :type 'u4 :if
(extended-p flags))) (crc (optional :type 'u4 :if (crc-p flags
extra-flags))) (frames (id3-frames :tag-size size :frame-type
'id3v2.3-frame)))) where extended-p and crc-p are helper functions that
test the appropriate bit of the flags value they're passed.  To test
whether an individual bit of an integer is set, you can use LOGBITP,
another bit-twiddling function.  It takes an index and an integer and
returns true if the specified bit is set in the integer.

   (defun extended-p (flags) (logbitp 6 flags))

   (defun crc-p (flags extra-flags) (and (extended-p flags) (logbitp 15
extra-flags))) As in the version 2.2 tag class, the frames slot is
defined to be of type id3-frames, passing the name of the frame type as
a parameter.  You do, however, need to make a few small changes to
id3-frames and read-frame to support the extra frame-type parameter.

   (define-binary-type id3-frames (tag-size frame-type) (:reader (in)
(loop with to-read = tag-size while (plusp to-read) for frame =
(read-frame frame-type in) while frame do (decf to-read (+
(frame-header-size frame) (size frame))) collect frame finally (loop
repeat (1- to-read) do (read-byte in)))) (:writer (out frames) (loop
with to-write = tag-size for frame in frames do (write-value frame-type
out frame) (decf to-write (+ (frame-header-size frame) (size frame)))
finally (loop repeat to-write do (write-byte 0 out)))))

   (defun read-frame (frame-type in) (handler-case (read-value
frame-type in) (in-padding () nil))) The changes are in the calls to
read-frame and write-value, where you need to pass the frame-type
argument and, in computing the size of the frame, where you need to use
a function frame-header-size instead of the literal value 6 since the
frame header changed size between version 2.2 and version 2.3.  Since
the difference in the result of this function is based on the class of
the frame, it makes sense to define it as a generic function like this:

   (defgeneric frame-header-size (frame)) You'll define the necessary
methods on that generic function in the next section after you define
the new frame classes.


File: pcl.info,  Node: 25-9,  Next: 25-10,  Prev: 25-8,  Up: Chapter 25

Versioned Frame Base Classes
============================

Where before you defined a single base class for all frames, you'll now
have two classes, id3v2.2-frame and id3v2.3-frame.  The id3v2.2-frame
class will be essentially the same as the original id3-frame class.

   (define-tagged-binary-class id3v2.2-frame () ((id (frame-id :length
3)) (size u3)) (:dispatch (find-frame-class id))) The id3v2.3-frame, on
the other hand, requires more changes.  The frame identifier and size
fields were extended in version 2.3 from three to four bytes each, and
two bytes worth of flags were added.  Additionally, the frame, like the
version 2.3 tag, can contain optional fields, controlled by the values
of three of the frame's flags.8 With those changes in mind, you can
define the version 2.3 frame base class, along with some helper
functions, like this:

   (define-tagged-binary-class id3v2.3-frame () ((id (frame-id :length
4)) (size u4) (flags u2) (decompressed-size (optional :type 'u4 :if
(frame-compressed-p flags))) (encryption-scheme (optional :type 'u1 :if
(frame-encrypted-p flags))) (grouping-identity (optional :type 'u1 :if
(frame-grouped-p flags)))) (:dispatch (find-frame-class id)))

   (defun frame-compressed-p (flags) (logbitp 7 flags))

   (defun frame-encrypted-p (flags) (logbitp 6 flags))

   (defun frame-grouped-p (flags) (logbitp 5 flags)) With these two
classes defined, you can now implement the methods on the generic
function frame-header-size.

   (defmethod frame-header-size ((frame id3v2.2-frame)) 6)

   (defmethod frame-header-size ((frame id3v2.3-frame)) 10) The optional
fields in a version 2.3 frame aren't counted as part of the header for
this computation since they're already included in the value of the
frame's size.


File: pcl.info,  Node: 25-10,  Next: 25-11,  Prev: 25-9,  Up: Chapter 25

Versioned Concrete Frame Classes
================================

In the original definition, generic-frame subclassed id3-frame.  But now
id3-frame has been replaced with the two version-specific base classes,
id3v2.2-frame and id3v2.3-frame.  So, you need to define two new
versions of generic-frame, one for each base class.  One way to define
this classes would be like this:

   (define-binary-class generic-frame-v2.2 (id3v2.2-frame) ((data
(raw-bytes :size size))))

   (define-binary-class generic-frame-v2.3 (id3v2.3-frame) ((data
(raw-bytes :size size)))) However, it's a bit annoying that these two
classes are the same except for their superclass.  It's not too bad in
this case since there's only one additional field.  But if you take this
approach for other concrete frame classes, ones that have a more complex
internal structure that's identical between the two ID3 versions, the
duplication will be more irksome.

   Another approach, and the one you should actually use, is to define a
class generic-frame as a mixin: a class intended to be used as a
superclass along with one of the version-specific base classes to
produce a concrete, version-specific frame class.  The only tricky bit
about this approach is that if generic-frame doesn't extend either of
the frame base classes, then you can't refer to the size slot in its
definition.  Instead, you must use the current-binary-object function I
discussed at the end of the previous chapter to access the object you're
in the midst of reading or writing and pass it to size.  And you need to
account for the difference in the number of bytes of the total frame
size that will be left over, in the case of a version 2.3 frame, if any
of the optional fields are included in the frame.  So, you should define
a generic function data-bytes with methods that do the right thing for
both version 2.2 and version 2.3 frames.

   (define-binary-class generic-frame () ((data (raw-bytes :size
(data-bytes (current-binary-object))))))

   (defgeneric data-bytes (frame))

   (defmethod data-bytes ((frame id3v2.2-frame)) (size frame))

   (defmethod data-bytes ((frame id3v2.3-frame)) (let ((flags (flags
frame))) (- (size frame) (if (frame-compressed-p flags) 4 0) (if
(frame-encrypted-p flags) 1 0) (if (frame-grouped-p flags) 1 0)))) Then
you can define concrete classes that extend one of the version-specific
base classes and generic-frame to define version-specific generic frame
classes.

   (define-binary-class generic-frame-v2.2 (id3v2.2-frame generic-frame)
())

   (define-binary-class generic-frame-v2.3 (id3v2.3-frame generic-frame)
()) With these classes defined, you can redefine the find-frame-class
function to return the right versioned class based on the length of the
identifier.

   (defun find-frame-class (id) (ecase (length id) (3
'generic-frame-v2.2) (4 'generic-frame-v2.3)))


File: pcl.info,  Node: 25-11,  Next: 25-12,  Prev: 25-10,  Up: Chapter 25

What Frames Do You Actually Need?
=================================

With the ability to read both version 2.2 and version 2.3 tags using
generic frames, you're ready to start implementing classes to represent
the specific frames you care about.  However, before you dive in, you
should take a breather and figure out what frames you actually care
about since, as I mentioned earlier, the ID3 spec specifies many frames
that are almost never used.  Of course, what frames you care about
depends on what kinds of applications you're interested in writing.  If
you're mostly interested in extracting information from existing ID3
tags, then you need implement only the classes representing the frames
containing the information you care about.  On the other hand, if you
want to write an ID3 tag editor, you may need to support all the frames.

   Rather than guessing which frames will be most useful, you can use
the code you've already written to poke around a bit at the REPL and see
what frames are actually used in your own MP3s.  To start, you need an
instance of id3-tag, which you can get with the read-id3 function.

   ID3V2> (read-id3 "/usr2/mp3/Kitka/Wintersongs/02 Byla Cesta.mp3")
#<ID3V2.2-TAG  #x727b2912> Since you'll want to play with this object a
bit, you should save it in a variable.

   ID3V2> (defparameter *id3* (read-id3 "/usr2/mp3/Kitka/Wintersongs/02
Byla Cesta.mp3")) *ID3* Now you can see, for example, how many frames it
has.

   ID3V2> (length (frames *id3*)) 11 Not too many-let's take a look at
what they are.

   ID3V2> (frames *id3*) (#<GENERIC-FRAME-V2.2  #x72dabdda>
#<GENERIC-FRAME-V2.2  #x72dabec2> #<GENERIC-FRAME-V2.2  #x72dabfa2>
#<GENERIC-FRAME-V2.2  #x72dac08a> #<GENERIC-FRAME-V2.2  #x72dac16a>
#<GENERIC-FRAME-V2.2  #x72dac24a> #<GENERIC-FRAME-V2.2  #x72dac32a>
#<GENERIC-FRAME-V2.2  #x72dac40a> #<GENERIC-FRAME-V2.2  #x72dac4f2>
#<GENERIC-FRAME-V2.2  #x72dac632> #<GENERIC-FRAME-V2.2  #x72dac7b2>)
Okay, that's not too informative.  What you really want to know are what
kinds of frames are in there.  In other words, you want to know the ids
of those frames, which you can get with a simple MAPCAR like this:

   ID3V2> (mapcar #'id (frames *id3*)) ("TT2" "TP1" "TAL" "TRK" "TPA"
"TYE" "TCO" "TEN" "COM" "COM" "COM") If you look up these identifiers in
the ID3v2.2 spec, you'll discover that all the frames with identifiers
starting with T are text information frames and have a similar
structure.  And COM is the identifier for comment frames, which have a
structure similar to that of text information frames.  The particular
text information frames identified here turn out to be the frames for
representing the song title, artist, album, track, part of set, year,
genre, and encoding program.

   Of course, this is just one MP3 file.  Maybe other frames are used in
other files.  It's easy enough to discover.  First define a function
that combines the previous MAPCAR expression with a call to read-id3 and
wraps the whole thing in a DELETE-DUPLICATES to keep things tidy.
You'll have to use a :test argument of #'string= to DELETE-DUPLICATES to
specify that you want two elements considered the same if they're the
same string.

   (defun frame-types (file) (delete-duplicates (mapcar #'id (frames
(read-id3 file))) :test #'string=)) This should give the same answer
except with only one of each identifier when passed the same filename.

   ID3V2> (frame-types "/usr2/mp3/Kitka/Wintersongs/02 Byla Cesta.mp3")
("TT2" "TP1" "TAL" "TRK" "TPA" "TYE" "TCO" "TEN" "COM") Then you can use
Chapter 15's walk-directory function along with mp3-p to find every MP3
file under a directory and combine the results of calling frame-types on
each file.  Recall that NUNION is the recycling version of the UNION
function; since frame-types makes a new list for each file, this is
safe.

   (defun frame-types-in-dir (dir) (let ((ids ())) (flet ((collect
(file) (setf ids (nunion ids (frame-types file) :test #'string=))))
(walk-directory dir #'collect :test #'mp3-p)) ids)) Now pass it the name
of a directory, and it'll tell you the set of identifiers used in all
the MP3 files under that directory.  It may take a few seconds depending
how many MP3 files you have, but you'll probably get something similar
to this:

   ID3V2> (frame-types-in-dir "/usr2/mp3/") ("TCON" "COMM" "TRCK" "TIT2"
"TPE1" "TALB" "TCP" "TT2" "TP1" "TCM" "TAL" "TRK" "TPA" "TYE" "TCO"
"TEN" "COM") The four-letter identifiers are the version 2.3 equivalents
of the version 2.2 identifiers I discussed previously.  Since the
information stored in those frames is exactly the information you'll
need in Chapter 27, it makes sense to implement classes only for the
frames actually used, namely, text information and comment frames, which
you'll do in the next two sections.  If you decide later that you want
to support other frame types, it's mostly a matter of translating the
ID3 specifications into the appropriate binary class definitions.


File: pcl.info,  Node: 25-12,  Next: 25-13,  Prev: 25-11,  Up: Chapter 25

Text Information Frames
=======================

All text information frames consist of two fields: a single byte
indicating which string encoding is used in the frame and a string
encoded in the remaining bytes of the frame.  If the encoding byte is
zero, the string is encoded in ISO 8859-1; if the encoding is one, the
string is a UCS-2 string.

   You've already defined binary types representing the four different
kinds of strings-two different encodings each with two different methods
of delimiting the string.  However, define-binary-class provides no
direct facility for determining the type of value to read based on other
values in the object.  Instead, you can define a binary type that you
pass the value of the encoding byte and that then reads or writes the
appropriate kind of string.

   As long as you're defining such a type, you can also define it to
take two parameters, :length and :terminator, and pick the right type of
string based on which argument is supplied.  To implement this new type,
you must first define some helper functions.  The first two return the
name of the appropriate string type based on the encoding byte.

   (defun non-terminated-type (encoding) (ecase encoding (0
'iso-8859-1-string) (1 'ucs-2-string)))

   (defun terminated-type (encoding) (ecase encoding (0
'iso-8859-1-terminated-string) (1 'ucs-2-terminated-string))) Then
string-args uses the encoding byte, the length, and the terminator to
determine several of the arguments to be passed to read-value and
write-value by the :reader and :writer of id3-encoded-string.  One of
the length and terminator arguments to string-args should always be NIL.

   (defun string-args (encoding length terminator) (cond (length (values
(non-terminated-type encoding) :length length)) (terminator (values
(terminated-type encoding) :terminator terminator)))) With those
helpers, the definition of id3-encoded-string is simple.  One detail to
note is that the keyword-either :length or :terminator-used in the call
to read-value and write-value is just another piece of data returned by
string-args.  Although keywords in arguments lists are almost always
literal keywords, they don't have to be.

   (define-binary-type id3-encoded-string (encoding length terminator)
(:reader (in) (multiple-value-bind (type keyword arg) (string-args
encoding length terminator) (read-value type in keyword arg))) (:writer
(out string) (multiple-value-bind (type keyword arg) (string-args
encoding length terminator) (write-value type out string keyword arg))))
Now you can define a text-info mixin class, much the way you defined
generic-frame earlier.

   (define-binary-class text-info-frame () ((encoding u1) (information
(id3-encoded-string :encoding encoding :length (bytes-left 1))))) As
when you defined generic-frame, you need access to the size of the
frame, in this case to compute the :length argument to pass to
id3-encoded-string.  Because you'll need to do a similar computation in
the next class you define, you can go ahead and define a helper
function, bytes-left, that uses current-binary-object to get at the size
of the frame.

   (defun bytes-left (bytes-read) (- (size (current-binary-object))
bytes-read)) Now, as you did with the generic-frame mixin, you can
define two version-specific concrete classes with a minimum of
duplicated code.

   (define-binary-class text-info-frame-v2.2 (id3v2.2-frame
text-info-frame) ())

   (define-binary-class text-info-frame-v2.3 (id3v2.3-frame
text-info-frame) ()) To wire these classes in, you need to modify
find-frame-class to return the appropriate class name when the ID
indicates the frame is a text information frame, namely, whenever the ID
starts with T and isn't TXX or TXXX.

   (defun find-frame-class (name) (cond ((and (char= (char name 0) #\T)
(not (member name '("TXX" "TXXX") :test #'string=))) (ecase (length
name) (3 'text-info-frame-v2.2) (4 'text-info-frame-v2.3))) (t (ecase
(length name) (3 'generic-frame-v2.2) (4 'generic-frame-v2.3)))))


File: pcl.info,  Node: 25-13,  Next: 25-14,  Prev: 25-12,  Up: Chapter 25

Comment Frames
==============

Another commonly used frame type is the comment frame, which is like a
text information frame with a few extra fields.  Like a text information
frame, it starts with a single byte indicating the string encoding used
in the frame.  That byte is followed by a three-character ISO 8859-1
string (regardless of the value of the string encoding byte), which
indicates what language the comment is in using an ISO-639-2 code, for
example, "eng" for English or "jpn" for Japanese.  That field is
followed by two strings encoded as indicated by the first byte.  The
first is a null-terminated string containing a description of the
comment.  The second, which takes up the remainder of the frame, is the
comment text itself.

   (define-binary-class comment-frame () ((encoding u1) (language
(iso-8859-1-string :length 3)) (description (id3-encoded-string
:encoding encoding :terminator +null+)) (text (id3-encoded-string
:encoding encoding :length (bytes-left (+ 1 ; encoding 3 ; language
(encoded-string-length description encoding t))))))) As in the
definition of the text-info mixin, you can use bytes-left to compute the
size of the final string.  However, since the description field is a
variable-length string, the number of bytes read prior to the start of
text isn't a constant.  To make matters worse, the number of bytes used
to encode description is dependent on the encoding.  So, you should
define a helper function that returns the number of bytes used to encode
a string given the string, the encoding code, and a boolean indicating
whether the string is terminated with an extra character.

   (defun encoded-string-length (string encoding terminated) (let
((characters (+ (length string) (if terminated 1 0)))) (* characters
(ecase encoding (0 1) (1 2))))) And, as before, you can define the
concrete version-specific comment frame classes and wire them into
find-frame-class.

   (define-binary-class comment-frame-v2.2 (id3v2.2-frame comment-frame)
())

   (define-binary-class comment-frame-v2.3 (id3v2.3-frame comment-frame)
())

   (defun find-frame-class (name) (cond ((and (char= (char name 0) #\T)
(not (member name '("TXX" "TXXX") :test #'string=))) (ecase (length
name) (3 'text-info-frame-v2.2) (4 'text-info-frame-v2.3))) ((string=
name "COM") 'comment-frame-v2.2) ((string= name "COMM")
'comment-frame-v2.3) (t (ecase (length name) (3 'generic-frame-v2.2) (4
'generic-frame-v2.3)))))


File: pcl.info,  Node: 25-14,  Next: Chapter 26,  Prev: 25-13,  Up: Chapter 25

Extracting Information from an ID3 Tag
======================================

Now that you have the basic ability to read and write ID3 tags, you have
a lot of directions you could take this code.  If you want to develop a
complete ID3 tag editor, you'll need to implement specific classes for
all the frame types.  You'd also need to define methods for manipulating
the tag and frame objects in a consistent way (for instance, if you
change the value of a string in a text-info-frame, you'll likely need to
adjust the size); as the code stands, there's nothing to make sure that
happens.9

   Or, if you just need to extract certain pieces of information about
an MP3 file from its ID3 tag-as you will when you develop a streaming
MP3 server in Chapters 27, 28, and 29-you'll need to write functions
that find the appropriate frames and extract the information you want.

   Finally, to make this production-quality code, you'd have to pore
over the ID3 specs and deal with the details I skipped over in the
interest of space.  In particular, some of the flags in both the tag and
the frame can affect the way the contents of the tag or frame is read;
unless you write some code that does the right thing when those flags
are set, there may be ID3 tags that this code won't be able to parse
correctly.  But the code from this chapter should be capable of parsing
nearly all the MP3s you actually encounter.

   For now you can finish with a few functions to extract individual
pieces of information from an id3-tag.  You'll need these functions in
Chapter 27 and probably in other code that uses this library.  They
belong in this library because they depend on details of the ID3 format
that the users of this library shouldn't have to worry about.

   To get, say, the name of the song of the MP3 from which an id3-tag
was extracted, you need to find the ID3 frame with a specific identifier
and then extract the information field.  And some pieces of information,
such as the genre, can require further decoding.  Luckily, all the
frames that contain the information you'll care about are text
information frames, so extracting a particular piece of information
mostly boils down to using the right identifier to look up the
appropriate frame.  Of course, the ID3 authors decided to change all the
identifiers between ID3v2.2 and ID3v2.3, so you'll have to account for
that.

   Nothing too complex-you just need to figure out the right path to get
to the various pieces of information.  This is a perfect bit of code to
develop interactively, much the way you figured out what frame classes
you needed to implement.  To start, you need an id3-tag object to play
with.  Assuming you have an MP3 laying around, you can use read-id3 like
this:

   ID3V2> (defparameter *id3* (read-id3 "Kitka/Wintersongs/02 Byla
Cesta.mp3")) *ID3* ID3V2> *id3* #<ID3V2.2-TAG  #x73d04c1a> replacing
Kitka/Wintersongs/02 Byla Cesta.mp3 with the filename of your MP3.  Once
you have your id3-tag object, you can start poking around.  For
instance, you can check out the list of frame objects with the frames
function.

   ID3V2> (frames *id3*) (#<TEXT-INFO-FRAME-V2.2  #x73d04cca>
#<TEXT-INFO-FRAME-V2.2  #x73d04dba> #<TEXT-INFO-FRAME-V2.2  #x73d04ea2>
#<TEXT-INFO-FRAME-V2.2  #x73d04f9a> #<TEXT-INFO-FRAME-V2.2  #x73d05082>
#<TEXT-INFO-FRAME-V2.2  #x73d0516a> #<TEXT-INFO-FRAME-V2.2  #x73d05252>
#<TEXT-INFO-FRAME-V2.2  #x73d0533a> #<COMMENT-FRAME-V2.2  #x73d0543a>
#<COMMENT-FRAME-V2.2  #x73d05612> #<COMMENT-FRAME-V2.2  #x73d0586a>) Now
suppose you want to extract the song title.  It's probably in one of
those frames, but to find it, you need to find the frame with the "TT2"
identifier.  Well, you can check easily enough to see if the tag
contains such a frame by extracting all the identifiers like this:

   ID3V2> (mapcar #'id (frames *id3*)) ("TT2" "TP1" "TAL" "TRK" "TPA"
"TYE" "TCO" "TEN" "COM" "COM" "COM") There it is, the first frame.
However, there's no guarantee it'll always be the first frame, so you
should probably look it up by identifier rather than position.  That's
also straightforward using the FIND function.

   ID3V2> (find "TT2" (frames *id3*) :test #'string= :key #'id)
#<TEXT-INFO-FRAME-V2.2  #x73d04cca> Now, to get at the actual
information in the frame, do this:

   ID3V2> (information (find "TT2" (frames *id3*) :test #'string= :key
#'id)) "Byla Cesta^@" Whoops.  That ^ is how Emacs prints a null
character.  In a maneuver reminiscent of the kludge that turned ID3v1
into ID3v1.1, the information slot of a text information frame, though
not officially a null-terminated string, can contain a null, and ID3
readers are supposed to ignore any characters after the null.  So, you
need a function that takes a string and returns the contents up to the
first null character, if any.  That's easy enough using the +null+
constant from the binary data library.

   (defun upto-null (string) (subseq string 0 (position +null+ string)))
Now you can get just the title.

   ID3V2> (upto-null (information (find "TT2" (frames *id3*) :test
#'string= :key #'id))) "Byla Cesta" You could just wrap that code in a
function named song that takes an id3-tag as an argument, and you'd be
done.  However, the only difference between this code and the code
you'll use to extract the other pieces of information you'll need (such
as the album name, the artist, and the genre) is the identifier.  So,
it's better to split up the code a bit.  For starters, you can write a
function that just finds a frame given an id3-tag and an identifier like
this:

   (defun find-frame (id3 id) (find id (frames id3) :test #'string= :key
#'id))

   ID3V2> (find-frame *id3* "TT2") #<TEXT-INFO-FRAME-V2.2  #x73d04cca>
Then the other bit of code, the part that extracts the information from
a text-info-frame, can go in another function.

   (defun get-text-info (id3 id) (let ((frame (find-frame id3 id)))
(when frame (upto-null (information frame)))))

   ID3V2> (get-text-info *id3* "TT2") "Byla Cesta" Now the definition of
song is just a matter of passing the right identifier.

   (defun song (id3) (get-text-info id3 "TT2"))

   ID3V2> (song *id3*) "Byla Cesta" However, this definition of song
works only with version 2.2 tags since the identifier changed from "TT2"
to "TIT2" between version 2.2 and version 2.3.  And all the other tags
changed too.  Since the user of this library shouldn't have to know
about different versions of the ID3 format to do something as simple as
get the song title, you should probably handle those details for them.
A simple way is to change find-frame to take not just a single
identifier but a list of identifiers like this:

   (defun find-frame (id3 ids) (find-if #'(lambda (x) (find (id x) ids
:test #'string=)) (frames id3))) Then change get-text-info slightly so
it can take one or more identifiers using a &rest parameter.

   (defun get-text-info (id3 &rest ids) (let ((frame (find-frame id3
ids))) (when frame (upto-null (information frame))))) Then the change
needed to allow song to support both version 2.2 and version 2.3 tags is
just a matter of adding the version 2.3 identifier.

   (defun song (id3) (get-text-info id3 "TT2" "TIT2")) Then you just
need to look up the appropriate version 2.2 and version 2.3 frame
identifiers for any fields for which you want to provide an accessor
function.  Here are the ones you'll need in Chapter 27:

   (defun album (id3) (get-text-info id3 "TAL" "TALB"))

   (defun artist (id3) (get-text-info id3 "TP1" "TPE1"))

   (defun track (id3) (get-text-info id3 "TRK" "TRCK"))

   (defun year (id3) (get-text-info id3 "TYE" "TYER" "TDRC"))

   (defun genre (id3) (get-text-info id3 "TCO" "TCON")) The last wrinkle
is that the way the genre is stored in the TCO or TCON frames isn't
always human readable.  Recall that in ID3v1, genres were stored as a
single byte that encoded a particular genre from a fixed list.
Unfortunately, those codes live on in ID3v2-if the text of the genre
frame is a number in parentheses, the number is supposed to be
interpreted as an ID3v1 genre code.  But, again, users of this library
probably won't care about that ancient history.  So, you should provide
a function that automatically translates the genre.  The following
function uses the genre function just defined to extract the actual
genre text and then checks whether it starts with a left parenthesis,
decoding the version 1 genre code with a function you'll define in a
moment if it does:

   (defun translated-genre (id3) (let ((genre (genre id3))) (if (and
genre (char= #\( (char genre 0))) (translate-v1-genre genre) genre)))
Since a version 1 genre code is effectively just an index into an array
of standard names, the easiest way to implement translate-v1-genre is to
extract the number from the genre string and use it as an index into an
actual array.

   (defun translate-v1-genre (genre) (aref *id3-v1-genres*
(parse-integer genre :start 1 :junk-allowed t))) Then all you need to do
is to define the array of names.  The following array of names includes
the 80 official version 1 genres plus the genres created by the authors
of Winamp:

   (defparameter *id3-v1-genres* #( ;; These are the official ID3v1
genres.  "Blues" "Classic Rock" "Country" "Dance" "Disco" "Funk"
"Grunge" "Hip-Hop" "Jazz" "Metal" "New Age" "Oldies" "Other" "Pop" "R&B"
"Rap" "Reggae" "Rock" "Techno" "Industrial" "Alternative" "Ska" "Death
Metal" "Pranks" "Soundtrack" "Euro-Techno" "Ambient" "Trip-Hop" "Vocal"
"Jazz+Funk" "Fusion" "Trance" "Classical" "Instrumental" "Acid" "House"
"Game" "Sound Clip" "Gospel" "Noise" "AlternRock" "Bass" "Soul" "Punk"
"Space" "Meditative" "Instrumental Pop" "Instrumental Rock" "Ethnic"
"Gothic" "Darkwave" "Techno-Industrial" "Electronic" "Pop-Folk"
"Eurodance" "Dream" "Southern Rock" "Comedy" "Cult" "Gangsta" "Top 40"
"Christian Rap" "Pop/Funk" "Jungle" "Native American" "Cabaret" "New
Wave" "Psychadelic" "Rave" "Showtunes" "Trailer" "Lo-Fi" "Tribal" "Acid
Punk" "Acid Jazz" "Polka" "Retro" "Musical" "Rock & Roll" "Hard Rock"

   ;; These were made up by the authors of Winamp but backported into ;;
the ID3 spec.  "Folk" "Folk-Rock" "National Folk" "Swing" "Fast Fusion"
"Bebob" "Latin" "Revival" "Celtic" "Bluegrass" "Avantgarde" "Gothic
Rock" "Progressive Rock" "Psychedelic Rock" "Symphonic Rock" "Slow Rock"
"Big Band" "Chorus" "Easy Listening" "Acoustic" "Humour" "Speech"
"Chanson" "Opera" "Chamber Music" "Sonata" "Symphony" "Booty Bass"
"Primus" "Porn Groove" "Satire" "Slow Jam" "Club" "Tango" "Samba"
"Folklore" "Ballad" "Power Ballad" "Rhythmic Soul" "Freestyle" "Duet"
"Punk Rock" "Drum Solo" "A capella" "Euro-House" "Dance Hall"

   ;; These were also invented by the Winamp folks but ignored by the ;;
ID3 authors.  "Goa" "Drum & Bass" "Club-House" "Hardcore" "Terror"
"Indie" "BritPop" "Negerpunk" "Polsk Punk" "Beat" "Christian Gangsta
Rap" "Heavy Metal" "Black Metal" "Crossover" "Contemporary Christian"
"Christian Rock" "Merengue" "Salsa" "Thrash Metal" "Anime" "Jpop"
"Synthpop")) Once again, it probably feels like you wrote a ton of code
in this chapter.  But if you put it all in a file, or if you download
the version from this book's Web site, you'll see it's just not that
many lines-most of the pain of writing this library stems from having to
understand the intricacies of the ID3 format itself.  Anyway, now you
have a major piece of what you'll turn into a streaming MP3 server in
Chapters 27, 28, and 29.  The other major bit of infrastructure you'll
need is a way to write server-side Web software, the topic of the next
chapter.


File: pcl.info,  Node: Chapter 26,  Next: Chapter 27,  Prev: Chapter 25,  Up: Top

26. Practical: Web Programming with AllegroServe
================================================

In this chapter you'll look at one way to develop Web-based programs in
Common Lisp, using the open-source AllegroServe Web server.  This isn't
meant as a full introduction to AllegroServe.  And I'm certainly not
going to cover anything more than a tiny corner of the larger topic of
Web programming.  My goal here is to cover enough of the basics of using
AllegroServe that you'll be able, in Chapter 29, to develop an
application for browsing a library of MP3 files and streaming them to an
MP3 client.  Similarly, this chapter will serve as a brief introduction
to Web programming for folks new to the topic.

* Menu:

* 26-1::       A 30-Second Intro to Server-Side Web Programming
* 26-2::       AllegroServe
* 26-3::       Generating Dynamic Content with AllegroServe
* 26-4::       Generating HTML
* 26-5::       HTML Macros
* 26-6::       Query Parameters
* 26-7::       Cookies
* 26-8::       A Small Application Framework
* 26-9::       The Implementation


File: pcl.info,  Node: 26-1,  Next: 26-2,  Prev: Chapter 26,  Up: Chapter 26

A 30-Second Intro to Server-Side Web Programming
================================================

While Web programming today typically involves quite a number of
software frameworks and different protocols, the core bits of Web
programming haven't changed much since they were invented in the early
1990s.  For simple applications, such as the one you'll write in Chapter
29, you need to understand only a few key concepts, so I'll review them
quickly here.  Experienced Web programmers can skim or skip the rest of
this section.1

   To start, you need to understand the roles the Web browser and the
Web server play in Web programming.  While a modern browser comes with a
lot of bells and whistles, the core functionality of a Web browser is to
request Web pages from a Web server and then render them.  Typically
those pages will be written in the Hypertext Markup Language (HTML),
which tells the browser how to render the page, including where to
insert inline images and links to other Web pages.  HTML consists of
text marked up with tags that give the text a structure that the browser
uses when rendering the page.  For instance, a simple HTML document
looks like this:

   <html> <head> <title>Hello</title> </head> <body> <p>Hello,
world!</p> <p>This is a picture: <img src="some-image.gif"></p> <p>This
is a <a href="another-page.html">link</a> to another page.</p> </body>
</html> Figure 26-1 shows how the browser renders this page.

   Figure 26-1.  Sample Web page The browser and server communicate
using a protocol called the Hypertext Transfer Protocol (HTTP). While
you don't need to worry about the details of the protocol, it's worth
understanding that it consists entirely of a sequence of requests
initiated by the browser and responses generated by the server.  That
is, the browser connects to the Web server and sends a request that
includes, at the least, the desired URL and the version of HTTP that the
browser speaks.  The browser can also include data in its request;
that's how the browser submits HTML forms to the server.

   To reply to a request, the server sends a response made up of a set
of headers and a body.  The headers contain information about the body,
such as what type of data it is (for instance, HTML, plain text, or an
image), and the body is the data itself, which is then rendered by the
browser.  The server can also send an error response telling the browser
that its request couldn't be answered for some reason.

   And that's pretty much it.  Once the browser has received the
complete response from the server, there's no communication between the
browser and the server until the next time the browser decides to
request a page from the server.2 This is the main constraint of Web
programming-there's no way for code running on the server to affect what
the user sees in their browser unless the browser issues a new request
to the server.3

   Some Web pages, called static pages, are simply HTML files stored on
the Web server and served up when requested by the browser.  Dynamic
pages, on the other hand, consist of HTML generated each time the page
is requested by a browser.  For instance, a dynamic page might be
generated by querying a database and then constructing HTML to represent
the results of the query.4

   When generating its response to a request, server-side code has four
main pieces of information to act on.  The first piece of information is
the requested URL. Typically, however, the URL is used by the Web server
itself to determine what code is responsible for generating the
response.  Next, if the URL contains a question mark, everything after
the question mark is considered to be a query string, which is typically
ignored by the Web server except that it makes it available to the code
generating the response.  Most of the time the query string contains a
set of key/value pairs.  The request from the browser can also contain
post data, which also usually consists of key/value pairs.  Post data is
typically used to submit HTML forms.  The key/value pairs supplied in
either the query string or the post data are collectively called the
query parameters.

   Finally, in order to string together a sequence of individual
requests from the same browser, code running in the server can set a
cookie, sending a special header in its response to the browser that
contains a bit of opaque data called a cookie.  After a cookie is set by
a particular server, the browser will send the cookie with each request
it sends to that server.  The browser doesn't care about the data in the
cookie-it just echoes it back to the server for the server-side code to
interpret however it wants.

   These are the primitive elements on top of which 99 percent of
server-side Web programming is built.  The browser sends a request, the
server finds some code to handle the request and runs it, and the code
uses query parameters and cookies to determine what to do.


File: pcl.info,  Node: 26-2,  Next: 26-3,  Prev: 26-1,  Up: Chapter 26

AllegroServe
============

You can serve Web content using Common Lisp in a number of ways; there
are at least three open-source Web servers written in Common Lisp as
well as plug-ins such as mod_lisp5 and Lisplets6 that allow the Apache
Web server or any Java Servlet container to delegate requests to a Lisp
server running in a separate process.

   For this chapter, you'll use a version of the open-source Web server
AllegroServe, originally written by John Foderaro at Franz Inc..
AllegroServe is included in the version of Allegro available from Franz
for use with this book.  If you're not using Allegro, you can use
PortableAllegroServe, a friendly fork of the AllegroServe code base,
which includes an Allegro compatibility layer that allows
PortableAllegroServe to run on most Common Lisps.  The code you'll write
in this chapter and in Chapter 29 should run in both vanilla
AllegroServe and PortableAllegroServe.

   AllegroServe provides a programming model similar in spirit to Java
Servlets-each time a browser requests a page, AllegroServe parses the
request and looks up an object, called an entity, which handles the
request.  Some entity classes provided as part of AllegroServe know how
to serve static content-either individual files or the contents of a
directory tree.  Others, the ones I'll spend most of this chapter
discussing, run arbitrary Lisp code to generate the response.7

   But before I get to that, you need to know how to start AllegroServe
and set it up to serve a few files.  The first step is to load the
AllegroServe code into your Lisp image.  In Allegro, you can simply type
(require :aserve).  In other Lisps (or in Allegro), you can load
PortableAllegroServe by loading the file INSTALL.lisp at the top of the
portableaserve directory tree.  Loading AllegroServe will create three
new packages, NET.ASERVE, NET.HTML.GENERATOR, and NET.ASERVE.CLIENT.8

   After loading the server, you start it with the function start in the
NET.ASERVE package.  To have easy access to the symbols exported from
NET.ASERVE, from COM.GIGAMONKEYS.HTML (a package I'll discuss in a
moment), and from the rest of Common Lisp, you should create a new
package to play in like this:

   CL-USER> (defpackage :com.gigamonkeys.web (:use :cl :net.aserve
:com.gigamonkeys.html)) #<The COM.GIGAMONKEYS.WEB package> Now switch to
that package with this IN-PACKAGE expression:

   CL-USER> (in-package :com.gigamonkeys.web) #<The COM.GIGAMONKEYS.WEB
package> WEB> Now you can use the exported names from NET.ASERVE without
qualification.  The function start starts the server.  It takes quite a
number of keyword parameters, but the only one you need to pass is
:port, which specifies the port to listen on.  You should probably use a
high port such as 2001 instead of the default port for HTTP servers, 80,
because on Unix-derived operating systems only the root user can listen
on ports below 1024.  To run AllegroServe listening on port 80 on Unix,
you'd need to start Lisp as root and then use the :setuid and :setgid
parameters to tell start to switch its identity after opening the port.
You can start a server listening on port 2001 like this:

   WEB> (start :port 2001) #<WSERVER port 2001  #x72511c72> The server
is now running in your Lisp.  It's possible you'll get an error that
says something about "port already in use" when you try to start the
server.  This means port 2001 is already in use by some other server on
your machine.  In that case, the simplest fix is to use a different
port, supplying a different argument to start and then using that value
instead of 2001 in the URLs used throughout this chapter.

   You can continue to interact with Lisp via the REPL because
AllegroServe starts its own threads to handle requests from browsers.
This means, among other things, that you can use the REPL to get a view
into the guts of your server while it's running, which makes debugging
and testing a lot easier than if the server is a complete black box.

   Assuming you're running Lisp on the same machine as your browser, you
can check that the server is up and running by pointing your browser at
http://localhost:2001/.  At this point you should get a page-not-found
error message in the browser since you haven't published anything yet.
But the error message will be from AllegroServe; it'll say so at the
bottom of the page.  On the other hand, if the browser displays an error
dialog that says something like "The connection was refused when
attempting to contact localhost:2001," it means either that the server
isn't running or that you started it with a different port than 2001.

   Now you can publish some files.  Suppose you have a file hello.html
in the directory /tmp/html with the following contents:

   <html> <head> <title>Hello</title> </head> <body> <p>Hello,
world!</p> </body> </html> You can publish it individually with the
publish-file function.

   WEB> (publish-file :path "/hello.html" :file "/tmp/html/hello.html")
#<NET.ASERVE::FILE-ENTITY  #x725eddea> The :path argument is the path
that will appear in the URL requested by the browser, while the :file
argument is the name of the file in the file system.  After evaluating
the publish-file expression, you can point your browser to
http://localhost:2001/hello.html, and it should display a page something
like Figure 26-2.

   Figure 26-2.  http://localhost:2001/hello.html You could also publish
a whole directory tree of files using the publish-directory function.
First let's clear out the already published entity with the following
call to publish-file:

   WEB> (publish-file :path "/hello.html" :remove t) NIL Now you can
publish the whole /tmp/html/ directory (and all its subdirectories) with
the publish-directory function.

   WEB> (publish-directory :prefix "/" :destination "/tmp/html/")
#<NET.ASERVE::DIRECTORY-ENTITY  #x72625aa2> In this case, the :prefix
argument specifies the beginning of the path part of URLs that should be
handled by this entity.  Thus, if the server receives a request for
http://localhost:2001/foo/bar.html, the path is /foo/bar.html, which
starts with /.  This path is then translated to a filename by replacing
the prefix, /, with the destination, /tmp/html/.  Thus, the URL
http://localhost:2001/hello.html will still be translated into a request
for the file /tmp/html/hello.html.


File: pcl.info,  Node: 26-3,  Next: 26-4,  Prev: 26-2,  Up: Chapter 26

Generating Dynamic Content with AllegroServe
============================================

Publishing entities that generate dynamic content is nearly as simple as
publishing static content.  The functions publish and publish-prefix are
the dynamic analogs of publish-file and publish-directory.  The basic
idea of these two functions is that you publish a function that will be
called to generate the response to a request for either a specific URL
or any URL with a given prefix.  The function will be called with two
arguments: an object representing the request and the published entity.
Most of time you don't need to do anything with the entity object except
to pass it along to a couple macros I'll discuss in a moment.  On the
other hand, you'll use the request object to obtain information
submitted by the browser-query parameters included in the URL or data
posted using an HTML form.

   For a trivial example of using a function to generate dynamic
content, let's write a function that generates a page with a different
random number each time it's requested.

   (defun random-number (request entity) (with-http-response (request
entity :content-type "text/html") (with-http-body (request entity)
(format (request-reply-stream request) "<html>~ 
<head><title>Random</title></head>~  <body>~  <p>Random number: ~d</p>~ 
</body>~  </html>~  " (random 1000))))) The macros with-http-response
and with-http-body are part of AllegroServe.  The former starts the
process of generating an HTTP response and can be used, as here, to
specify things such as the type of content that will be returned.  It
also handles various parts of HTTP such as dealing with
If-Modified-Since requests.  The with-http-body actually sends the HTTP
response headers and then executes its body, which should contain code
that generates the content of the reply.  Within with-http-response but
before the with-http-body, you can add or change HTTP headers to be sent
in the reply.  The function request-reply-stream is also part of
AllegroServe and returns the stream to which you should write output
intended to be sent to the browser.

   As this function shows, you can just use FORMAT to print HTML to the
stream returned by request-reply-stream.  In the next section, I'll show
you more convenient ways to programmatically generate HTML.9

   Now you're ready to publish this function.

   WEB> (publish :path "/random-number" :function 'random-number)
#<COMPUTED-ENTITY  #x7262bab2> As it does in the publish-file function,
the :path argument specifies the path part of the URL that will result
in this function being invoked.  The :function argument specifies either
the name or an actual function object.  Using the name of a function, as
shown here, allows you to redefine the function later without
republishing and have AllegroServe use the new function definition.
After evaluating the call to publish, you can point your browser at
http:// localhost:2001/random-number to get a page with a random number
on it, as shown in Figure 26-3.

   Figure 26-3.  http://localhost:2001/random-number


File: pcl.info,  Node: 26-4,  Next: 26-5,  Prev: 26-3,  Up: Chapter 26

Generating HTML
===============

Although using FORMAT to emit HTML works fine for the simple pages I've
discussed so far, as you start building more elaborate pages it'd be
nice to have a more concise way to generate HTML. Several libraries are
available for generating HTML from an s-expression representation
including one, htmlgen, that's included with AllegroServe.  In this
chapter you'll use a library called FOO,10 which is loosely modeled on
Franz's htmlgen and whose implementation you'll look at in more detail
in Chapters 30 and 31.  For now, however, you just need to know how to
use FOO.

   Generating HTML from within Lisp is quite natural since s-expressions
and HTML are essentially isomorphic.  You can represent HTML elements
with s-expressions by treating each element in HTML as a list "tagged"
with an appropriate first element, such as a keyword symbol of the same
name as the HTML tag.  Thus, the HTML <p>foo</p> is represented by the
s-expression (:p "foo").  Because HTML elements nest the same way lists
in s-expressions do, this scheme extends to more complex HTML. For
instance, this HTML:

   <html> <head> <title>Hello</title> </head> <body> <p>Hello,
world!</p> </body> </html> could be represented with the following
s-expression:

   (:html (:head (:title "Hello")) (:body (:p "Hello, world!")))  HTML
elements with attributes complicate things a bit but not in an
insurmountable way.  FOO supports two ways of including attributes in a
tag.  One is to simply follow the first item of the list with
keyword/value pairs.  The first element that follows a keyword/value
pair that's not itself a keyword symbol marks the beginning of the
element's contents.  Thus, you'd represent this HTML:

   <a href="foo.html">This is a link</a> with the following
s-expression:

   (:a :href "foo.html" "This is a link") The other syntax FOO supports
is to group the tag name and attributes into their own list like this:

   ((:a :href "foo.html") "This is link.")  FOO can use the s-expression
representation of HTML in two ways.  The function emit-html takes an
HTML s-expression and outputs the corresponding HTML.

   WEB> (emit-html '(:html (:head (:title "Hello")) (:body (:p "Hello,
world!"))))  <html> <head> <title>Hello</title> </head> <body> <p>Hello,
world!</p> </body> </html> T However, emit-html isn't always the most
efficient way to generate HTML because its argument must be a complete
s-expression representation of the HTML to be generated.  While it's
easy to build such a representation, it's not always particularly
efficient.  For instance, suppose you wanted to make an HTML page
containing a list of 10,000 random numbers.  You could build the
s-expression using a backquote template and then pass it to emit-html
like this:

   (emit-html '(:html (:head (:title "Random numbers")) (:body (:h1
"Random numbers") (:p ,@(loop repeat 10000 collect (random 1000) collect
" "))))) However, this has to build a tree containing a 10,000-element
list before it can even start emitting HTML, and the whole s-expression
will become garbage as soon as the HTML is emitted.  To avoid this
inefficiency, FOO also provides a macro html, which allows you to embed
bits of Lisp code in the middle of an HTML s-expression.

   Literal values such as strings and numbers in the input to html are
interpolated into the output HTML. Likewise, symbols are treated as
variable references, and code is generated to emit their value at
runtime.  Thus, both of these:

   (html (:p "foo"))

   (let ((x "foo")) (html (:p x))) will emit the following:

   <p>foo</p> List forms that don't start with a keyword symbol are
assumed to be code and are embedded in the generated code.  Any values
the embedded code returns will be ignored, but the code can emit more
HTML by calling html itself.  For instance, to emit the contents of a
list in HTML, you might write this:

   (html (:ul (dolist (item (list 1 2 3)) (html (:li item))))) which
will emit the following HTML:

   <ul> <li>1</li> <li>2</li> <li>3</li> </ul> If you want to emit the
value of a list form, you must wrap it in the pseudotag :print.  Thus,
this expression:

   (html (:p (+ 1 2))) generates this HTML after computing and
discarding the value 3:

   <p></p> To emit the 3, you must write this:

   (html (:p (:print (+ 1 2)))) Or you could compute the value and store
it in a variable outside the call to html like this:

   (let ((x (+ 1 2))) (html (:p x))) Thus, you can use the html macro to
generate the list of random numbers like this:

   (html (:html (:head (:title "Random numbers")) (:body (:h1 "Random
numbers") (:p (loop repeat 10 do (html (:print (random 1000)) " "))))))
The macro version will be quite a bit more efficient than the emit-html
version.  Not only do you never have to generate an s-expression
representing the whole page, also much of the work that emit-html does
at runtime to interpret the s-expression will be done once, when the
macro is expanded, rather than every time the code is run.

   You can control where the output generated by both html and emit-html
is sent with the macro with-html-output, which is part of the FOO
library.  Thus, you can use the with-html-output and html macros from
FOO to rewrite random-number like this:

   (defun random-number (request entity) (with-http-response (request
entity :content-type "text/html") (with-http-body (request entity)
(with-html-output ((request-reply-stream request)) (html (:html (:head
(:title "Random")) (:body (:p "Random number: " (:print (random
1000))))))))))

