This is pcl.info, produced by makeinfo version 5.2 from pcl.texi.


File: pcl.info,  Node: 9-3,  Next: 9-4,  Prev: 9-2,  Up: Chapter 9

Fixing the Return Value
=======================

You can start with fixing test-+ so its return value indicates whether
all the test cases passed.  Since check is responsible for generating
the code that ultimately runs the test cases, you just need to change it
to generate code that also keeps track of the results.

   As a first step, you can make a small change to report-result so it
returns the result of the test case it's reporting.

   (defun report-result (result form) (format t "~:[FAIL~;pass~] ...
~a~%" result form) result) Now that report-result returns the result of
its test case, it might seem you could just change the PROGN to an AND
to combine the results.  Unfortunately, AND doesn't do quite what you
want in this case because of its short-circuiting behavior: as soon as
one test case fails, AND will skip the rest.  On the other hand, if you
had a construct that worked like AND without the short-circuiting, you
could use it in the place of PROGN, and you'd be done.  Common Lisp
doesn't provide such a construct, but that's no reason you can't use it:
it's a trivial matter to write a macro to provide it yourself.

   Leaving test cases aside for a moment, what you want is a macro-let's
call it combine-results-that will let you say this:

   (combine-results (foo) (bar) (baz)) and have it mean something like
this:

   (let ((result t)) (unless (foo) (setf result nil)) (unless (bar)
(setf result nil)) (unless (baz) (setf result nil)) result) The only
tricky bit to writing this macro is that you need to introduce a
variable-result in the previous code-in the expansion.  As you saw in
the previous chapter, using a literal name for variables in macro
expansions can introduce a leak in your macro abstraction, so you'll
need to create a unique name.  This is a job for with-gensyms.  You can
define combine-results like this:

   (defmacro combine-results (&body forms) (with-gensyms (result) '(let
((,result t)) ,@(loop for f in forms collect '(unless ,f (setf ,result
nil))) ,result))) Now you can fix check by simply changing the expansion
to use combine-results instead of PROGN.

   (defmacro check (&body forms) '(combine-results ,@(loop for f in
forms collect '(report-result ,f ',f)))) With that version of check,
test-+ should emit the results of its three test expressions and then
return T to indicate that everything passed.4

   CL-USER> (test-+) pass ...  (= (+ 1 2) 3) pass ...  (= (+ 1 2 3) 6)
pass ...  (= (+ -1 -3) -4) T And if you change one of the test cases so
it fails,5 the final return value changes to NIL.

   CL-USER> (test-+) pass ...  (= (+ 1 2) 3) pass ...  (= (+ 1 2 3) 6)
FAIL ...  (= (+ -1 -3) -5) NIL


File: pcl.info,  Node: 9-4,  Next: 9-5,  Prev: 9-3,  Up: Chapter 9

Better Result Reporting
=======================

As long as you have only one test function, the current result reporting
is pretty clear.  If a particular test case fails, all you have to do is
find the test case in the check form and figure out why it's failing.
But if you write a lot of tests, you'll probably want to organize them
somehow, rather than shoving them all into one function.  For instance,
suppose you wanted to add some test cases for the * function.  You might
write a new test function.

   (defun test-* () (check (= (* 2 2) 4) (= (* 3 5) 15))) Now that you
have two test functions, you'll probably want another function that runs
all the tests.  That's easy enough.

   (defun test-arithmetic () (combine-results (test-+) (test-*))) In
this function you use combine-results instead of check since both test-+
and test-* will take care of reporting their own results.  When you run
test-arithmetic, you'll get the following results:

   CL-USER> (test-arithmetic) pass ...  (= (+ 1 2) 3) pass ...  (= (+ 1
2 3) 6) pass ...  (= (+ -1 -3) -4) pass ...  (= (* 2 2) 4) pass ...  (=
(* 3 5) 15) T Now imagine that one of the test cases failed and you need
to track down the problem.  With only five test cases and two test
functions, it won't be too hard to find the code of the failing test
case.  But suppose you had 500 test cases spread across 20 functions.
It might be nice if the results told you what function each test case
came from.

   Since the code that prints the results is centralized in
report-result, you need a way to pass information about what test
function you're in to report-result.  You could add a parameter to
report-result to pass this information, but check, which generates the
calls to report-result, doesn't know what function it's being called
from, which means you'd also have to change the way you call check,
passing it an argument that it simply passes onto report-result.

   This is exactly the kind of problem dynamic variables were designed
to solve.  If you create a dynamic variable that each test function
binds to the name of the function before calling check, then
report-result can use it without check having to know anything about it.

   Step one is to declare the variable at the top level.

   (defvar *test-name* nil) Now you need to make another tiny change to
report-result to include *test-name* in the FORMAT output.

   (format t "~:[FAIL~;pass~] ...  ~a: ~a~%" result *test-name* form)
With those changes, the test functions will still work but will produce
the following output because *test-name* is never rebound:

   CL-USER> (test-arithmetic) pass ...  NIL: (= (+ 1 2) 3) pass ...
NIL: (= (+ 1 2 3) 6) pass ...  NIL: (= (+ -1 -3) -4) pass ...  NIL: (=
(* 2 2) 4) pass ...  NIL: (= (* 3 5) 15) T For the name to be reported
properly, you need to change the two test functions.

   (defun test-+ () (let ((*test-name* 'test-+)) (check (= (+ 1 2) 3) (=
(+ 1 2 3) 6) (= (+ -1 -3) -4))))

   (defun test-* () (let ((*test-name* 'test-*)) (check (= (* 2 2) 4) (=
(* 3 5) 15)))) Now the results are properly labeled.

   CL-USER> (test-arithmetic) pass ...  TEST-+: (= (+ 1 2) 3) pass ...
TEST-+: (= (+ 1 2 3) 6) pass ...  TEST-+: (= (+ -1 -3) -4) pass ...
TEST-*: (= (* 2 2) 4) pass ...  TEST-*: (= (* 3 5) 15) T


File: pcl.info,  Node: 9-5,  Next: 9-6,  Prev: 9-4,  Up: Chapter 9

An Abstraction Emerges
======================

In fixing the test functions, you've introduced several new bits of
duplication.  Not only does each function have to include the name of
the function twice-once as the name in the DEFUN and once in the binding
of *test-name*-but the same three-line code pattern is duplicated
between the two functions.  You could remove the duplication simply on
the grounds that duplication is bad.  But if you look more closely at
the root cause of the duplication, you can learn an important lesson
about how to use macros.

   The reason both these functions start the same way is because they're
both test functions.  The duplication arises because, at the moment,
test function is only half an abstraction.  The abstraction exists in
your mind, but in the code there's no way to express "this is a test
function" other than to write code that follows a particular pattern.

   Unfortunately, partial abstractions are a crummy tool for building
software.  Because a half abstraction is expressed in code by a
manifestation of the pattern, you're guaranteed to have massive code
duplication with all the normal bad consequences that implies for
maintainability.  More subtly, because the abstraction exists only in
the minds of programmers, there's no mechanism to make sure different
programmers (or even the same programmer working at different times)
actually understand the abstraction the same way.  To make a complete
abstraction, you need a way to express "this is a test function" and
have all the code required by the pattern be generated for you.  In
other words, you need a macro.

   Because the pattern you're trying to capture is a DEFUN plus some
boilerplate code, you need to write a macro that will expand into a
DEFUN. You'll then use this macro, instead of a plain DEFUN to define
test functions, so it makes sense to call it deftest.

   (defmacro deftest (name parameters &body body) '(defun ,name
,parameters (let ((*test-name* ',name)) ,@body))) With this macro you
can rewrite test-+ as follows:

   (deftest test-+ () (check (= (+ 1 2) 3) (= (+ 1 2 3) 6) (= (+ -1 -3)
-4)))


File: pcl.info,  Node: 9-6,  Next: 9-7,  Prev: 9-5,  Up: Chapter 9

A Hierarchy of Tests
====================

Now that you've established test functions as first-class citizens, the
question might arise, should test-arithmetic be a test function?  As
things stand, it doesn't really matter-if you did define it with
deftest, its binding of *test-name* would be shadowed by the bindings in
test-+ and test-* before any results are reported.

   But now imagine you've got thousands of test cases to organize.  The
first level of organization is provided by test functions such as test-+
and test-* that directly call check.  But with thousands of test cases,
you'll likely need other levels of organization.  Functions such as
test-arithmetic can group related test functions into test suites.  Now
suppose some low-level test functions are called from multiple test
suites.  It's not unheard of for a test case to pass in one context but
fail in another.  If that happens, you'll probably want to know more
than just what low-level test function contains the test case.

   If you define the test suite functions such as test-arithmetic with
deftest and make a small change to the *test-name* bookkeeping, you can
have results reported with a "fully qualified" path to the test case,
something like this:

   pass ...  (TEST-ARITHMETIC TEST-+): (= (+ 1 2) 3) Because you've
already abstracted the process of defining a test function, you can
change the bookkeeping details without modifying the code of the test
functions.6 To make *test-name* hold a list of test function names
instead of just the name of the most recently entered test function, you
just need to change this binding form:

   (let ((*test-name* ',name)) to the following:

   (let ((*test-name* (append *test-name* (list ',name)))) Since APPEND
returns a new list made up of the elements of its arguments, this
version will bind *test-name* to a list containing the old contents of
*test-name* with the new name tacked onto the end.7 When each test
function returns, the old value of *test-name* will be restored.

   Now you can redefine test-arithmetic with deftest instead of DEFUN.

   (deftest test-arithmetic () (combine-results (test-+) (test-*))) The
results now show exactly how you got to each test expression.

   CL-USER> (test-arithmetic) pass ...  (TEST-ARITHMETIC TEST-+): (= (+
1 2) 3) pass ...  (TEST-ARITHMETIC TEST-+): (= (+ 1 2 3) 6) pass ...
(TEST-ARITHMETIC TEST-+): (= (+ -1 -3) -4) pass ...  (TEST-ARITHMETIC
TEST-*): (= (* 2 2) 4) pass ...  (TEST-ARITHMETIC TEST-*): (= (* 3 5)
15) T As your test suite grows, you can add new layers of test
functions; as long as they're defined with deftest, the results will be
reported correctly.  For instance, the following:

   (deftest test-math () (test-arithmetic)) would generate these
results:

   CL-USER> (test-math) pass ...  (TEST-MATH TEST-ARITHMETIC TEST-+): (=
(+ 1 2) 3) pass ...  (TEST-MATH TEST-ARITHMETIC TEST-+): (= (+ 1 2 3) 6)
pass ...  (TEST-MATH TEST-ARITHMETIC TEST-+): (= (+ -1 -3) -4) pass ...
(TEST-MATH TEST-ARITHMETIC TEST-*): (= (* 2 2) 4) pass ...  (TEST-MATH
TEST-ARITHMETIC TEST-*): (= (* 3 5) 15) T


File: pcl.info,  Node: 9-7,  Next: Chapter 10,  Prev: 9-6,  Up: Chapter 9

Wrapping Up
===========

You could keep going, adding more features to this test framework.  But
as a framework for writing tests with a minimum of busywork and easily
running them from the REPL, this is a reasonable start.  Here's the
complete code, all 26 lines of it:

   (defvar *test-name* nil)

   (defmacro deftest (name parameters &body body) "Define a test
function.  Within a test function we can call other test functions or
use 'check' to run individual test cases."  '(defun ,name ,parameters
(let ((*test-name* (append *test-name* (list ',name)))) ,@body)))

   (defmacro check (&body forms) "Run each expression in 'forms' as a
test case."  '(combine-results ,@(loop for f in forms collect
'(report-result ,f ',f))))

   (defmacro combine-results (&body forms) "Combine the results (as
booleans) of evaluating 'forms' in order."  (with-gensyms (result) '(let
((,result t)) ,@(loop for f in forms collect '(unless ,f (setf ,result
nil))) ,result)))

   (defun report-result (result form) "Report the results of a single
test case.  Called by 'check'."  (format t "~:[FAIL~;pass~] ...  ~a:
~a~%" result *test-name* form) result) It's worth reviewing how you got
here because it's illustrative of how programming in Lisp often goes.

   You started by defining a simple version of your problem-how to
evaluate a bunch of boolean expressions and find out if they all
returned true.  Just ANDing them together worked and was syntactically
clean but revealed the need for better result reporting.  So you wrote
some really simpleminded code, chock-full of duplication and error-prone
idioms that reported the results the way you wanted.

   The next step was to see if you could refactor the second version
into something as clean as the former.  You started with a standard
refactoring technique of extracting some code into a function,
report-result.  Unfortunately, you could see that using report-result
was going to be tedious and error-prone since you had to pass the test
expression twice, once for the value and once as quoted data.  So you
wrote the check macro to automate the details of calling report-result
correctly.

   While writing check, you realized as long as you were generating
code, you could make a single call to check to generate multiple calls
to report-result, getting you back to a version of test-+ about as
concise as the original AND version.

   At that point you had the check API nailed down, which allowed you to
start mucking with how it worked on the inside.  The next task was to
fix check so the code it generated would return a boolean indicating
whether all the test cases had passed.  Rather than immediately hacking
away at check, you paused to indulge in a little language design by
fantasy.  What if-you fantasized-there was already a
non-short-circuiting AND construct.  Then fixing check would be trivial.
Returning from fantasyland you realized there was no such construct but
that you could write one in a few lines.  After writing combine-results,
the fix to check was indeed trivial.

   At that point all that was left was to make a few more improvements
to the way you reported test results.  Once you started making changes
to the test functions, you realized those functions represented a
special category of function that deserved its own abstraction.  So you
wrote deftest to abstract the pattern of code that turns a regular
function into a test function.

   With deftest providing an abstraction barrier between the test
definitions and the underlying machinery, you were able to enhance the
result reporting without touching the test functions.

   Now, with the basics of functions, variables, and macros mastered,
and a little practical experience using them, you're ready to start
exploring Common Lisp's rich standard library of functions and data
types.


File: pcl.info,  Node: Chapter 10,  Next: Chapter 11,  Prev: Chapter 9,  Up: Top

10. Numbers, Characters, and Strings
====================================

While functions, variables, macros, and 25 special operators provide the
basic building blocks of the language itself, the building blocks of
your programs will be the data structures you use.  As Fred Brooks
observed in The Mythical Man-Month, "Representation is the essence of
programming."  (1)

   Common Lisp provides built-in support for most of the data types
typically found in modern languages: numbers (integer, floating point,
and complex), characters, strings, arrays (including multidimensional
arrays), lists, hash tables, input and output streams, and an
abstraction for portably representing filenames.  Functions are also a
first-class data type in Lisp-they can be stored in variables, passed as
arguments, returned as return values, and created at runtime.

   And these built-in types are just the beginning.  They're defined in
the language standard so programmers can count on them being available
and because they tend to be easier to implement efficiently when tightly
integrated with the rest of the implementation.  But, as you'll see in
later chapters, Common Lisp also provides several ways for you to define
new data types, define operations on them, and integrate them with the
built-in data types.

   For now, however, you can start with the built-in data types.
Because Lisp is a high-level language, the details of exactly how
different data types are implemented are largely hidden.  From your
point of view as a user of the language, the built-in data types are
defined by the functions that operate on them.  So to learn a data type,
you just have to learn about the functions you can use with it.
Additionally, most of the built-in data types have a special syntax that
the Lisp reader understands and that the Lisp printer uses.  That's why,
for instance, you can write strings as "foo"; numbers as 123, 1/23, and
1.23; and lists as (a b c).  I'll describe the syntax for different
kinds of objects when I describe the functions for manipulating them.

   In this chapter, I'll cover the built-in "scalar" data types:
numbers, characters, and strings.  Technically, strings aren't true
scalars-a string is a sequence of characters, and you can access
individual characters and manipulate strings with a function that
operates on sequences.  But I'll discuss strings here because most of
the string-specific functions manipulate them as single values and also
because of the close relation between several of the string functions
and their character counterparts.

* Menu:

* 10-1::                 Numbers
* 10-2::                 Numeric Literals
* 10-3::                 Basic Math
* 10-4::                 Numeric Comparisons
* 10-5::                 Higher Math
* 10-6::                 Characters
* 10-7::                 Character Comparisons
* 10-8::                 Strings
* 10-9::                 String Comparisons

   ---------- Footnotes ----------

   (1) Fred Brooks, The Mythical Man-Month, 20th Anniversary Edition
(Boston: Addison-Wesley, 1995), p.  103.  Emphasis in original.


File: pcl.info,  Node: 10-1,  Next: 10-2,  Prev: Chapter 10,  Up: Chapter 10

Numbers
=======

Math, as Barbie says, is hard.  (1) Common Lisp can't make the math part
any easier, but it does tend to get in the way a lot less than other
programming languages.  That's not surprising given its mathematical
heritage.  Lisp was originally designed by a mathematician as a tool for
studying mathematical functions.  And one of the main projects of the
MAC project at MIT was the Macsyma symbolic algebra system, written in
Maclisp, one of Common Lisp's immediate predecessors.  Additionally,
Lisp has been used as a teaching language at places such as MIT where
even the computer science professors cringe at the thought of telling
their students that 10/4 = 2, leading to Lisp's support for exact
ratios.  And at various times Lisp has been called upon to compete with
FORTRAN in the high-performance numeric computing arena.

   One of the reasons Lisp is a nice language for math is its numbers
behave more like true mathematical numbers than the approximations of
numbers that are easy to implement in finite computer hardware.  For
instance, integers in Common Lisp can be almost arbitrarily large rather
than being limited by the size of a machine word.  (2) And dividing two
integers results in an exact ratio, not a truncated value.  And since
ratios are represented as pairs of arbitrarily sized integers, ratios
can represent arbitrarily precise fractions.  (3)

   On the other hand, for high-performance numeric programming, you may
be willing to trade the exactitude of rationals for the speed offered by
using the hardware's underlying floating-point operations.  So, Common
Lisp also offers several types of floating-point numbers, which are
mapped by the implementation to the appropriate hardware-supported
floating-point representations.  (4) Floats are also used to represent
the results of a computation whose true mathematical value would be an
irrational number.

   Finally, Common Lisp supports complex numbers-the numbers that result
from doing things such as taking square roots and logarithms of negative
numbers.  The Common Lisp standard even goes so far as to specify the
principal values and branch cuts for irrational and transcendental
functions on the complex domain.

   ---------- Footnotes ----------

   (1) Mattel's Teen Talk Barbie

   (2) Obviously, the size of a number that can be represented on a
computer with finite memory is still limited in practice; furthermore,
the actual representation of bignums used in a particular Common Lisp
implementation may place other limits on the size of number that can be
represented.  But these limits are going to be well beyond
"astronomically" large numbers.  For instance, the number of atoms in
the universe is estimated to be less than 2^269; current Common Lisp
implementations can easily handle numbers up to and beyond 2^262144.

   (3) Folks interested in using Common Lisp for intensive numeric
computation should note that a naive comparison of the performance of
numeric code in Common Lisp and languages such as C or FORTRAN will
probably show Common Lisp to be much slower.  This is because something
as simple as (+ a b) in Common Lisp is doing a lot more than the
seemingly equivalent a + b in one of those languages.  Because of Lisp's
dynamic typing and support for things such as arbitrary precision
rationals and complex numbers, a seemingly simple addition is doing a
lot more than an addition of two numbers that are known to be
represented by machine words.  However, you can use declarations to give
Common Lisp information about the types of numbers you're using that
will enable it to generate code that does only as much work as the code
that would be generated by a C or FORTRAN compiler.  Tuning numeric code
for this kind of performance is beyond the scope of this book, but it's
certainly possible.

   (4) While the standard doesn't require it, many Common Lisp
implementations support the IEEE standard for floating-point arithmetic,
IEEE Standard for Binary Floating-Point Arithmetic, ANSI/ IEEE Std
754-1985 (Institute of Electrical and Electronics Engineers, 1985).


File: pcl.info,  Node: 10-2,  Next: 10-3,  Prev: 10-1,  Up: Chapter 10

Numeric Literals
================

You can write numeric literals in a variety of ways; you saw a few
examples in Chapter 4.  However, it's important to keep in mind the
division of labor between the Lisp reader and the Lisp evaluator-the
reader is responsible for translating text into Lisp objects, and the
Lisp evaluator then deals only with those objects.  For a given number
of a given type, there can be many different textual representations,
all of which will be translated to the same object representation by the
Lisp reader.  For instance, you can write the integer 10 as 10, 20/2,
#xA, or any of a number of other ways, but the reader will translate all
these to the same object.  When numbers are printed back out-say, at the
REPL-they're printed in a canonical textual syntax that may be different
from the syntax used to enter the number.  For example:

     CL-USER> 10
     10
     CL-USER> 20/2
     10
     CL-USER> #xa
     10

   The syntax for integer values is an optional sign (+ or -) followed
by one or more digits.  Ratios are written as an optional sign and a
sequence of digits, representing the numerator, a slash (/), and another
sequence of digits representing the denominator.  All rational numbers
are "canonicalized" as they're read-that's why 10 and 20/2 are both read
as the same number, as are 3/4 and 6/8.  Rationals are printed in
"reduced" form-integer values are printed in integer syntax and ratios
with the numerator and denominator reduced to lowest terms.

   It's also possible to write rationals in bases other than 10.  If
preceded by #B or #b, a rational literal is read as a binary number with
0 and 1 as the only legal digits.  An #O or #o indicates an octal number
(legal digits 0-7), and #X or #x indicates hexadecimal (legal digits 0-F
or 0-f).  You can write rationals in other bases from 2 to 36 with #nR
where n is the base (always written in decimal).  Additional "digits"
beyond 9 are taken from the letters A-Z or a-z.  Note that these radix
indicators apply to the whole rational-it's not possible to write a
ratio with the numerator in one base and denominator in another.  Also,
you can write integer values, but not ratios, as decimal digits
terminated with a decimal point.  (1) Some examples of rationals, with
their canonical, decimal representation are as follows:

     123                            ==> 123
     +123                           ==> 123
     -123                           ==> -123
     123.                           ==> 123
     2/3                            ==> 2/3
     -2/3                           ==> -2/3
     4/6                            ==> 2/3
     6/3                            ==> 2
     #b10101                        ==> 21
     #b1010/1011                    ==> 10/11
     #o777                          ==> 511
     #xDADA                         ==> 56026
     #36rABCDEFGHIJKLMNOPQRSTUVWXYZ ==> 8337503854730415241050377135811259267835

   You can also write floating-point numbers in a variety of ways.
Unlike rational numbers, the syntax used to notate a floating-point
number can affect the actual type of number read.  Common Lisp defines
four subtypes of floating-point number: short, single, double, and long.
Each subtype can use a different number of bits in its representation,
which means each subtype can represent values spanning a different range
and with different precision.  More bits gives a wider range and more
precision.  (2)

   The basic format for floating-point numbers is an optional sign
followed by a nonempty sequence of decimal digits possibly with an
embedded decimal point.  This sequence can be followed by an exponent
marker for "computerized scientific notation."  (3) The exponent marker
consists of a single letter followed by an optional sign and a sequence
of digits, which are interpreted as the power of ten by which the number
before the exponent marker should be multiplied.  The letter does double
duty: it marks the beginning of the exponent and indicates what
floating- point representation should be used for the number.  The
exponent markers s, f, d, l (and their uppercase equivalents) indicate
short, single, double, and long floats, respectively.  The letter e
indicates that the default representation (initially single-float)
should be used.

   Numbers with no exponent marker are read in the default
representation and must contain a decimal point followed by at least one
digit to distinguish them from integers.  The digits in a floating-point
number are always treated as base 10 digits-the #B, #X, #O, and #R
syntaxes work only with rationals.  The following are some example
floating-point numbers along with their canonical representation:

     1.0      ==> 1.0
     1e0      ==> 1.0
     1d0      ==> 1.0d0
     123.0    ==> 123.0
     123e0    ==> 123.0
     0.123    ==> 0.123
     .123     ==> 0.123
     123e-3   ==> 0.123
     123E-3   ==> 0.123
     0.123e20 ==> 1.23e+19
     123d23   ==> 1.23d+25

   Finally, complex numbers are written in their own syntax, namely, #C
or #c followed by a list of two real numbers representing the real and
imaginary part of the complex number.  There are actually five kinds of
complex numbers because the real and imaginary parts must either both be
rational or both be the same kind of floating-point number.

   But you can write them however you want-if a complex is written with
one rational and one floating-point part, the rational is converted to a
float of the appropriate representation.  Similarly, if the real and
imaginary parts are both floats of different representations, the one in
the smaller representation will be upgraded.

   However, no complex numbers have a rational real component and a zero
imaginary part-since such values are, mathematically speaking, rational,
they're represented by the appropriate rational value.  The same
mathematical argument could be made for complex numbers with
floating-point components, but for those complex types a number with a
zero imaginary part is always a different object than the floating-point
number representing the real component.  Here are some examples of
numbers written the complex number syntax:

     #c(2      1)    ==> #c(2 1)
     #c(2/3  3/4)    ==> #c(2/3 3/4)
     #c(2    1.0)    ==> #c(2.0 1.0)
     #c(2.0  1.0d0)  ==> #c(2.0d0 1.0d0)
     #c(1/2  1.0)    ==> #c(0.5 1.0)
     #c(3      0)    ==> 3
     #c(3.0  0.0)    ==> #c(3.0 0.0)
     #c(1/2    0)    ==> 1/2
     #c(-6/3   0)    ==> -2

   ---------- Footnotes ----------

   (1) It's also possible to change the default base the reader uses for
numbers without a specific radix marker by changing the value of the
global variable *READ-BASE*.  However, it's not clear that's the path to
anything other than complete insanity.

   (2) Since the purpose of floating-point numbers is to make efficient
use of floating-point hardware, each Lisp implementation is allowed to
map these four subtypes onto the native floating-point types as
appropriate.  If the hardware supports fewer than four distinct
representations, one or more of the types may be equivalent.

   (3) "Computerized scientific notation" is in scare quotes because,
while commonly used in computer languages since the days of FORTRAN,
it's actually quite different from real scientific notation.  In
particular, something like 1.0e4 means 10000.0, but in true scientific
notation that would be written as 1.0 x 10^4.  And to further confuse
matters, in true scientific notation the letter e stands for the base of
the natural logarithm, so something like 1.0 x e^4, while superficially
similar to 1.0e4, is a completely different value, approximately 54.6.


File: pcl.info,  Node: 10-3,  Next: 10-4,  Prev: 10-2,  Up: Chapter 10

Basic Math
==========

The basic arithmetic operations-addition, subtraction, multiplication,
and division-are supported for all the different kinds of Lisp numbers
with the functions +, -, *, and /.  Calling any of these functions with
more than two arguments is equivalent to calling the same function on
the first two arguments and then calling it again on the resulting value
and the rest of the arguments.  For example, (+ 1 2 3) is equivalent to
(+ (+ 1 2) 3).  With only one argument, + and * return the value; -
returns its negation and / its reciprocal.  (1)

     (+ 1 2)              ==> 3
     (+ 1 2 3)            ==> 6
     (+ 10.0 3.0)         ==> 13.0
     (+ #c(1 2) #c(3 4))  ==> #c(4 6)
     (- 5 4)              ==> 1
     (- 2)                ==> -2
     (- 10 3 5)           ==> 2
     (* 2 3)              ==> 6
     (* 2 3 4)            ==> 24
     (/ 10 5)             ==> 2
     (/ 10 5 2)           ==> 1
     (/ 2 3)              ==> 2/3
     (/ 4)                ==> 1/4

   If all the arguments are the same type of number (rational, floating
point, or complex), the result will be the same type except in the case
where the result of an operation on complex numbers with rational
components yields a number with a zero imaginary part, in which case the
result will be a rational.  However, floating-point and complex numbers
are contagious-if all the arguments are reals but one or more are
floating-point numbers, the other arguments are converted to the nearest
floating-point value in a "largest" floating-point representation of the
actual floating-point arguments.  Floating-point numbers in a "smaller"
representation are also converted to the larger representation.
Similarly, if any of the arguments are complex, any real arguments are
converted to the complex equivalents.

     (+ 1 2.0)             ==> 3.0
     (/ 2 3.0)             ==> 0.6666667
     (+ #c(1 2) 3)         ==> #c(4 2)
     (+ #c(1 2) 3/2)       ==> #c(5/2 2)
     (+ #c(1 1) #c(2 -1))  ==> 3

   Because / doesn't truncate, Common Lisp provides four flavors of
truncating and rounding for converting a real number (rational or
floating point) to an integer: FLOOR truncates toward negative infinity,
returning the largest integer less than or equal to the argument.
CEILING truncates toward positive infinity, returning the smallest
integer greater than or equal to the argument.  TRUNCATE truncates
toward zero, making it equivalent to FLOOR for positive arguments and to
CEILING for negative arguments.  And ROUND rounds to the nearest
integer.  If the argument is exactly halfway between two integers, it
rounds to the nearest even integer.

   Two related functions are MOD and REM, which return the modulus and
remainder of a truncating division on real numbers.  These two functions
are related to the FLOOR and TRUNCATE functions as follows:

     (+ (* (floor    (/ x y)) y) (mod x y)) === x
     (+ (* (truncate (/ x y)) y) (rem x y)) === x

   Thus, for positive quotients they're equivalent, but for negative
quotients they produce different results.  (2)

   The functions 1+ and 1- provide a shorthand way to express adding and
subtracting one from a number.  Note that these are different from the
macros INCF and DECF. 1+ and 1- are just functions that return a new
value, but INCF and DECF modify a place.  The following equivalences
show the relation between INCF/DECF, 1+/1-, and +/-:

     (incf x)    === (setf x (1+ x)) === (setf x (+ x 1))
     (decf x)    === (setf x (1- x)) === (setf x (- x 1))
     (incf x 10) === (setf x (+ x 10))
     (decf x 10) === (setf x (- x 10))

   ---------- Footnotes ----------

   (1) For mathematical consistency, + and * can also be called with no
arguments, in which case they return the appropriate identity: 0 for +
and 1 for *.

   (2) Roughly speaking, MOD is equivalent to the % operator in Perl and
Python, and REM is equivalent to the % in C and Java.  (Technically, the
exact behavior of % in C wasn't specified until the C99 standard.)


File: pcl.info,  Node: 10-4,  Next: 10-5,  Prev: 10-3,  Up: Chapter 10

Numeric Comparisons
===================

The function = is the numeric equality predicate.  It compares numbers
by mathematical value, ignoring differences in type.  Thus, = will
consider mathematically equivalent values of different types equivalent
while the generic equality predicate EQL would consider them
inequivalent because of the difference in type.  (The generic equality
predicate EQUALP, however, uses = to compare numbers.)  If it's called
with more than two arguments, it returns true only if they all have the
same value.  Thus:

     (= 1 1)                        ==> T
     (= 10 20/2)                    ==> T
     (= 1 1.0 #c(1.0 0.0) #c(1 0))  ==> T

   The /= function, conversely, returns true only if all its arguments
are different values.

     (/= 1 1)        ==> NIL
     (/= 1 2)        ==> T
     (/= 1 2 3)      ==> T
     (/= 1 2 3 1)    ==> NIL
     (/= 1 2 3 1.0)  ==> NIL

   The functions <, >, <=, and >= order rationals and floating-point
numbers (in other words, the real numbers.)  Like = and /=, these
functions can be called with more than two arguments, in which case each
argument is compared to the argument to its right.

     (< 2 3)       ==> T
     (> 2 3)       ==> NIL
     (> 3 2)       ==> T
     (< 2 3 4)     ==> T
     (< 2 3 3)     ==> NIL
     (<= 2 3 3)    ==> T
     (<= 2 3 3 4)  ==> T
     (<= 2 3 4 3)  ==> NIL

   To pick out the smallest or largest of several numbers, you can use
the function MIN or MAX, which takes any number of real number arguments
and returns the minimum or maximum value.

     (max 10 11)    ==> 11
     (min -12 -10)  ==> -12
     (max -1 2 -3)  ==> 2

   Some other handy functions are ZEROP, MINUSP, and PLUSP, which test
whether a single real number is equal to, less than, or greater than
zero.  Two other predicates, EVENP and ODDP, test whether a single
integer argument is even or odd.  The P suffix on the names of these
functions is a standard naming convention for predicate functions,
functions that test some condition and return a boolean.


File: pcl.info,  Node: 10-5,  Next: 10-6,  Prev: 10-4,  Up: Chapter 10

Higher Math
===========

The functions you've seen so far are the beginning of the built-in
mathematical functions.  Lisp also supports logarithms: LOG;
exponentiation: EXP and EXPT; the basic trigonometric functions: SIN,
COS, and TAN; their inverses: ASIN, ACOS, and ATAN; hyperbolic
functions: SINH, COSH, and TANH; and their inverses: ASINH, ACOSH, and
ATANH. It also provides functions to get at the individual bits of an
integer and to extract the parts of a ratio or a complex number.  For a
complete list, see any Common Lisp reference.


File: pcl.info,  Node: 10-6,  Next: 10-7,  Prev: 10-5,  Up: Chapter 10

Characters
==========

Common Lisp characters are a distinct type of object from numbers.
That's as it should be-characters are not numbers, and languages that
treat them as if they are tend to run into problems when character
encodings change, say, from 8-bit ASCII to 21-bit Unicode.  (1) Because
the Common Lisp standard didn't mandate a particular representation for
characters, today several Lisp implementations use Unicode as their
"native" character encoding despite Unicode being only a gleam in a
standards body's eye at the time Common Lisp's own standardization was
being wrapped up.

   The read syntax for characters objects is simple: #\ followed by the
desired character.  Thus, #\x is the character x.  Any character can be
used after the #\, including otherwise special characters such as ", (,
and whitespace.  However, writing whitespace characters this way isn't
very (human) readable; an alternative syntax for certain characters is
#\ followed by the character's name.  Exactly what names are supported
depends on the character set and on the Lisp implementation, but all
implementations support the names Space and Newline.  Thus, you should
write #\Space instead of #\ , though the latter is technically legal.
Other semistandard names (that implementations must use if the character
set has the appropriate characters) are Tab, Page, Rubout, Linefeed,
Return, and Backspace.

   ---------- Footnotes ----------

   (1) Even Java, which was designed from the beginning to use Unicode
characters on the theory that Unicode was the going to be the character
encoding of the future, has run into trouble since Java characters are
defined to be a 16-bit quantity and the Unicode 3.1 standard extended
the range of the Unicode character set to require a 21-bit
representation.  Ooops.


File: pcl.info,  Node: 10-7,  Next: 10-8,  Prev: 10-6,  Up: Chapter 10

Character Comparisons
=====================

The main thing you can do with characters, other than putting them into
strings (which I'll get to later in this chapter), is to compare them
with other characters.  Since characters aren't numbers, you can't use
the numeric comparison functions, such as < and >.  Instead, two sets of
functions provide character-specific analogs to the numeric comparators;
one set is case-sensitive and the other case-insensitive.

   The case-sensitive analog to the numeric = is the function CHAR=.
Like =, CHAR= can take any number of arguments and returns true only if
they're all the same character.  The case- insensitive version is
CHAR-EQUAL.

   The rest of the character comparators follow this same naming scheme:
the case-sensitive comparators are named by prepending the analogous
numeric comparator with CHAR; the case-insensitive versions spell out
the comparator name, separated from the CHAR with a hyphen.  Note,
however, that <= and >= are "spelled out" with the logical equivalents
NOT-GREATERP and NOT-LESSP rather than the more verbose LESSP-OR-EQUALP
and GREATERP-OR-EQUALP. Like their numeric counterparts, all these
functions can take one or more arguments.  Table 10-1 summarizes the
relation between the numeric and character comparison functions.

   Table 10-1.  Character Comparison Functions

 [image src="tables/10-1.png" ]

   Other functions that deal with characters provide functions for,
among other things, testing whether a given character is alphabetic or a
digit character, testing the case of a character, obtaining a
corresponding character in a different case, and translating between
numeric values representing character codes and actual character
objects.  Again, for complete details, see your favorite Common Lisp
reference.


File: pcl.info,  Node: 10-8,  Next: 10-9,  Prev: 10-7,  Up: Chapter 10

Strings
=======

As mentioned earlier, strings in Common Lisp are really a composite data
type, namely, a one-dimensional array of characters.  Consequently, I'll
cover many of the things you can do with strings in the next chapter
when I discuss the many functions for manipulating sequences, of which
strings are just one type.  But strings also have their own literal
syntax and a library of functions for performing string-specific
operations.  I'll discuss these aspects of strings in this chapter and
leave the others for Chapter 11.

   As you've seen, literal strings are written enclosed in double
quotes.  You can include any character supported by the character set in
a literal string except double quote (") and backslash (\).  And you can
include these two as well if you escape them with a backslash.  In fact,
backslash always escapes the next character, whatever it is, though this
isn't necessary for any character except for " and itself.  Table 10-2
shows how various literal strings will be read by the Lisp reader.

   Table 10-2.  Literal Strings

 [image src="tables/10-2.png" ]

   Note that the REPL will ordinarily print strings in readable form,
adding the enclosing quotation marks and any necessary escaping
backslashes, so if you want to see the actual contents of a string, you
need to use function such as FORMAT designed to print human-readable
output.  For example, here's what you see if you type a string
containing an embedded quotation mark at the REPL:

     CL-USER> "foo\"bar"
     "foo\"bar"

   FORMAT, on the other hand, will show you the actual string contents:
(1)

     CL-USER> (format t "foo\"bar")
     foo"bar
     NIL

   ---------- Footnotes ----------

   (1) Note, however, that not all literal strings can be printed by
passing them as the second argument to FORMAT since certain sequences of
characters have a special meaning to FORMAT. To safely print an
arbitrary string-say, the value of a variable s-with FORMAT you should
write (format t "~a" s).


File: pcl.info,  Node: 10-9,  Next: Chapter 11,  Prev: 10-8,  Up: Chapter 10

String Comparisons
==================

You can compare strings using a set of functions that follow the same
naming convention as the character comparison functions except with
STRING as the prefix rather than CHAR (see Table 10-3).

   Table 10-3.  String Comparison Functions

 [image src="tables/10-3.png" ]

   However, unlike the character and number comparators, the string
comparators can compare only two strings.  That's because they also take
keyword arguments that allow you to restrict the comparison to a
substring of either or both strings.  The arguments-:start1, :end1,
:start2, and :end2-specify the starting (inclusive) and ending
(exclusive) indices of substrings in the first and second string
arguments.  Thus, the following:

     (string= "foobarbaz" "quuxbarfoo" :start1 3 :end1 6 :start2 4 :end2 7)

   compares the substring "bar" in the two arguments and returns true.
The :end1 and :end2 arguments can be NIL (or the keyword argument
omitted altogether) to indicate that the corresponding substring extends
to the end of the string.

   The comparators that return true when their arguments differ-that is,
all of them except STRING= and STRING-EQUAL-return the index in the
first string where the mismatch was detected.

     (string/= "lisp" "lissome") ==> 3

   If the first string is a prefix of the second, the return value will
be the length of the first string, that is, one greater than the largest
valid index into the string.

     (string< "lisp" "lisper") ==> 4

   When comparing substrings, the resulting value is still an index into
the string as a whole.  For instance, the following compares the
substrings "bar" and "baz" but returns 5 because that's the index of the
r in the first string:

     (string< "foobar" "abaz" :start1 3 :start2 1) ==> 5   ; N.B. not 2

   Other string functions allow you to convert the case of strings and
trim characters from one or both ends of a string.  And, as I mentioned
previously, since strings are really a kind of sequence, all the
sequence functions I'll discuss in the next chapter can be used with
strings.  For instance, you can discover the length of a string with the
LENGTH function and can get and set individual characters of a string
with the generic sequence element accessor function, ELT, or the generic
array element accessor function, AREF. Or you can use the
string-specific accessor, CHAR. But those functions, and others, are the
topic of the next chapter, so let's move on.


File: pcl.info,  Node: Chapter 11,  Next: Chapter 12,  Prev: Chapter 10,  Up: Top

11. Collections
===============

Like most programming languages, Common Lisp provides standard data
types that collect multiple values into a single object.  Every language
slices up the collection problem a little bit differently, but the basic
collection types usually boil down to an integer-indexed array type and
a table type that can be used to map more or less arbitrary keys to
values.  The former are variously called arrays, lists, or tuples; the
latter go by the names hash tables, associative arrays, maps, and
dictionaries.

   Lisp is, of course, famous for its list data structure, and most Lisp
books, following the ontogeny-recapitulates-phylogeny principle of
language instruction, start their discussion of Lisp's collections with
lists.  However, that approach often leads readers to the mistaken
conclusion that lists are Lisp's only collection type.  To make matters
worse, because Lisp's lists are such a flexible data structure, it is
possible to use them for many of the things arrays and hash tables are
used for in other languages.  But it's a mistake to focus too much on
lists; while they're a crucial data structure for representing Lisp code
as Lisp data, in many situations other data structures are more
appropriate.

   To keep lists from stealing the show, in this chapter I'll focus on
Common Lisp's other collection types: vectors and hash tables.  (1)
However, vectors and lists share enough characteristics that Common Lisp
treats them both as subtypes of a more general abstraction, the
sequence.  Thus, you can use many of the functions I'll discuss in this
chapter with both vectors and lists.

* Menu:

* 11-1::                            Vectors
* 11-2::                            Subtypes of Vector
* 11-3::                            Vectors As Sequences
* 11-4::                            Sequence Iterating Functions
* 11-5::                            Higher-Order Function Variants
* 11-6::                            Whole Sequence Manipulations
* 11-7::                            Sorting and Merging
* 11-8::                            Subsequence Manipulations
* 11-9::                            Sequence Predicates
* 11-10::                           Sequence Mapping Functions
* 11-11::                           Hash Tables
* 11-12::                           Hash Table Iteration

   ---------- Footnotes ----------

   (1) Once you're familiar with all the data types Common Lisp offers,
you'll also see that lists can be useful for prototyping data structures
that will later be replaced with something more efficient once it
becomes clear how exactly the data is to be used.


File: pcl.info,  Node: 11-1,  Next: 11-2,  Prev: Chapter 11,  Up: Chapter 11

Vectors
=======

Vectors are Common Lisp's basic integer-indexed collection, and they
come in two flavors.  Fixed-size vectors are a lot like arrays in a
language such as Java: a thin veneer over a chunk of contiguous memory
that holds the vector's elements.  (1) Resizable vectors, on the other
hand, are more like arrays in Perl or Ruby, lists in Python, or the
ArrayList class in Java: they abstract the actual storage, allowing the
vector to grow and shrink as elements are added and removed.

   You can make fixed-size vectors containing specific values with the
function VECTOR, which takes any number of arguments and returns a
freshly allocated fixed-size vector containing those arguments.

     (vector)     ==> #()
     (vector 1)   ==> #(1)
     (vector 1 2) ==> #(1 2)

   The #(...)  syntax is the literal notation for vectors used by the
Lisp printer and reader.  This syntax allows you to save and restore
vectors by PRINTing them out and READing them back in.  You can use the
#(...)  syntax to include literal vectors in your code, but as the
effects of modifying literal objects aren't defined, you should always
use VECTOR or the more general function MAKE-ARRAY to create vectors you
plan to modify.

   MAKE-ARRAY is more general than VECTOR since you can use it to create
arrays of any dimensionality as well as both fixed-size and resizable
vectors.  The one required argument to MAKE-ARRAY is a list containing
the dimensions of the array.  Since a vector is a one-dimensional array,
this list will contain one number, the size of the vector.  As a
convenience, MAKE-ARRAY will also accept a plain number in the place of
a one-item list.  With no other arguments, MAKE-ARRAY will create a
vector with uninitialized elements that must be set before they can be
accessed.  (2) To create a vector with the elements all set to a
particular value, you can pass an :initial-element argument.  Thus, to
make a five-element vector with its elements initialized to NIL, you can
write the following:

     (make-array 5 :initial-element nil) ==> #(NIL NIL NIL NIL NIL)

   MAKE-ARRAY is also the function to use to make a resizable vector.  A
resizable vector is a slightly more complicated object than a fixed-size
vector; in addition to keeping track of the memory used to hold the
elements and the number of slots available, a resizable vector also
keeps track of the number of elements actually stored in the vector.
This number is stored in the vector's fill pointer, so called because
it's the index of the next position to be filled when you add an element
to the vector.

   To make a vector with a fill pointer, you pass MAKE-ARRAY a
:fill-pointer argument.  For instance, the following call to MAKE-ARRAY
makes a vector with room for five elements; but it looks empty because
the fill pointer is zero:

     (make-array 5 :fill-pointer 0) ==> #()

   To add an element to the end of a resizable vector, you can use the
function VECTOR-PUSH. It adds the element at the current value of the
fill pointer and then increments the fill pointer by one, returning the
index where the new element was added.  The function VECTOR-POP returns
the most recently pushed item, decrementing the fill pointer in the
process.

     (defparameter *x* (make-array 5 :fill-pointer 0))

     (vector-push 'a *x*) ==> 0
     *x*                  ==> #(A)
     (vector-push 'b *x*) ==> 1
     *x*                  ==> #(A B)
     (vector-push 'c *x*) ==> 2
     *x*                  ==> #(A B C)
     (vector-pop *x*)     ==> C
     *x*                  ==> #(A B)
     (vector-pop *x*)     ==> B
     *x*                  ==> #(A)
     (vector-pop *x*)     ==> A
     *x*                  ==> #()

   However, even a vector with a fill pointer isn't completely
resizable.  The vector *x* can hold at most five elements.  To make an
arbitrarily resizable vector, you need to pass MAKE-ARRAY another
keyword argument: :adjustable.

     (make-array 5 :fill-pointer 0 :adjustable t) ==> #()

   This call makes an adjustable vector whose underlying memory can be
resized as needed.  To add elements to an adjustable vector, you use
VECTOR-PUSH-EXTEND, which works just like VECTOR-PUSH except it will
automatically expand the array if you try to push an element onto a full
vector-one whose fill pointer is equal to the size of the underlying
storage.  (3)

   ---------- Footnotes ----------

   (1) Vectors are called vectors, not arrays as their analogs in other
languages are, because Common Lisp supports true multidimensional
arrays.  It's equally correct, though more cumbersome, to refer to them
as one-dimensional arrays.

   (2) Array elements "must" be set before they're accessed in the sense
that the behavior is undefined; Lisp won't necessarily stop you.

   (3) While frequently used together, the :fill-pointer and :adjustable
arguments are independent-you can make an adjustable array without a
fill pointer.  However, you can use VECTOR-PUSH and VECTOR-POP only with
vectors that have a fill pointer and VECTOR-PUSH-EXTEND only with
vectors that have a fill pointer and are adjustable.  You can also use
the function ADJUST-ARRAY to modify adjustable arrays in a variety of
ways beyond just extending the length of a vector.


File: pcl.info,  Node: 11-2,  Next: 11-3,  Prev: 11-1,  Up: Chapter 11

Subtypes of Vector
==================

All the vectors you've dealt with so far have been general vectors that
can hold any type of object.  It's also possible to create specialized
vectors that are restricted to holding certain types of elements.  One
reason to use specialized vectors is they may be stored more compactly
and can provide slightly faster access to their elements than general
vectors.  However, for the moment let's focus on a couple kinds of
specialized vectors that are important data types in their own right.

   One of these you've seen already-strings are vectors specialized to
hold characters.  Strings are important enough to get their own
read/print syntax (double quotes) and the set of string-specific
functions I discussed in the previous chapter.  But because they're also
vectors, all the functions I'll discuss in the next few sections that
take vector arguments can also be used with strings.  These functions
will fill out the string library with functions for things such as
searching a string for a substring, finding occurrences of a character
within a string, and more.

   Literal strings, such as "foo", are like literal vectors written with
the #() syntax-their size is fixed, and they must not be modified.
However, you can use MAKE-ARRAY to make resizable strings by adding
another keyword argument, :element-type.  This argument takes a type
descriptor.  I won't discuss all the possible type descriptors you can
use here; for now it's enough to know you can create a string by passing
the symbol CHARACTER as the :element-type argument.  Note that you need
to quote the symbol to prevent it from being treated as a variable name.
For example, to make an initially empty but resizable string, you can
write this:

     (make-array 5 :fill-pointer 0 :adjustable t :element-type 'character)  ""

   Bit vectors-vectors whose elements are all zeros or ones-also get
some special treatment.  They have a special read/print syntax that
looks like #*00001111 and a fairly large library of functions, which I
won't discuss, for performing bit-twiddling operations such as "anding"
together two bit arrays.  The type descriptor to pass as the
:element-type to create a bit vector is the symbol BIT.


File: pcl.info,  Node: 11-3,  Next: 11-4,  Prev: 11-2,  Up: Chapter 11

Vectors As Sequences
====================

As mentioned earlier, vectors and lists are the two concrete subtypes of
the abstract type sequence.  All the functions I'll discuss in the next
few sections are sequence functions; in addition to being applicable to
vectors-both general and specialized-they can also be used with lists.

   The two most basic sequence functions are LENGTH, which returns the
length of a sequence, and ELT, which allows you to access individual
elements via an integer index.  LENGTH takes a sequence as its only
argument and returns the number of elements it contains.  For vectors
with a fill pointer, this will be the value of the fill pointer.  ELT,
short for element, takes a sequence and an integer index between zero
(inclusive) and the length of the sequence (exclusive) and returns the
corresponding element.  ELT will signal an error if the index is out of
bounds.  Like LENGTH, ELT treats a vector with a fill pointer as having
the length specified by the fill pointer.

     (defparameter *x* (vector 1 2 3))

     (length *x*) ==> 3
     (elt *x* 0)  ==> 1
     (elt *x* 1)  ==> 2
     (elt *x* 2)  ==> 3
     (elt *x* 3)  ==> error

   ELT is also a SETFable place, so you can set the value of a
particular element like this:

     (setf (elt *x* 0) 10)

     *x* ==> #(10 2 3)


File: pcl.info,  Node: 11-4,  Next: 11-5,  Prev: 11-3,  Up: Chapter 11

Sequence Iterating Functions
============================

While in theory all operations on sequences boil down to some
combination of LENGTH, ELT, and SETF of ELT operations, Common Lisp
provides a large library of sequence functions.

   One group of sequence functions allows you to express certain
operations on sequences such as finding or filtering specific elements
without writing explicit loops.  Table 11-1 summarizes them.

   Table 11-1.Basic Sequence Functions

 [image src="tables/11-1.png" ]

   Here are some simple examples of how to use these functions:

     (count 1 #(1 2 1 2 3 1 2 3 4))         ==> 3
     (remove 1 #(1 2 1 2 3 1 2 3 4))        ==> #(2 2 3 2 3 4)
     (remove 1 '(1 2 1 2 3 1 2 3 4))        ==> (2 2 3 2 3 4)
     (remove #\a "foobarbaz")               ==> "foobrbz"
     (substitute 10 1 #(1 2 1 2 3 1 2 3 4)) ==> #(10 2 10 2 3 10 2 3 4)
     (substitute 10 1 '(1 2 1 2 3 1 2 3 4)) ==> (10 2 10 2 3 10 2 3 4)
     (substitute #\x #\b "foobarbaz")       ==> "fooxarxaz"
     (find 1 #(1 2 1 2 3 1 2 3 4))          ==> 1
     (find 10 #(1 2 1 2 3 1 2 3 4))         ==> NIL
     (position 1 #(1 2 1 2 3 1 2 3 4))      ==> 0

   Note how REMOVE and SUBSTITUTE always return a sequence of the same
type as their sequence argument.

   You can modify the behavior of these five functions in a variety of
ways using keyword arguments.  For instance, these functions, by
default, look for elements in the sequence that are the same object as
the item argument.  You can change this in two ways: First, you can use
the :test keyword to pass a function that accepts two arguments and
returns a boolean.  If provided, it will be used to compare item to each
element instead of the default object equality test, EQL. (1) Second,
with the :key keyword you can pass a one-argument function to be called
on each element of the sequence to extract a key value, which will then
be compared to the item in the place of the element itself.  Note,
however, that functions such as FIND that return elements of the
sequence continue to return the actual element, not just the extracted
key.

     (count "foo" #("foo" "bar" "baz") :test #'string=)    ==> 1
     (find 'c #((a 10) (b 20) (c 30) (d 40)) :key #'first) ==> (C 30)

   To limit the effects of these functions to a particular subsequence
of the sequence argument, you can provide bounding indices with :start
and :end arguments.  Passing NIL for :end or omitting it is the same as
specifying the length of the sequence.  (2)

   If a non-NIL :from-end argument is provided, then the elements of the
sequence will be examined in reverse order.  By itself :from-end can
affect the results of only FIND and POSITION. For instance:

     (find 'a #((a 10) (b 20) (a 30) (b 40)) :key #'first)             ==> (A 10)
     (find 'a #((a 10) (b 20) (a 30) (b 40)) :key #'first :from-end t) ==> (A 30)

   However, the :from-end argument can affect REMOVE and SUBSTITUTE in
conjunction with another keyword parameter, :count, that's used to
specify how many elements to remove or substitute.  If you specify a
:count lower than the number of matching elements, then it obviously
matters which end you start from:

     (remove #\a "foobarbaz" :count 1)             ==> "foobrbaz"
     (remove #\a "foobarbaz" :count 1 :from-end t) ==> "foobarbz"

   And while :from-end can't change the results of the COUNT function,
it does affect the order the elements are passed to any :test and :key
functions, which could possibly have side effects.  For example:

     CL-USER> (defparameter *v* #((a 10) (b 20) (a 30) (b 40)))
     *V*
     CL-USER> (defun verbose-first (x) (format t "Looking at ~s~%" x) (first x))
     VERBOSE-FIRST
     CL-USER> (count 'a *v* :key #'verbose-first)
     Looking at (A 10)
     Looking at (B 20)
     Looking at (A 30)
     Looking at (B 40)
     2
     CL-USER> (count 'a *v* :key #'verbose-first :from-end t)
     Looking at (B 40)
     Looking at (A 30)
     Looking at (B 20)
     Looking at (A 10)
     2

   Table 11-2 summarizes these arguments.

   Table 11-2.  Standard Sequence Function Keyword Arguments

 [image src="tables/11-2.png" ]

   ---------- Footnotes ----------

   (1) Another parameter, :test-not parameter, specifies a two-argument
predicate to be used like a :test argument except with the boolean
result logically reversed.  This parameter is deprecated, however, in
preference for using the COMPLEMENT function.  COMPLEMENT takes a
function argu-ment and returns a function that takes the same number of
arguments as the original and returns the logical complement of the
original function.  Thus, you can, and should, write this:

     (count x sequence :test (complement #'some-test))

     rather than the following:

   (count x sequence :test-not #'some-test)

   (2) Note, however, that the effect of :start and :end on REMOVE and
SUBSTITUTE is only to limit the elements they consider for removal or
substitution; elements before :start and after :end will be passed
through untouched.


File: pcl.info,  Node: 11-5,  Next: 11-6,  Prev: 11-4,  Up: Chapter 11

Higher-Order Function Variants
==============================

For each of the functions just discussed, Common Lisp provides two
higher-order function variants that, in the place of the item argument,
take a function to be called on each element of the sequence.  One set
of variants are named the same as the basic function with an -IF
appended.  These functions count, find, remove, and substitute elements
of the sequence for which the function argument returns true.  The other
set of variants are named with an -IF-NOT suffix and count, find,
remove, and substitute elements for which the function argument does not
return true.

     (count-if #'evenp #(1 2 3 4 5))         ==> 2

     (count-if-not #'evenp #(1 2 3 4 5))     ==> 3

     (position-if #'digit-char-p "abcd0001") ==> 4

     (remove-if-not #'(lambda (x) (char= (elt x 0) #\f))
       #("foo" "bar" "baz" "foom")) ==> #("foo" "foom")

   According to the language standard, the -IF-NOT variants are
deprecated.  However, that deprecation is generally considered to have
itself been ill-advised.  If the standard is ever revised, it's more
likely the deprecation will be removed than the -IF-NOT functions.  For
one thing, the REMOVE-IF-NOT variant is probably used more often than
REMOVE-IF. Despite its negative-sounding name, REMOVE-IF-NOT is actually
the positive variant-it returns the elements that do satisfy the
predicate.  (1)

   The -IF and -IF-NOT variants accept all the same keyword arguments as
their vanilla counterparts except for :test, which isn't needed since
the main argument is already a function.  (2) With a :key argument, the
value extracted by the :key function is passed to the function instead
of the actual element.

     (count-if #'evenp #((1 a) (2 b) (3 c) (4 d) (5 e)) :key #'first)     ==> 2

     (count-if-not #'evenp #((1 a) (2 b) (3 c) (4 d) (5 e)) :key #'first) ==> 3

     (remove-if-not #'alpha-char-p
       #("foo" "bar" "1baz") :key #'(lambda (x) (elt x 0))) ==> #("foo" "bar")

   The REMOVE family of functions also support a fourth variant,
REMOVE-DUPLICATES, that has only one required argument, a sequence, from
which it removes all but one instance of each duplicated element.  It
takes the same keyword arguments as REMOVE, except for :count, since it
always removes all duplicates.

     (remove-duplicates #(1 2 1 2 3 1 2 3 4)) ==> #(1 2 3 4)

   ---------- Footnotes ----------

   (1) This same functionality goes by the name grep in Perl and filter
in Python.

   (2) The difference between the predicates passed as :test arguments
and as the function arguments to the -IF and -IF-NOT functions is that
the :test predicates are two-argument predicates used to compare the
elements of the sequence to the specific item while the -IF and -IF-NOT
predicates are one-argument functions that simply test the individual
elements of the sequence.  If the vanilla variants didn't exist, you
could implement them in terms of the -IF versions by embedding a
specific item in the test function.

     (count char string) ===
       (count-if #'(lambda (c) (eql char c)) string)
     (count char string :test #'CHAR-EQUAL) ===
       (count-if #'(lambda (c) (char-equal char c)) string)


File: pcl.info,  Node: 11-6,  Next: 11-7,  Prev: 11-5,  Up: Chapter 11

Whole Sequence Manipulations
============================

A handful of functions perform operations on a whole sequence (or
sequences) at a time.  These tend to be simpler than the other functions
I've described so far.  For instance, COPY-SEQ and REVERSE each take a
single argument, a sequence, and each returns a new sequence of the same
type.  The sequence returned by COPY-SEQ contains the same elements as
its argument while the sequence returned by REVERSE contains the same
elements but in reverse order.  Note that neither function copies the
elements themselves-only the returned sequence is a new object.

   The CONCATENATE function creates a new sequence containing the
concatenation of any number of sequences.  However, unlike REVERSE and
COPY-SEQ, which simply return a sequence of the same type as their
single argument, CONCATENATE must be told explicitly what kind of
sequence to produce in case the arguments are of different types.  Its
first argument is a type descriptor, like the :element-type argument to
MAKE-ARRAY. In this case, the type descriptors you'll most likely use
are the symbols VECTOR, LIST, or STRING. (1) For example:

     (concatenate 'vector #(1 2 3) '(4 5 6))    ==> #(1 2 3 4 5 6)
     (concatenate 'list #(1 2 3) '(4 5 6))      ==> (1 2 3 4 5 6)
     (concatenate 'string "abc" '(#\d #\e #\f)) ==> "abcdef"

   ---------- Footnotes ----------

   (1) If you tell CONCATENATE to return a specialized vector, such as a
string, all the elements of the argument sequences must be instances of
the vector's element type.


File: pcl.info,  Node: 11-7,  Next: 11-8,  Prev: 11-6,  Up: Chapter 11

Sorting and Merging
===================

The functions SORT and STABLE-SORT provide two ways of sorting a
sequence.  They both take a sequence and a two-argument predicate and
return a sorted version of the sequence.

     (sort (vector "foo" "bar" "baz") #'string<) ==> #("bar" "baz" "foo")

   The difference is that STABLE-SORT is guaranteed to not reorder any
elements considered equivalent by the predicate while SORT guarantees
only that the result is sorted and may reorder equivalent elements.

   Both these functions are examples of what are called destructive
functions.  Destructive functions are allowed-typically for reasons of
efficiency-to modify their arguments in more or less arbitrary ways.
This has two implications: one, you should always do something with the
return value of these functions (such as assign it to a variable or pass
it to another function), and, two, unless you're done with the object
you're passing to the destructive function, you should pass a copy
instead.  I'll say more about destructive functions in the next chapter.

   Typically you won't care about the unsorted version of a sequence
after you've sorted it, so it makes sense to allow SORT and STABLE-SORT
to destroy the sequence in the course of sorting it.  But it does mean
you need to remember to write the following: (1)

     (setf my-sequence (sort my-sequence #'string<))

   rather than just this:

     (sort my-sequence #'string<)

   Both these functions also take a keyword argument, :key, which, like
the :key argument in other sequence functions, should be a function and
will be used to extract the values to be passed to the sorting predicate
in the place of the actual elements.  The extracted keys are used only
to determine the ordering of elements; the sequence returned will
contain the actual elements of the argument sequence.

   The MERGE function takes two sequences and a predicate and returns a
sequence produced by merging the two sequences, according to the
predicate.  It's related to the two sorting functions in that if each
sequence is already sorted by the same predicate, then the sequence
returned by MERGE will also be sorted.  Like the sorting functions,
MERGE takes a :key argument.  Like CONCATENATE, and for the same reason,
the first argument to MERGE must be a type descriptor specifying the
type of sequence to produce.

     (merge 'vector #(1 3 5) #(2 4 6) #'<) ==> #(1 2 3 4 5 6)
     (merge 'list #(1 3 5) #(2 4 6) #'<)   ==> (1 2 3 4 5 6)

   ---------- Footnotes ----------

   (1) When the sequence passed to the sorting functions is a vector,
the "destruction" is actually guaranteed to entail permuting the
elements in place, so you could get away without saving the returned
value.  However, it's good style to always do something with the return
value since the sorting functions can modify lists in much more
arbitrary ways.


File: pcl.info,  Node: 11-8,  Next: 11-9,  Prev: 11-7,  Up: Chapter 11

Subsequence Manipulations
=========================

Another set of functions allows you to manipulate subsequences of
existing sequences.  The most basic of these is SUBSEQ, which extracts a
subsequence starting at a particular index and continuing to a
particular ending index or the end of the sequence.  For instance:

     (subseq "foobarbaz" 3)   ==> "barbaz"
     (subseq "foobarbaz" 3 6) ==> "bar"

   SUBSEQ is also SETFable, but it won't extend or shrink a sequence; if
the new value and the subsequence to be replaced are different lengths,
the shorter of the two determines how many characters are actually
changed.

     (defparameter *x* (copy-seq "foobarbaz"))

     (setf (subseq *x* 3 6) "xxx")  ; subsequence and new value are same length
     *x* ==> "fooxxxbaz"

     (setf (subseq *x* 3 6) "abcd") ; new value too long, extra character ignored.
     *x* ==> "fooabcbaz"

     (setf (subseq *x* 3 6) "xx")   ; new value too short, only two characters changed
     *x* ==> "fooxxcbaz"

   You can use the FILL function to set multiple elements of a sequence
to a single value.  The required arguments are a sequence and the value
with which to fill it.  By default every element of the sequence is set
to the value; :start and :end keyword arguments can limit the effects to
a given subsequence.

   If you need to find a subsequence within a sequence, the SEARCH
function works like POSITION except the first argument is a sequence
rather than a single item.

     (position #\b "foobarbaz") ==> 3
     (search "bar" "foobarbaz") ==> 3

   On the other hand, to find where two sequences with a common prefix
first diverge, you can use the MISMATCH function.  It takes two
sequences and returns the index of the first pair of mismatched
elements.

     (mismatch "foobarbaz" "foom") ==> 3

   It returns NIL if the strings match.  MISMATCH also takes many of the
standard keyword arguments: a :key argument for specifying a function to
use to extract the values to be compared; a :test argument to specify
the comparison function; and :start1, :end1, :start2, and :end2
arguments to specify subsequences within the two sequences.  And a
:from-end argument of T specifies the sequences should be searched in
reverse order, causing MISMATCH to return the index, in the first
sequence, where whatever common suffix the two sequences share begins.

     (mismatch "foobar" "bar" :from-end t) ==> 3


File: pcl.info,  Node: 11-9,  Next: 11-10,  Prev: 11-8,  Up: Chapter 11

Sequence Predicates
===================

Four other handy functions are EVERY, SOME, NOTANY, and NOTEVERY, which
iterate over sequences testing a boolean predicate.  The first argument
to all these functions is the predicate, and the remaining arguments are
sequences.  The predicate should take as many arguments as the number of
sequences passed.  The elements of the sequences are passed to the
predicate-one element from each sequence-until one of the sequences runs
out of elements or the overall termination test is met: EVERY
terminates, returning false, as soon as the predicate fails.  If the
predicate is always satisfied, it returns true.  SOME returns the first
non-NIL value returned by the predicate or returns false if the
predicate is never satisfied.  NOTANY returns false as soon as the
predicate is satisfied or true if it never is.  And NOTEVERY returns
true as soon as the predicate fails or false if the predicate is always
satisfied.  Here are some examples of testing just one sequence:

     (every #'evenp #(1 2 3 4 5))    ==> NIL
     (some #'evenp #(1 2 3 4 5))     ==> T
     (notany #'evenp #(1 2 3 4 5))   ==> NIL
     (notevery #'evenp #(1 2 3 4 5)) ==> T

   These calls compare elements of two sequences pairwise:

     (every #'> #(1 2 3 4) #(5 4 3 2))    ==> NIL
     (some #'> #(1 2 3 4) #(5 4 3 2))     ==> T
     (notany #'> #(1 2 3 4) #(5 4 3 2))   ==> NIL
     (notevery #'> #(1 2 3 4) #(5 4 3 2)) ==> T


File: pcl.info,  Node: 11-10,  Next: 11-11,  Prev: 11-9,  Up: Chapter 11

Sequence Mapping Functions
==========================

Finally, the last of the sequence functions are the generic mapping
functions.  MAP, like the sequence predicate functions, takes a
n-argument function and n sequences.  But instead of a boolean value,
MAP returns a new sequence containing the result of applying the
function to subsequent elements of the sequences.  Like CONCATENATE and
MERGE, MAP needs to be told what kind of sequence to create.

     (map 'vector #'* #(1 2 3 4 5) #(10 9 8 7 6)) ==> #(10 18 24 28 30)

   MAP-INTO is like MAP except instead of producing a new sequence of a
given type, it places the results into a sequence passed as the first
argument.  This sequence can be the same as one of the sequences
providing values for the function.  For instance, to sum several
vectors-a, b, and c-into one, you could write this:

     (map-into a #'+ a b c)

   If the sequences are different lengths, MAP-INTO affects only as many
elements as are present in the shortest sequence, including the sequence
being mapped into.  However, if the sequence being mapped into is a
vector with a fill pointer, the number of elements affected isn't
limited by the fill pointer but rather by the actual size of the vector.
After a call to MAP-INTO, the fill pointer will be set to the number of
elements mapped.  MAP-INTO won't, however, extend an adjustable vector.

   The last sequence function is REDUCE, which does another kind of
mapping: it maps over a single sequence, applying a two-argument
function first to the first two elements of the sequence and then to the
value returned by the function and subsequent elements of the sequence.
Thus, the following expression sums the numbers from one to ten:

     (reduce #'+ #(1 2 3 4 5 6 7 8 9 10)) ==> 55

   REDUCE is a surprisingly useful function-whenever you need to distill
a sequence down to a single value, chances are you can write it with
REDUCE, and it will often be quite a concise way to express what you
want.  For instance, to find the maximum value in a sequence of numbers,
you can write (reduce #'max numbers).  REDUCE also takes a full
complement of keyword arguments (:key, :from-end, :start, and :end) and
one unique to REDUCE (:initial-value).  The latter specifies a value
that's logically placed before the first element of the sequence (or
after the last if you also specify a true :from-end argument).


File: pcl.info,  Node: 11-11,  Next: 11-12,  Prev: 11-10,  Up: Chapter 11

Hash Tables
===========

The other general-purpose collection provided by Common Lisp is the hash
table.  Where vectors provide an integer-indexed data structure, hash
tables allow you to use arbitrary objects as the indexes, or keys.  When
you add a value to a hash table, you store it under a particular key.
Later you can use the same key to retrieve the value.  Or you can
associate a new value with the same key-each key maps to a single value.

   With no arguments MAKE-HASH-TABLE makes a hash table that considers
two keys equivalent if they're the same object according to EQL. This is
a good default unless you want to use strings as keys, since two strings
with the same contents aren't necessarily EQL. In that case you'll want
a so-called EQUAL hash table, which you can get by passing the symbol
EQUAL as the :test keyword argument to MAKE-HASH-TABLE. Two other
possible values for the :test argument are the symbols EQ and EQUALP.
These are, of course, the names of the standard object comparison
functions, which I discussed in Chapter 4.  However, unlike the :test
argument passed to sequence functions, MAKE-HASH-TABLE's :test can't be
used to specify an arbitrary function-only the values EQ, EQL, EQUAL,
and EQUALP. This is because hash tables actually need two functions, an
equivalence function and a hash function that computes a numerical hash
code from the key in a way compatible with how the equivalence function
will ultimately compare two keys.  However, although the language
standard provides only for hash tables that use the standard equivalence
functions, most implementations provide some mechanism for defining
custom hash tables.

   The GETHASH function provides access to the elements of a hash table.
It takes two arguments-a key and the hash table-and returns the value,
if any, stored in the hash table under that key or NIL. (1) For example:

     (defparameter *h* (make-hash-table))

     (gethash 'foo *h*) ==> NIL

     (setf (gethash 'foo *h*) 'quux)

     (gethash 'foo *h*) ==> QUUX

   Since GETHASH returns NIL if the key isn't present in the table,
there's no way to tell from the return value the difference between a
key not being in a hash table at all and being in the table with the
value NIL. GETHASH solves this problem with a feature I haven't
discussed yet-multiple return values.  GETHASH actually returns two
values; the primary value is the value stored under the given key or
NIL. The secondary value is a boolean indicating whether the key is
present in the hash table.  Because of the way multiple values work, the
extra return value is silently discarded unless the caller explicitly
handles it with a form that can "see" multiple values.

   I'll discuss multiple return values in greater detail in Chapter 20,
but for now I'll give you a sneak preview of how to use the
MULTIPLE-VALUE-BIND macro to take advantage of GETHASH's extra return
value.  MULTIPLE-VALUE-BIND creates variable bindings like LET does,
filling them with the multiple values returned by a form.

   The following function shows how you might use MULTIPLE-VALUE-BIND;
the variables it binds are value and present:

     (defun show-value (key hash-table)
       (multiple-value-bind (value present) (gethash key hash-table)
         (if present
           (format nil "Value ~a actually present." value)
           (format nil "Value ~a because key not found." value))))

     (setf (gethash 'bar *h*) nil) ; provide an explicit value of NIL

     (show-value 'foo *h*) ==> "Value QUUX actually present."
     (show-value 'bar *h*) ==> "Value NIL actually present."
     (show-value 'baz *h*) ==> "Value NIL because key not found."

   Since setting the value under a key to NIL leaves the key in the
table, you'll need another function to completely remove a key/value
pair.  REMHASH takes the same arguments as GETHASH and removes the
specified entry.  You can also completely clear a hash table of all its
key/value pairs with CLRHASH.

   ---------- Footnotes ----------

   (1) By an accident of history, the order of arguments to GETHASH is
the opposite of ELT-ELT takes the collection first and then the index
while GETHASH takes the key first and then the collection.


File: pcl.info,  Node: 11-12,  Next: Chapter 12,  Prev: 11-11,  Up: Chapter 11

Hash Table Iteration
====================

Common Lisp provides a couple ways to iterate over the entries in a hash
table.  The simplest of these is via the function MAPHASH. Analogous to
the MAP function, MAPHASH takes a two-argument function and a hash table
and invokes the function once for each key/value pair in the hash table.
For instance, to print all the key/value pairs in a hash table, you
could use MAPHASH like this:

     (maphash #'(lambda (k v) (format t "~a => ~a~%" k v)) *h*)

   The consequences of adding or removing elements from a hash table
while iterating over it aren't specified (and are likely to be bad) with
two exceptions: you can use SETF with GETHASH to change the value of the
current entry, and you can use REMHASH to remove the current entry.  For
instance, to remove all the entries whose value is less than ten, you
could write this:

     (maphash #'(lambda (k v) (when (< v 10) (remhash k *h*))) *h*)

   The other way to iterate over a hash table is with the extended LOOP
macro, which I'll discuss in Chapter 22.  (1) The LOOP equivalent of the
first MAPHASH expression would look like this:

     (loop for k being the hash-keys in *h* using (hash-value v)
       do (format t "~a => ~a~%" k v))

   I could say a lot more about the nonlist collections supported by
Common Lisp.  For instance, I haven't discussed multidimensional arrays
at all or the library of functions for manipulating bit arrays.
However, what I've covered in this chapter should suffice for most of
your general-purpose programming needs.  Now it's finally time to look
at Lisp's eponymous data structure: lists.

   ---------- Footnotes ----------

   (1) LOOP's hash table iteration is typically implemented on top of a
more primitive form, WITH-HASH-TABLE-ITERATOR, that you don't need to
worry about; it was added to the language specifically to support
implementing things such as LOOP and is of little use unless you need to
write completely new control constructs for iterating over hash tables.


File: pcl.info,  Node: Chapter 12,  Next: Chapter 13,  Prev: Chapter 11,  Up: Top

12. They Called It LISP for a Reason: List Processing
=====================================================

Lists play an important role in Lisp-for reasons both historical and
practical.  Historically, lists were Lisp's original composite data
type, though it has been decades since they were its only such data
type.  These days, a Common Lisp programmer is as likely to use a
vector, a hash table, or a user-defined class or structure as to use a
list.

   Practically speaking, lists remain in the language because they're an
excellent solution to certain problems.  One such problem-how to
represent code as data in order to support code-transforming and
code-generating macros-is particular to Lisp, which may explain why
other languages don't feel the lack of Lisp-style lists.  More
generally, lists are an excellent data structure for representing any
kind of heterogeneous and/or hierarchical data.  They're also quite
lightweight and support a functional style of programming that's another
important part of Lisp's heritage.

   Thus, you need to understand lists on their own terms; as you gain a
better understanding of how lists work, you'll be in a better position
to appreciate when you should and shouldn't use them.

* Menu:

* 12-1::             "There Is No List"
* 12-2::             Functional Programming and Lists
* 12-3::             "Destructive" Operations
* 12-4::             Combining Recycling with Shared Structure
* 12-5::             List-Manipulation Functions
* 12-6::             Mapping
* 12-7::             Other Structures


File: pcl.info,  Node: 12-1,  Next: 12-2,  Prev: Chapter 12,  Up: Chapter 12

"There Is No List"
==================

     Spoon Boy: Do not try and bend the list.  That's impossible.
     Instead .  .  .  only try to realize the truth.  Neo: What truth?
     Spoon Boy: There is no list.  Neo: There is no list?  Spoon Boy:
     Then you'll see that it is not the list that bends; it is only
     yourself.  (1)
   The key to understanding lists is to understand that they're largely
an illusion built on top of objects that are instances of a more
primitive data type.  Those simpler objects are pairs of values called
cons cells, after the function CONS used to create them.

   CONS takes two arguments and returns a new cons cell containing the
two values.  (2) These values can be references to any kind of object.
Unless the second value is NIL or another cons cell, a cons is printed
as the two values in parentheses separated by a dot, a so-called dotted
pair.

     (cons 1 2) ==> (1 . 2)

   The two values in a cons cell are called the CAR and the CDR after
the names of the functions used to access them.  At the dawn of time,
these names were mnemonic, at least to the folks implementing the first
Lisp on an IBM 704.  But even then they were just lifted from the
assembly mnemonics used to implement the operations.  However, it's not
all bad that these names are somewhat meaningless-when considering
individual cons cells, it's best to think of them simply as an arbitrary
pair of values without any particular semantics.  Thus:

     (car (cons 1 2)) ==> 1
     (cdr (cons 1 2)) ==> 2

   Both CAR and CDR are also SETFable places-given an existing cons
cell, it's possible to assign a new value to either of its values.  (3)

     (defparameter *cons* (cons 1 2))
     *cons*                 ==> (1 . 2)
     (setf (car *cons*) 10) ==> 10
     *cons*                 ==> (10 . 2)
     (setf (cdr *cons*) 20) ==> 20
     *cons*                 ==> (10 . 20)

   Because the values in a cons cell can be references to any kind of
object, you can build larger structures out of cons cells by linking
them together.  Lists are built by linking together cons cells in a
chain.  The elements of the list are held in the CARs of the cons cells
while the links to subsequent cons cells are held in the CDRs.  The last
cell in the chain has a CDR of NIL, which-as I mentioned in Chapter
4-represents the empty list as well as the boolean value false.

   This arrangement is by no means unique to Lisp; it's called a singly
linked list.  However, few languages outside the Lisp family provide
such extensive support for this humble data type.

   So when I say a particular value is a list, what I really mean is
it's either NIL or a reference to a cons cell.  The CAR of the cons cell
is the first item of the list, and the CDR is a reference to another
list, that is, another cons cell or NIL, containing the remaining
elements.  The Lisp printer understands this convention and prints such
chains of cons cells as parenthesized lists rather than as dotted pairs.

     (cons 1 nil)                   ==> (1)
     (cons 1 (cons 2 nil))          ==> (1 2)
     (cons 1 (cons 2 (cons 3 nil))) ==> (1 2 3)

   When talking about structures built out of cons cells, a few diagrams
can be a big help.  Box-and-arrow diagrams represent cons cells as a
pair of boxes like this:

 [image src="imgs/one-cons-cell.png" ]

   The box on the left represents the CAR, and the box on the right is
the CDR. The values stored in a particular cons cell are either drawn in
the appropriate box or represented by an arrow from the box to a
representation of the referenced value.  (4) For instance, the list (1 2
3), which consists of three cons cells linked together by their CDRs,
would be diagrammed like this:

 [image src="imgs/list-1-2-3.png" ]

   However, most of the time you work with lists you won't have to deal
with individual cons cells-the functions that create and manipulate
lists take care of that for you.  For example, the LIST function builds
a cons cells under the covers for you and links them together; the
following LIST expressions are equivalent to the previous CONS
expressions:

     (list 1)     ==> (1)
     (list 1 2)   ==> (1 2)
     (list 1 2 3) ==> (1 2 3)

   Similarly, when you're thinking in terms of lists, you don't have to
use the meaningless names CAR and CDR; FIRST and REST are synonyms for
CAR and CDR that you should use when you're dealing with cons cells as
lists.

     (defparameter *list* (list 1 2 3 4))
     (first *list*)        ==> 1
     (rest *list*)         ==> (2 3 4)
     (first (rest *list*)) ==> 2

   Because cons cells can hold any kind of values, so can lists.  And a
single list can hold objects of different types.

     (list "foo" (list 1 2) 10) ==> ("foo" (1 2) 10)

   The structure of that list would look like this:

 [image src="imgs/mixed-list.png" ]

   Because lists can have other lists as elements, you can also use them
to represent trees of arbitrary depth and complexity.  As such, they
make excellent representations for any heterogeneous, hierarchical data.
Lisp-based XML processors, for instance, usually represent XML documents
internally as lists.  Another obvious example of tree-structured data is
Lisp code itself.  In Chapters 30 and 31 you'll write an HTML generation
library that uses lists of lists to represent the HTML to be generated.
I'll talk more next chapter about using cons cells to represent other
data structures.

   Common Lisp provides quite a large library of functions for
manipulating lists.  In the sections "List-Manipulation Functions" and
"Mapping," you'll look at some of the more important of these functions.
However, they will be easier to understand in the context of a few ideas
borrowed from functional programming.

   ---------- Footnotes ----------

   (1) Adapted from The Matrix (http://us.imdb.com/Quotes?0133093)

   (2) CONS was originally short for the verb construct.

   (3) When the place given to SETF is a CAR or CDR, it expands into a
call to the function RPLACA or RPLACD; some old-school Lispers-the same
ones who still use SETQ-will still use RPLACA and RPLACD directly, but
modern style is to use SETF of CAR or CDR.

   (4) Typically, simple objects such as numbers are drawn within the
appropriate box, and more complex objects will be drawn outside the box
with an arrow from the box indicating the reference.  This actually
corresponds well with how many Common Lisp implementations work-although
all objects are conceptually stored by reference, certain simple
immutable objects can be stored directly in a cons cell.


File: pcl.info,  Node: 12-2,  Next: 12-3,  Prev: 12-1,  Up: Chapter 12

Functional Programming and Lists
================================

The essence of functional programming is that programs are built
entirely of functions with no side effects that compute their results
based solely on the values of their arguments.  The advantage of the
functional style is that it makes programs easier to understand.
Eliminating side effects eliminates almost all possibilities for action
at a distance.  And since the result of a function is determined only by
the values of its arguments, its behavior is easier to understand and
test.  For instance, when you see an expression such as (+ 3 4), you
know the result is uniquely determined by the definition of the +
function and the values 3 and 4.  You don't have to worry about what may
have happened earlier in the execution of the program since there's
nothing that can change the result of evaluating that expression.

   Functions that deal with numbers are naturally functional since
numbers are immutable.  A list, on the other hand, can be mutated, as
you've just seen, by SETFing the CARs and CDRs of the cons cells that
make up its backbone.  However, lists can be treated as a functional
data type if you consider their value to be determined by the elements
they contain.  Thus, any list of the form (1 2 3 4) is functionally
equivalent to any other list containing those four values, regardless of
what cons cells are actually used to represent the list.  And any
function that takes a list as an argument and returns a value based
solely on the contents of the list can likewise be considered
functional.  For instance, the REVERSE sequence function, given the list
(1 2 3 4), always returns a list (4 3 2 1).  Different calls to REVERSE
with functionally equivalent lists as the argument will return
functionally equivalent result lists.  Another aspect of functional
programming, which I'll discuss in the section "Mapping," is the use of
higher-order functions: functions that treat other functions as data,
taking them as arguments or returning them as results.

   Most of Common Lisp's list-manipulation functions are written in a
functional style.  I'll discuss later how to mix functional and other
coding styles, but first you should understand a few subtleties of the
functional style as applied to lists.

   The reason most list functions are written functionally is it allows
them to return results that share cons cells with their arguments.  To
take a concrete example, the function APPEND takes any number of list
arguments and returns a new list containing the elements of all its
arguments.  For instance:

     (append (list 1 2) (list 3 4)) ==> (1 2 3 4)

   From a functional point of view, APPEND's job is to return the list
(1 2 3 4) without modifying any of the cons cells in the lists (1 2) and
(3 4).  One obvious way to achieve that goal is to create a completely
new list consisting of four new cons cells.  However, that's more work
than is necessary.  Instead, APPEND actually makes only two new cons
cells to hold the values 1 and 2, linking them together and pointing the
CDR of the second cons cell at the head of the last argument, the list
(3 4).  It then returns the cons cell containing the 1.  None of the
original cons cells has been modified, and the result is indeed the list
(1 2 3 4).  The only wrinkle is that the list returned by APPEND shares
some cons cells with the list (3 4).  The resulting structure looks like
this:

 [image src="imgs/after-append.png" ]

   In general, APPEND must copy all but its last argument, but it can
always return a result that shares structure with the last argument.

   Other functions take similar advantage of lists' ability to share
structure.  Some, like APPEND, are specified to always return results
that share structure in a particular way.  Others are simply allowed to
return shared structure at the discretion of the implementation.


File: pcl.info,  Node: 12-3,  Next: 12-4,  Prev: 12-2,  Up: Chapter 12

"Destructive" Operations
========================

If Common Lisp were a purely functional language, that would be the end
of the story.  However, because it's possible to modify a cons cell
after it has been created by SETFing its CAR or CDR, you need to think a
bit about how side effects and structure sharing mix.

   Because of Lisp's functional heritage, operations that modify
existing objects are called destructive-in functional programming,
changing an object's state "destroys" it since it no longer represents
the same value.  However, using the same term to describe all
state-modifying operations leads to a certain amount of confusion since
there are two very different kinds of destructive operations,
for-side-effect operations and recycling operations.  (1)

   For-side-effect operations are those used specifically for their side
effects.  All uses of SETF are destructive in this sense, as are
functions that use SETF under the covers to change the state of an
existing object such as VECTOR-PUSH or VECTOR-POP. But it's a bit unfair
to describe these operations as destructive-they're not intended to be
used in code written in a functional style, so they shouldn't be
described using functional terminology.  However, if you mix
nonfunctional, for-side-effect operations with functions that return
structure-sharing results, then you need to be careful not to
inadvertently modify the shared structure.  For instance, consider these
three definitions:

     (defparameter *list-1* (list 1 2))
     (defparameter *list-2* (list 3 4))
     (defparameter *list-3* (append *list-1* *list-2*))

   After evaluating these forms, you have three lists, but *list-3* and
*list-2* share structure just like the lists in the previous diagram.

     *list-1*                  ==> (1 2)
     *list-2*                  ==> (3 4)
     *list-3*                  ==> (1 2 3 4)

   Now consider what happens when you modify *list-2*.

     (setf (first *list-2*) 0) ==> 0
     *list-2*                  ==> (0 4)     ; as expected
     *list-3*                  ==> (1 2 0 4) ; maybe not what you wanted

   The change to *list-2* also changes *list-3* because of the shared
structure: the first cons cell in *list-2* is also the third cons cell
in *list-3*.  SETFing the FIRST of *list-2* changes the value in the CAR
of that cons cell, affecting both lists.

   On the other hand, the other kind of destructive operations,
recycling operations, are intended to be used in functional code.  They
use side effects only as an optimization.  In particular, they reuse
certain cons cells from their arguments when building their result.
However, unlike functions such as APPEND that reuse cons cells by
including them, unmodified, in the list they return, recycling functions
reuse cons cells as raw material, modifying the CAR and CDR as necessary
to build the desired result.  Thus, recycling functions can be used
safely only when the original lists aren't going to be needed after the
call to the recycling function.

   To see how a recycling function works, let's compare REVERSE, the
nondestructive function that returns a reversed version of a sequence,
to NREVERSE, a recycling version of the same function.  Because REVERSE
doesn't modify its argument, it must allocate a new cons cell for each
element in the list being reversed.  But suppose you write something
like this:

     (setf *list* (reverse *list*))

   By assigning the result of REVERSE back to *list*, you've removed the
reference to the original value of *list*.  Assuming the cons cells in
the original list aren't referenced anywhere else, they're now eligible
to be garbage collected.  However, in many Lisp implementations it'd be
more efficient to immediately reuse the existing cons cells rather than
allocating new ones and letting the old ones become garbage.

   NREVERSE allows you to do exactly that.  The N stands for
non-consing, meaning it doesn't need to allocate any new cons cells.
The exact side effects of NREVERSE are intentionally not specified-it's
allowed to modify any CAR or CDR of any cons cell in the list-but a
typical implementation might walk down the list changing the CDR of each
cons cell to point to the previous cons cell, eventually returning the
cons cell that was previously the last cons cell in the old list and is
now the head of the reversed list.  No new cons cells need to be
allocated, and no garbage is created.

   Most recycling functions, like NREVERSE, have nondestructive
counterparts that compute the same result.  In general, the recycling
functions have names that are the same as their non-destructive
counterparts except with a leading N. However, not all do, including
several of the more commonly used recycling functions such as NCONC, the
recycling version of APPEND, and DELETE, DELETE-IF, DELETE-IF-NOT, and
DELETE-DUPLICATES, the recycling versions of the REMOVE family of
sequence functions.

   In general, you use recycling functions in the same way you use their
nondestructive counterparts except it's safe to use them only when you
know the arguments aren't going to be used after the function returns.
The side effects of most recycling functions aren't specified tightly
enough to be relied upon.

   However, the waters are further muddied by a handful of recycling
functions with specified side effects that can be relied upon.  They are
NCONC, the recycling version of APPEND, and NSUBSTITUTE and its -IF and
-IF-NOT variants, the recycling versions of the sequence functions
SUBSTITUTE and friends.

   Like APPEND, NCONC returns a concatenation of its list arguments, but
it builds its result in the following way: for each nonempty list it's
passed, NCONC sets the CDR of the list's last cons cell to point to the
first cons cell of the next nonempty list.  It then returns the first
list, which is now the head of the spliced-together result.  Thus:

     (defparameter *x* (list 1 2 3))

     (nconc *x* (list 4 5 6)) ==> (1 2 3 4 5 6)

     *x* ==> (1 2 3 4 5 6)

   NSUBSTITUTE and variants can be relied on to walk down the list
structure of the list argument and to SETF the CARs of any cons cells
holding the old value to the new value and to otherwise leave the list
intact.  It then returns the original list, which now has the same value
as would've been computed by SUBSTITUTE. (2)

   The key thing to remember about NCONC and NSUBSTITUTE is that they're
the exceptions to the rule that you can't rely on the side effects of
recycling functions.  It's perfectly acceptable-and arguably good
style-to ignore the reliability of their side effects and use them, like
any other recycling function, only for the value they return.

   ---------- Footnotes ----------

   (1) The phrase for-side-effect is used in the language standard, but
recycling is my own invention; most Lisp literature simply uses the term
destructive for both kinds of operations, leading to the confusion I'm
trying to dispel.

   (2) The string functions NSTRING-CAPITALIZE, NSTRING-DOWNCASE, and
NSTRING-UPCASE are similar-they return the same results as their N-less
counterparts but are specified to modify their string argument in place.


File: pcl.info,  Node: 12-4,  Next: 12-5,  Prev: 12-3,  Up: Chapter 12

Combining Recycling with Shared Structure
=========================================

Although you can use recycling functions whenever the arguments to the
recycling function won't be used after the function call, it's worth
noting that each recycling function is a loaded gun pointed footward: if
you accidentally use a recycling function on an argument that is used
later, you're liable to lose some toes.

   To make matters worse, shared structure and recycling functions tend
to work at cross-purposes.  Nondestructive list functions return lists
that share structure under the assumption that cons cells are never
modified, but recycling functions work by violating that assumption.
Or, put another way, sharing structure is based on the premise that you
don't care exactly what cons cells make up a list while using recycling
functions requires that you know exactly what cons cells are referenced
from where.

   In practice, recycling functions tend to be used in a few idiomatic
ways.  By far the most common recycling idiom is to build up a list to
be returned from a function by "consing" onto the front of a list,
usually by PUSHing elements onto a list stored in a local variable and
then returning the result of NREVERSEing it.  (1)

   This is an efficient way to build a list because each PUSH has to
create only one cons cell and modify a local variable and the NREVERSE
just has to zip down the list reassigning the CDRs.  Because the list is
created entirely within the function, there's no danger any code outside
the function has a reference to any of its cons cells.  Here's a
function that uses this idiom to build a list of the first n numbers,
starting at zero: (2)

     (defun upto (max)
       (let ((result nil))
         (dotimes (i max)
           (push i result))
         (nreverse result)))

     (upto 10) ==> (0 1 2 3 4 5 6 7 8 9)

   The next most common recycling idiom (3) is to immediately reassign
the value returned by the recycling function back to the place
containing the potentially recycled value.  For instance, you'll often
see expressions like the following, using DELETE, the recycling version
of REMOVE:

     (setf foo (delete nil foo))

   This sets the value of foo to its old value except with all the NILs
removed.  However, even this idiom must be used with some care-if foo
shares structure with lists referenced elsewhere, using DELETE instead
of REMOVE can destroy the structure of those other lists.  For example,
consider the two lists *list-2* and *list-3* from earlier that share
their last two cons cells.

     *list-2* ==> (0 4)
     *list-3* ==> (1 2 0 4)

   You can delete 4 from *list-3* like this:

     (setf *list-3* (delete 4 *list-3*)) ==> (1 2 0)

   However, DELETE will likely perform the necessary deletion by setting
the CDR of the third cons cell to NIL, disconnecting the fourth cons
cell, the one holding the 4, from the list.  Because the third cons cell
of *list-3* is also the first cons cell in *list-2*, the following
modifies *list-2* as well:

     *list-2* ==> (0)

   If you had used REMOVE instead of DELETE, it would've built a list
containing the values 1, 2, and 0, creating new cons cells as necessary
rather than modifying any of the cons cells in *list-3*.  In that case,
*list-2* wouldn't have been affected.

   The PUSH/NREVERSE and SETF/DELETE idioms probably account for 80
percent of the uses of recycling functions.  Other uses are possible but
require keeping careful track of which functions return shared structure
and which do not.

   In general, when manipulating lists, it's best to write your own code
in a functional style-your functions should depend only on the contents
of their list arguments and shouldn't modify them.  Following that rule
will, of course, rule out using any destructive functions, recycling or
otherwise.  Once you have your code working, if profiling shows you need
to optimize, you can replace nondestructive list operations with their
recycling counterparts but only if you're certain the argument lists
aren't referenced from anywhere else.

   One last gotcha to watch out for is that the sorting functions SORT,
STABLE-SORT, and MERGE mentioned in Chapter 11 are also recycling
functions when applied to lists.  (4) However, these functions don't
have nondestructive counterparts, so if you need to sort a list without
destroying it, you need to pass the sorting function a copy made with
COPY-LIST. In either case you need to be sure to save the result of the
sorting function because the original argument is likely to be in
tatters.  For instance:

     CL-USER> (defparameter *list* (list 4 3 2 1))
     *LIST*
     CL-USER> (sort *list* #'<)
     (1 2 3 4)                      ; looks good
     CL-USER> *list*
     (4)                            ; whoops!

   ---------- Footnotes ----------

   (1) For example, in an examination of all uses of recycling functions
in the Common Lisp Open Code Collection (CLOCC), a diverse set of
libraries written by various authors, instances of the PUSH/NREVERSE
idiom accounted for nearly half of all uses of recycling functions.

   (2) There are, of course, other ways to do this same thing.  The
extended LOOP macro, for instance, makes it particularly easy and likely
generates code that's even more efficient than the PUSH/ NREVERSE
version.

   (3) This idiom accounts for 30 percent of uses of recycling in the
CLOCC code base.

   (4) SORT and STABLE-SORT can be used as for-side-effect operations on
vectors, but since they still return the sorted vector, you should
ignore that fact and use them for return values for the sake of
consistency.


File: pcl.info,  Node: 12-5,  Next: 12-6,  Prev: 12-4,  Up: Chapter 12

List-Manipulation Functions
===========================

With that background out of the way, you're ready to look at the library
of functions Common Lisp provides for manipulating lists.

   You've already seen the basic functions for getting at the elements
of a list: FIRST and REST. Although you can get at any element of a list
by combining enough calls to REST (to move down the list) with a FIRST
(to extract the element), that can be a bit tedious.  So Common Lisp
provides functions named for the other ordinals from SECOND to TENTH
that return the appropriate element.  More generally, the function NTH
takes two arguments, an index and a list, and returns the nth
(zero-based) element of the list.  Similarly, NTHCDR takes an index and
a list and returns the result of calling CDR n times.  (Thus, (nthcdr 0
...)  simply returns the original list, and (nthcdr 1 ...)  is
equivalent to REST.) Note, however, that none of these functions is any
more efficient, in terms of work done by the computer, than the
equivalent combinations of FIRSTs and RESTs-there's no way to get to the
nth element of a list without following n CDR references.  (1)

   The 28 composite CAR/CDR functions are another family of functions
you may see used from time to time.  Each function is named by placing a
sequence of up to four As and Ds between a C and R, with each A
representing a call to CAR and each D a call to CDR. Thus:

     (caar list) === (car (car list))
     (cadr list) === (car (cdr list))
     (cadadr list) === (car (cdr (car (cdr list))))

   Note, however, that many of these functions make sense only when
applied to lists that contain other lists.  For instance, CAAR extracts
the CAR of the CAR of the list it's given; thus, the list it's passed
must contain another list as its first element.  In other words, these
are really functions on trees rather than lists:

     (caar (list 1 2 3))                  ==> error
     (caar (list (list 1 2) 3))           ==> 1
     (cadr (list (list 1 2) (list 3 4)))  ==> (3 4)
     (caadr (list (list 1 2) (list 3 4))) ==> 3

   These functions aren't used as often now as in the old days.  And
even the most die-hard old-school Lisp hackers tend to avoid the longer
combinations.  However, they're used quite a bit in older Lisp code, so
it's worth at least understanding how they work.  (2)

   The FIRST-TENTH and CAR, CADR, and so on, functions can also be used
as SETFable places if you're using lists nonfunctionally.

   Table 12-1 summarizes some other list functions that I won't cover in
detail.

   Table 12-1.  Other List Functions

 [image src="tables/12-1.png" ]

   ---------- Footnotes ----------

   (1) NTH is roughly equivalent to the sequence function ELT but works
only with lists.  Also, confusingly, NTH takes the index as the first
argument, the opposite of ELT. Another difference is that ELT will
signal an error if you try to access an element at an index greater than
or equal to the length of the list, but NTH will return NIL.

   (2) In particular, they used to be used to extract the various parts
of expressions passed to macros before the invention of destructuring
parameter lists.  For example, you could take apart the following
expression:

     (when (> x 10) (print x))

   Like this:

     ;; the condition
     (cadr '(when (> x 10) (print x))) ==> (> X 10)
     ;; the body, as a list
     (cddr '(when (> x 10) (print x))) ==> ((PRINT X))


File: pcl.info,  Node: 12-6,  Next: 12-7,  Prev: 12-5,  Up: Chapter 12

Mapping
=======

Another important aspect of the functional style is the use of
higher-order functions, functions that take other functions as arguments
or return functions as values.  You saw several examples of higher-order
functions, such as MAP, in the previous chapter.  Although MAP can be
used with both lists and vectors (that is, with any kind of sequence),
Common Lisp also provides six mapping functions specifically for lists.
The differences between the six functions have to do with how they build
up their result and whether they apply the function to the elements of
the list or to the cons cells of the list structure.

   MAPCAR is the function most like MAP. Because it always returns a
list, it doesn't require the result-type argument MAP does.  Instead,
its first argument is the function to apply, and subsequent arguments
are the lists whose elements will provide the arguments to the function.
Otherwise, it behaves like MAP: the function is applied to successive
elements of the list arguments, taking one element from each list per
application of the function.  The results of each function call are
collected into a new list.  For example:

     (mapcar #'(lambda (x) (* 2 x)) (list 1 2 3)) ==> (2 4 6)
     (mapcar #'+ (list 1 2 3) (list 10 20 30)) ==> (11 22 33)

   MAPLIST is just like MAPCAR except instead of passing the elements of
the list to the function, it passes the actual cons cells.  (1) Thus,
the function has access not only to the value of each element of the
list (via the CAR of the cons cell) but also to the rest of the list
(via the CDR).

   MAPCAN and MAPCON work like MAPCAR and MAPLIST except for the way
they build up their result.  While MAPCAR and MAPLIST build a completely
new list to hold the results of the function calls, MAPCAN and MAPCON
build their result by splicing together the results-which must be
lists-as if by NCONC. Thus, each function invocation can provide any
number of elements to be included in the result.  (2) MAPCAN, like
MAPCAR, passes the elements of the list to the mapped function while
MAPCON, like MAPLIST, passes the cons cells.

   Finally, the functions MAPC and MAPL are control constructs disguised
as functions-they simply return their first list argument, so they're
useful only when the side effects of the mapped function do something
interesting.  MAPC is the cousin of MAPCAR and MAPCAN while MAPL is in
the MAPLIST/MAPCON family.

   ---------- Footnotes ----------

   (1) Thus, MAPLIST is the more primitive of the two functions-if you
had only MAPLIST, you could build MAPCAR on top of it, but you couldn't
build MAPLIST on top of MAPCAR.

   (2) In Lisp dialects that didn't have filtering functions like
REMOVE, the idiomatic way to filter a list was with MAPCAN.

     (mapcan #'(lambda (x) (if (= x 10) nil (list x)))  list) === (remove 10 list)


File: pcl.info,  Node: 12-7,  Next: Chapter 13,  Prev: 12-6,  Up: Chapter 12

Other Structures
================

While cons cells and lists are typically considered to be synonymous,
that's not quite right-as I mentioned earlier, you can use lists of
lists to represent trees.  Just as the functions discussed in this
chapter allow you to treat structures built out of cons cells as lists,
other functions allow you to use cons cells to represent trees, sets,
and two kinds of key/value maps.  I'll discuss some of those functions
in the next chapter.


File: pcl.info,  Node: Chapter 13,  Next: Chapter 14,  Prev: Chapter 12,  Up: Top

13. Beyond Lists: Other Uses for Cons Cells
===========================================

As you saw in the previous chapter, the list data type is an illusion
created by a set of functions that manipulate cons cells.  Common Lisp
also provides functions that let you treat data structures built out of
cons cells as trees, sets, and lookup tables.  In this chapter I'll give
you a quick tour of some of these other data structures and the
functions for manipulating them.  As with the list-manipulation
functions, many of these functions will be useful when you start writing
more complicated macros and need to manipulate Lisp code as data.

* Menu:

* 13-1::                Trees
* 13-2::                Sets
* 13-3::                Lookup Tables: Alists and Plists
* 13-4::                DESTRUCTURING-BIND


File: pcl.info,  Node: 13-1,  Next: 13-2,  Prev: Chapter 13,  Up: Chapter 13

Trees
=====

Treating structures built from cons cells as trees is just about as
natural as treating them as lists.  What is a list of lists, after all,
but another way of thinking of a tree?  The difference between a
function that treats a bunch of cons cells as a list and a function that
treats the same bunch of cons cells as a tree has to do with which cons
cells the functions traverse to find the values of the list or tree.
The cons cells traversed by a list function, called the list structure,
are found by starting at the first cons cell and following CDR
references until reaching a NIL. The elements of the list are the
objects referenced by the CARs of the cons cells in the list structure.
If a cons cell in the list structure has a CAR that references another
cons cell, the referenced cons cell is considered to be the head of a
list that's an element of the outer list.  (1) Tree structure, on the
other hand, is traversed by following both CAR and CDR references for as
long as they point to other cons cells.  The values in a tree are thus
the atomic-non-cons-cell-values referenced by either the CARs or the
CDRs of the cons cells in the tree structure.

   For instance, the following box-and-arrow diagram shows the cons
cells that make up the list of lists: ((1 2) (3 4) (5 6)).  The list
structure includes only the three cons cells inside the dashed box while
the tree structure includes all the cons cells.

 [image src="imgs/list-or-tree.png" ]

   To see the difference between a list function and a tree function,
you can consider how the functions COPY-LIST and COPY-TREE will copy
this bunch of cons cells.  COPY-LIST, as a list function, copies the
cons cells that make up the list structure.  That is, it makes a new
cons cell corresponding to each of the cons cells inside the dashed box.
The CARs of each of these new cons cells reference the same object as
the CARs of the original cons cells in the list structure.  Thus,
COPY-LIST doesn't copy the sublists (1 2), (3 4), or (5 6), as shown in
this diagram:

 [image src="imgs/copy-list-list-or-tree.png" ]

   COPY-TREE, on the other hand, makes a new cons cell for each of the
cons cells in the diagram and links them together in the same structure,
as shown in this diagram:

 [image src="imgs/copy-tree-list-or-tree.png" ]

   Where a cons cell in the original referenced an atomic value, the
corresponding cons cell in the copy will reference the same value.
Thus, the only objects referenced in common by the original tree and the
copy produced by COPY-TREE are the numbers 1-6, and the symbol NIL.

   Another function that walks both the CARs and the CDRs of a tree of
cons cells is TREE-EQUAL, which compares two trees, considering them
equal if the tree structure is the same shape and if the leaves are EQL
(or if they satisfy the test supplied with the :test keyword argument).

   Some other tree-centric functions are the tree analogs to the
SUBSTITUTE and NSUBSTITUTE sequence functions and their -IF and -IF-NOT
variants.  The function SUBST, like SUBSTITUTE, takes a new item, an old
item, and a tree (as opposed to a sequence), along with :key and :test
keyword arguments, and it returns a new tree with the same shape as the
original tree but with all instances of the old item replaced with the
new item.  For example:

     CL-USER> (subst 10 1 '(1 2 (3 2 1) ((1 1) (2 2))))
     (10 2 (3 2 10) ((10 10) (2 2)))

   SUBST-IF is analogous to SUBSTITUTE-IF. Instead of an old item, it
takes a one-argument function-the function is called with each atomic
value in the tree, and whenever it returns true, the position in the new
tree is filled with the new value.  SUBST-IF-NOT is the same except the
values where the test returns NIL are replaced.  NSUBST, NSUBST-IF, and
NSUBST-IF-NOT are the recycling versions of the SUBST functions.  As
with most other recycling functions, you should use these functions only
as drop-in replacements for their nondestructive counterparts in
situations where you know there's no danger of modifying a shared
structure.  In particular, you must continue to save the return value of
these functions since you have no guarantee that the result will be EQ
to the original tree.  (2)

   ---------- Footnotes ----------

   (1) It's possible to build a chain of cons cells where the CDR of the
last cons cell isn't NIL but some other atom.  This is called a dotted
list because the last cons is a dotted pair.

   (2) It may seem that the NSUBST family of functions can and in fact
does modify the tree in place.  However, there's one edge case: when the
"tree" passed is, in fact, an atom, it can't be modified in place, so
the result of NSUBST will be a different object than the argument:
(nsubst 'x 'y 'y) X.


File: pcl.info,  Node: 13-2,  Next: 13-3,  Prev: 13-1,  Up: Chapter 13

Sets
====

Sets can also be implemented in terms of cons cells.  In fact, you can
treat any list as a set-Common Lisp provides several functions for
performing set-theoretic operations on lists.  However, you should bear
in mind that because of the way lists are structured, these operations
get less and less efficient the bigger the sets get.

   That said, using the built-in set functions makes it easy to write
set-manipulation code.  And for small sets they may well be more
efficient than the alternatives.  If profiling shows you that these
functions are a performance bottleneck in your code, you can always
replace the lists with sets built on top of hash tables or bit vectors.

   To build up a set, you can use the function ADJOIN. ADJOIN takes an
item and a list representing a set and returns a list representing the
set containing the item and all the items in the original set.  To
determine whether the item is present, it must scan the list; if the
item isn't found, ADJOIN creates a new cons cell holding the item and
pointing to the original list and returns it.  Otherwise, it returns the
original list.

   ADJOIN also takes :key and :test keyword arguments, which are used
when determining whether the item is present in the original list.  Like
CONS, ADJOIN has no effect on the original list-if you want to modify a
particular list, you need to assign the value returned by ADJOIN to the
place where the list came from.  The modify macro PUSHNEW does this for
you automatically.

     CL-USER> (defparameter *set* ())
     *SET*
     CL-USER> (adjoin 1 *set*)
     (1)
     CL-USER> *set*
     NIL
     CL-USER> (setf *set* (adjoin 1 *set*))
     (1)
     CL-USER> (pushnew 2 *set*)
     (2 1)
     CL-USER> *set*
     (2 1)
     CL-USER> (pushnew 2 *set*)
     (2 1)

   You can test whether a given item is in a set with MEMBER and the
related functions MEMBER-IF and MEMBER-IF-NOT. These functions are
similar to the sequence functions FIND, FIND-IF, and FIND-IF-NOT except
they can be used only with lists.  And instead of returning the item
when it's present, they return the cons cell containing the item-in
other words, the sublist starting with the desired item.  When the
desired item isn't present in the list, all three functions return NIL.

   The remaining set-theoretic functions provide bulk operations:
INTERSECTION, UNION, SET-DIFFERENCE, and SET-EXCLUSIVE-OR. Each of these
functions takes two lists and :key and :test keyword arguments and
returns a new list representing the set resulting from performing the
appropriate set-theoretic operation on the two lists: INTERSECTION
returns a list containing all the elements found in both arguments.
UNION returns a list containing one instance of each unique element from
the two arguments.  (1) SET-DIFFERENCE returns a list containing all the
elements from the first argument that don't appear in the second
argument.  And SET-EXCLUSIVE-OR returns a list containing those elements
appearing in only one or the other of the two argument lists but not in
both.  Each of these functions also has a recycling counterpart whose
name is the same except with an N prefix.

   Finally, the function SUBSETP takes two lists and the usual :key and
:test keyword arguments and returns true if the first list is a subset
of the second-if every element in the first list is also present in the
second list.  The order of the elements in the lists doesn't matter.

     CL-USER> (subsetp '(3 2 1) '(1 2 3 4))
     T
     CL-USER> (subsetp '(1 2 3 4) '(3 2 1))
     NIL

   ---------- Footnotes ----------

   (1) UNION takes only one element from each list, but if either list
contains duplicate elements, the result may also contain duplicates.


File: pcl.info,  Node: 13-3,  Next: 13-4,  Prev: 13-2,  Up: Chapter 13

Lookup Tables: Alists and Plists
================================

In addition to trees and sets, you can build tables that map keys to
values out of cons cells.  Two flavors of cons-based lookup tables are
commonly used, both of which I've mentioned in passing in previous
chapters.  They're association lists, also called alists, and property
lists, also known as plists.  While you wouldn't use either alists or
plists for large tables-for that you'd use a hash table-it's worth
knowing how to work with them both because for small tables they can be
more efficient than hash tables and because they have some useful
properties of their own.

   An alist is a data structure that maps keys to values and also
supports reverse lookups, finding the key when given a value.  Alists
also support adding key/value mappings that shadow existing mappings in
such a way that the shadowing mapping can later be removed and the
original mappings exposed again.

   Under the covers, an alist is essentially a list whose elements are
themselves cons cells.  Each element can be thought of as a key/value
pair with the key in the cons cell's CAR and the value in the CDR. For
instance, the following is a box-and-arrow diagram of an alist mapping
the symbol A to the number 1, B to 2, and C to 3:

 [image src="imgs/alist-abc-123.png" ]

   Unless the value in the CDR is a list, cons cells representing the
key/value pairs will be dotted pairs in s-expression notation.  The
alist diagramed in the previous figure, for instance, is printed like
this:

     ((A . 1) (B . 2) (C . 3))

   The main lookup function for alists is ASSOC, which takes a key and
an alist and returns the first cons cell whose CAR matches the key or
NIL if no match is found.

     CL-USER> (assoc 'a '((a . 1) (b . 2) (c . 3)))
     (A . 1)
     CL-USER> (assoc 'c '((a . 1) (b . 2) (c . 3)))
     (C . 3)
     CL-USER> (assoc 'd '((a . 1) (b . 2) (c . 3)))
     NIL

   To get the value corresponding to a given key, you simply pass the
result of ASSOC to CDR.

     CL-USER> (cdr (assoc 'a '((a . 1) (b . 2) (c . 3))))
     1

   By default the key given is compared to the keys in the alist using
EQL, but you can change that with the standard combination of :key and
:test keyword arguments.  For instance, if you wanted to use string
keys, you might write this:

     CL-USER> (assoc "a" '(("a" . 1) ("b" . 2) ("c" . 3)) :test #'string=)
     ("a" . 1)

   Without specifying :test to be STRING=, that ASSOC would probably
return NIL because two strings with the same contents aren't necessarily
EQL.

     CL-USER> (assoc "a" '(("a" . 1) ("b" . 2) ("c" . 3)))
     NIL

   Because ASSOC searches the list by scanning from the front of the
list, one key/value pair in an alist can shadow other pairs with the
same key later in the list.

     CL-USER> (assoc 'a '((a . 10) (a . 1) (b . 2) (c . 3)))
     (A . 10)

   You can add a pair to the front of an alist with CONS like this:

     (cons (cons 'new-key 'new-value) alist)

   However, as a convenience, Common Lisp provides the function ACONS,
which lets you write this:

     (acons 'new-key 'new-value alist)

   Like CONS, ACONS is a function and thus can't modify the place
holding the alist it's passed.  If you want to modify an alist, you need
to write either this:

     (setf alist (acons 'new-key 'new-value alist))

   or this:

     (push (cons 'new-key 'new-value) alist)

   Obviously, the time it takes to search an alist with ASSOC is a
function of how deep in the list the matching pair is found.  In the
worst case, determining that no pair matches requires ASSOC to scan
every element of the alist.  However, since the basic mechanism for
alists is so lightweight, for small tables an alist can outperform a
hash table.  Also, alists give you more flexibility in how you do the
lookup.  I already mentioned that ASSOC takes :key and :test keyword
arguments.  When those don't suit your needs, you may be able to use the
ASSOC-IF and ASSOC-IF-NOT functions, which return the first key/value
pair whose CAR satisfies (or not, in the case of ASSOC-IF-NOT) the test
function passed in the place of a specific item.  And three
functions-RASSOC, RASSOC-IF, and RASSOC-IF-NOT-work just like the
corresponding ASSOC functions except they use the value in the CDR of
each element as the key, performing a reverse lookup.

   The function COPY-ALIST is similar to COPY-TREE except, instead of
copying the whole tree structure, it copies only the cons cells that
make up the list structure, plus the cons cells directly referenced from
the CARs of those cells.  In other words, the original alist and the
copy will both contain the same objects as the keys and values, even if
those keys or values happen to be made up of cons cells.

   Finally, you can build an alist from two separate lists of keys and
values with the function PAIRLIS. The resulting alist may contain the
pairs either in the same order as the original lists or in reverse
order.  For example, you may get this result:

     CL-USER> (pairlis '(a b c) '(1 2 3))
     ((C . 3) (B . 2) (A . 1))

   Or you could just as well get this:

     CL-USER> (pairlis '(a b c) '(1 2 3))
     ((A . 1) (B . 2) (C . 3))

   The other kind of lookup table is the property list, or plist, which
you used to represent the rows in the database in Chapter 3.
Structurally a plist is just a regular list with the keys and values as
alternating values.  For instance, a plist mapping A, B, and C, to 1, 2,
and 3 is simply the list (A 1 B 2 C 3).  In boxes-and-arrows form, it
looks like this:

 [image src="imgs/plist-abc-123.png" ]

   However, plists are less flexible than alists.  In fact, plists
support only one fundamental lookup operation, the function GETF, which
takes a plist and a key and returns the associated value or NIL if the
key isn't found.  GETF also takes an optional third argument, which will
be returned in place of NIL if the key isn't found.

   Unlike ASSOC, which uses EQL as its default test and allows a
different test function to be supplied with a :test argument, GETF
always uses EQ to test whether the provided key matches the keys in the
plist.  Consequently, you should never use numbers or characters as keys
in a plist; as you saw in Chapter 4, the behavior of EQ for those types
is essentially undefined.  Practically speaking, the keys in a plist are
almost always symbols, which makes sense since plists were first
invented to implement symbolic "properties," arbitrary mappings between
names and values.

   You can use SETF with GETF to set the value associated with a given
key.  SETF also treats GETF a bit specially in that the first argument
to GETF is treated as the place to modify.  Thus, you can use SETF of
GETF to add a new key/value pair to an existing plist.

     CL-USER> (defparameter *plist* ())
     *PLIST*
     CL-USER> *plist*
     NIL
     CL-USER> (setf (getf *plist* :a) 1)
     1
     CL-USER> *plist*
     (:A 1)
     CL-USER> (setf (getf *plist* :a) 2)
     2
     CL-USER> *plist*
     (:A 2)

   To remove a key/value pair from a plist, you use the macro REMF,
which sets the place given as its first argument to a plist containing
all the key/value pairs except the one specified.  It returns true if
the given key was actually found.

     CL-USER> (remf *plist* :a)
     T
     CL-USER> *plist*
     NIL

   Like GETF, REMF always uses EQ to compare the given key to the keys
in the plist.

   Since plists are often used in situations where you want to extract
several properties from the same plist, Common Lisp provides a function,
GET-PROPERTIES, that makes it more efficient to extract multiple values
from a single plist.  It takes a plist and a list of keys to search for
and returns, as multiple values, the first key found, the corresponding
value, and the head of the list starting with the found key.  This
allows you to process a property list, extracting the desired
properties, without continually rescanning from the front of the list.
For instance, the following function efficiently processes-using the
hypothetical function process-property-all the key/value pairs in a
plist for a given list of keys:

     (defun process-properties (plist keys)
       (loop while plist do
            (multiple-value-bind (key value tail) (get-properties plist keys)
              (when key (process-property key value))
              (setf plist (cddr tail)))))

   The last special thing about plists is the relationship they have
with symbols: every symbol object has an associated plist that can be
used to store information about the symbol.  The plist can be obtained
via the function SYMBOL-PLIST. However, you rarely care about the whole
plist; more often you'll use the functions GET, which takes a symbol and
a key and is shorthand for a GETF of the same key in the symbols
SYMBOL-PLIST.

     (get 'symbol 'key) === (getf (symbol-plist 'symbol) 'key)
   Like GETF, GET is SETFable, so you can attach arbitrary information
to a symbol like this:

     (setf (get 'some-symbol 'my-key) "information")

   To remove a property from a symbol's plist, you can use either REMF
of SYMBOL-PLIST or the convenience function REMPROP. (1)

     (remprop 'symbol 'key) === (remf (symbol-plist 'symbol key))

   Being able to attach arbitrary information to names is quite handy
when doing any kind of symbolic programming.  For instance, one of the
macros you'll write in Chapter 24 will attach information to names that
other instances of the same macros will extract and use when generating
their expansions.

   ---------- Footnotes ----------

   (1) It's also possible to directly SETF SYMBOL-PLIST. However, that's
a bad idea, as different code may have added different properties to the
symbol's plist for different reasons.  If one piece of code clobbers the
symbol's whole plist, it may break other code that added its own
properties to the plist.


File: pcl.info,  Node: 13-4,  Next: Chapter 14,  Prev: 13-3,  Up: Chapter 13

DESTRUCTURING-BIND
==================

One last tool for slicing and dicing lists that I need to cover since
you'll need it in later chapters is the DESTRUCTURING-BIND macro.  This
macro provides a way to destructure arbitrary lists, similar to the way
macro parameter lists can take apart their argument list.  The basic
skeleton of a DESTRUCTURING-BIND is as follows:

     (destructuring-bind (parameter*) list
       body-form*)

   The parameter list can include any of the types of parameters
supported in macro parameter lists such as &optional, &rest, and &key
parameters.  (1) And, as in macro parameter lists, any parameter can be
replaced with a nested destructuring parameter list, which takes apart
the list that would otherwise have been bound to the replaced parameter.
The list form is evaluated once and should return a list, which is then
destructured and the appropriate values are bound to the variables in
the parameter list.  Then the body-forms are evaluated in order with
those bindings in effect.  Some simple examples follow:

     (destructuring-bind (x y z) (list 1 2 3)
       (list :x x :y y :z z)) ==> (:X 1 :Y 2 :Z 3)

     (destructuring-bind (x y z) (list 1 (list 2 20) 3)
       (list :x x :y y :z z)) ==> (:X 1 :Y (2 20) :Z 3)

     (destructuring-bind (x (y1 y2) z) (list 1 (list 2 20) 3)
       (list :x x :y1 y1 :y2 y2 :z z)) ==> (:X 1 :Y1 2 :Y2 20 :Z 3)

     (destructuring-bind (x (y1 &optional y2) z) (list 1 (list 2 20) 3)
       (list :x x :y1 y1 :y2 y2 :z z)) ==> (:X 1 :Y1 2 :Y2 20 :Z 3)

     (destructuring-bind (x (y1 &optional y2) z) (list 1 (list 2) 3)
       (list :x x :y1 y1 :y2 y2 :z z)) ==> (:X 1 :Y1 2 :Y2 NIL :Z 3)

     (destructuring-bind (&key x y z) (list :x 1 :y 2 :z 3)
       (list :x x :y y :z z)) ==> (:X 1 :Y 2 :Z 3)

     (destructuring-bind (&key x y z) (list :z 1 :y 2 :x 3)
       (list :x x :y y :z z)) ==> (:X 3 :Y 2 :Z 1)

   One kind of parameter you can use with DESTRUCTURING-BIND and also in
macro parameter lists, though I didn't mention it in Chapter 8, is a
&whole parameter.  If specified, it must be the first parameter in a
parameter list, and it's bound to the whole list form.  (2) After a
&whole parameter, other parameters can appear as usual and will extract
specific parts of the list just as they would if the &whole parameter
weren't there.  An example of using &whole with DESTRUCTURING-BIND looks
like this:

     (destructuring-bind (&whole whole &key x y z) (list :z 1 :y 2 :x 3)
       (list :x x :y y :z z :whole whole))
     ==> (:X 3 :Y 2 :Z 1 :WHOLE (:Z 1 :Y 2 :X 3))

   You'll use a &whole parameter in one of the macros that's part of the
HTML generation library you'll develop in Chapter 31.  However, I have a
few more topics to cover before you can get to that.  After two chapters
on the rather Lispy topic of cons cells, you can now turn to the more
prosaic matter of how to deal with files and filenames.

   ---------- Footnotes ----------

   (1) Macro parameter lists do support one parameter type, &environment
parameters, which DESTRUCTURING-BIND doesn't.  However, I didn't discuss
that parameter type in Chapter 8, and you don't need to worry about it
now either.

   (2) When a &whole parameter is used in a macro parameter list, the
form it's bound to is the whole macro form, including the name of the
macro.


File: pcl.info,  Node: Chapter 14,  Next: Chapter 15,  Prev: Chapter 13,  Up: Top

14. Files and File I/O
======================

Common Lisp provides a rich library of functionality for dealing with
files.  In this chapter I'll focus on a few basic file-related tasks:
reading and writing files and listing files in the file system.  For
these basic tasks, Common Lisp's I/O facilities are similar to those in
other languages.  Common Lisp provides a stream abstraction for reading
and writing data and an abstraction, called pathnames, for manipulating
filenames in an operating system-independent way.  Additionally, Common
Lisp provides other bits of functionality unique to Lisp such as the
ability to read and write s-expressions.

* Menu:

* 14-1::      Reading File Data
* 14-2::      Reading Binary Data
* 14-3::      Bulk Reads
* 14-4::      File Output
* 14-5::      Closing Files
* 14-6::      Filenames
* 14-7::      How Pathnames Represent Filenames
* 14-8::      Constructing New Pathnames
* 14-9::      Two Representations of Directory Names
* 14-10::     Interacting with the File System
* 14-11::     Other Kinds of I/O


File: pcl.info,  Node: 14-1,  Next: 14-2,  Prev: Chapter 14,  Up: Chapter 14

Reading File Data
=================

The most basic file I/O task is to read the contents of a file.  You
obtain a stream from which you can read a file's contents with the OPEN
function.  By default OPEN returns a character-based input stream you
can pass to a variety of functions that read one or more characters of
text: READ-CHAR reads a single character; READ-LINE reads a line of
text, returning it as a string with the end-of-line character(s)
removed; and READ reads a single s-expression, returning a Lisp object.
When you're done with the stream, you can close it with the CLOSE
function.

   The only required argument to OPEN is the name of the file to read.
As you'll see in the section "Filenames," Common Lisp provides a couple
of ways to represent a filename, but the simplest is to use a string
containing the name in the local file-naming syntax.  So assuming that
/some/file/name.txt is a file, you can open it like this:

   (open "/some/file/name.txt") You can use the object returned as the
first argument to any of the read functions.  For instance, to print the
first line of the file, you can combine OPEN, READ-LINE, and CLOSE as
follows:

   (let ((in (open "/some/file/name.txt"))) (format t "~a~%" (read-line
in)) (close in)) Of course, a number of things can go wrong while trying
to open and read from a file.  The file may not exist.  Or you may
unexpectedly hit the end of the file while reading.  By default OPEN and
the READ-* functions will signal an error in these situations.  In
Chapter 19, I'll discuss how to recover from such errors.  For now,
however, there's a lighter-weight solution: each of these functions
accepts arguments that modify its behavior in these exceptional
situations.

   If you want to open a possibly nonexistent file without OPEN
signaling an error, you can use the keyword argument :if-does-not-exist
to specify a different behavior.  The three possible values are :error,
the default; :create, which tells it to go ahead and create the file and
then proceed as if it had already existed; and NIL, which tells it to
return NIL instead of a stream.  Thus, you can change the previous
example to deal with the possibility that the file may not exist.

   (let ((in (open "/some/file/name.txt" :if-does-not-exist nil))) (when
in (format t "~a~%" (read-line in)) (close in))) The reading
functions-READ-CHAR, READ-LINE, and READ-all take an optional argument,
which defaults to true, that specifies whether they should signal an
error if they're called at the end of the file.  If that argument is
NIL, they instead return the value of their third argument, which
defaults to NIL. Thus, you could print all the lines in a file like
this:

   (let ((in (open "/some/file/name.txt" :if-does-not-exist nil))) (when
in (loop for line = (read-line in nil) while line do (format t "~a~%"
line)) (close in))) Of the three text-reading functions, READ is unique
to Lisp.  This is the same function that provides the R in the REPL and
that's used to read Lisp source code.  Each time it's called, it reads a
single s-expression, skipping whitespace and comments, and returns the
Lisp object denoted by the s-expression.  For instance, suppose
/some/file/name.txt has the following contents:

   (1 2 3) 456 "a string" ; this is a comment ((a b) (c d)) In other
words, it contains four s-expressions: a list of numbers, a number, a
string, and a list of lists.  You can read those expressions like this:

   CL-USER> (defparameter *s* (open "/some/file/name.txt")) *S* CL-USER>
(read *s*) (1 2 3) CL-USER> (read *s*) 456 CL-USER> (read *s*) "a
string" CL-USER> (read *s*) ((A B) (C D)) CL-USER> (close *s*) T As you
saw in Chapter 3, you can use PRINT to print Lisp objects in "readable"
form.  Thus, whenever you need to store a bit of data in a file, PRINT
and READ provide an easy way to do it without having to design a data
format or write a parser.  They even-as the previous example
demonstrated-give you comments for free.  And because s-expressions were
designed to be human editable, it's also a fine format for things like
configuration files.1


File: pcl.info,  Node: 14-2,  Next: 14-3,  Prev: 14-1,  Up: Chapter 14

Reading Binary Data
===================

By default OPEN returns character streams, which translate the
underlying bytes to characters according to a particular
character-encoding scheme.2 To read the raw bytes, you need to pass OPEN
an :element-type argument of '(unsigned-byte 8).3 You can pass the
resulting stream to the function READ-BYTE, which will return an integer
between 0 and 255 each time it's called.  READ-BYTE, like the
character-reading functions, also accepts optional arguments to specify
whether it should signal an error if called at the end of the file and
what value to return if not.  In Chapter 24 you'll build a library that
allows you to conveniently read structured binary data using READ-BYTE.4


File: pcl.info,  Node: 14-3,  Next: 14-4,  Prev: 14-2,  Up: Chapter 14

Bulk Reads
==========

One last reading function, READ-SEQUENCE, works with both character and
binary streams.  You pass it a sequence (typically a vector) and a
stream, and it attempts to fill the sequence with data from the stream.
It returns the index of the first element of the sequence that wasn't
filled or the length of the sequence if it was able to completely fill
it.  You can also pass :start and :end keyword arguments to specify a
subsequence that should be filled instead.  The sequence argument must
be a type that can hold elements of the stream's element type.  Since
most operating systems support some form of block I/O, READ-SEQUENCE is
likely to be quite a bit more efficient than filling a sequence by
repeatedly calling READ-BYTE or READ-CHAR.


File: pcl.info,  Node: 14-4,  Next: 14-5,  Prev: 14-3,  Up: Chapter 14

File Output
===========

To write data to a file, you need an output stream, which you obtain by
calling OPEN with a :direction keyword argument of :output.  When
opening a file for output, OPEN assumes the file shouldn't already exist
and will signal an error if it does.  However, you can change that
behavior with the :if-exists keyword argument.  Passing the value
:supersede tells OPEN to replace the existing file.  Passing :append
causes OPEN to open the existing file such that new data will be written
at the end of the file, while :overwrite returns a stream that will
overwrite existing data starting from the beginning of the file.  And
passing NIL will cause OPEN to return NIL instead of a stream if the
file already exists.  A typical use of OPEN for output looks like this:

   (open "/some/file/name.txt" :direction :output :if-exists :supersede)
Common Lisp also provides several functions for writing data: WRITE-CHAR
writes a single character to the stream.  WRITE-LINE writes a string
followed by a newline, which will be output as the appropriate
end-of-line character or characters for the platform.  Another function,
WRITE-STRING, writes a string without adding any end-of-line characters.
Two different functions can print just a newline: TERPRI-short for
"terminate print"-unconditionally prints a newline character, and
FRESH-LINE prints a newline character unless the stream is at the
beginning of a line.  FRESH-LINE is handy when you want to avoid
spurious blank lines in textual output generated by different functions
called in sequence.  For example, suppose you have one function that
generates output that should always be followed by a line break and
another that should start on a new line.  But assume that if the
functions are called one after the other, you don't want a blank line
between the two bits of output.  If you use FRESH-LINE at the beginning
of the second function, its output will always start on a new line, but
if it's called right after the first, it won't emit an extra line break.

   Several functions output Lisp data as s-expressions: PRINT prints an
s-expression preceded by an end-of-line and followed by a space.  PRIN1
prints just the s-expression.  And the function PPRINT prints
s-expressions like PRINT and PRIN1 but using the "pretty printer," which
tries to print its output in an aesthetically pleasing way.

   However, not all objects can be printed in a form that READ will
understand.  The variable *PRINT-READABLY* controls what happens if you
try to print such an object with PRINT, PRIN1, or PPRINT. When it's NIL,
these functions will print the object in a special syntax that's
guaranteed to cause READ to signal an error if it tries to read it;
otherwise they will signal an error rather than print the object.

   Another function, PRINC, also prints Lisp objects, but in a way
designed for human consumption.  For instance, PRINC prints strings
without quotation marks.  You can generate more elaborate text output
with the incredibly flexible if somewhat arcane FORMAT function.  I'll
discuss some of the more important details of FORMAT, which essentially
defines a mini-language for emitting formatted output, in Chapter 18.

   To write binary data to a file, you have to OPEN the file with the
same :element-type argument as you did to read it: '(unsigned-byte 8).
You can then write individual bytes to the stream with WRITE-BYTE.

   The bulk output function WRITE-SEQUENCE accepts both binary and
character streams as long as all the elements of the sequence are of an
appropriate type for the stream, either characters or bytes.  As with
READ-SEQUENCE, this function is likely to be quite a bit more efficient
than writing the elements of the sequence one at a time.


File: pcl.info,  Node: 14-5,  Next: 14-6,  Prev: 14-4,  Up: Chapter 14

Closing Files
=============

As anyone who has written code that deals with lots of files knows, it's
important to close files when you're done with them, because file
handles tend to be a scarce resource.  If you open files and don't close
them, you'll soon discover you can't open any more files.5 It might seem
straightforward enough to just be sure every OPEN has a matching CLOSE.
For instance, you could always structure your file using code like this:

   (let ((stream (open "/some/file/name.txt"))) ;; do stuff with stream
(close stream)) However, this approach suffers from two problems.  One
is simply that it's error prone-if you forget the CLOSE, the code will
leak a file handle every time it runs.  The other-and more
significant-problem is that there's no guarantee you'll get to the
CLOSE. For instance, if the code prior to the CLOSE contains a RETURN or
RETURN-FROM, you could leave the LET without closing the stream.  Or, as
you'll see in Chapter 19, if any of the code before the CLOSE signals an
error, control may jump out of the LET to an error handler and never
come back to close the stream.

   Common Lisp provides a general solution to the problem of how to
ensure that certain code always runs: the special operator
UNWIND-PROTECT, which I'll discuss in Chapter 20.  However, because the
pattern of opening a file, doing something with the resulting stream,
and then closing the stream is so common, Common Lisp provides a macro,
WITH-OPEN-FILE, built on top of UNWIND-PROTECT, to encapsulate this
pattern.  This is the basic form:

   (with-open-file (stream-var open-argument*) body-form*) The forms in
body-forms are evaluated with stream-var bound to a file stream opened
by a call to OPEN with open-arguments as its arguments.  WITH-OPEN-FILE
then ensures the stream in stream-var is closed before the
WITH-OPEN-FILE form returns.  Thus, you can write this to read a line
from a file:

   (with-open-file (stream "/some/file/name.txt") (format t "~a~%"
(read-line stream))) To create a new file, you can write something like
this:

   (with-open-file (stream "/some/file/name.txt" :direction :output)
(format stream "Some text."))  You'll probably use WITH-OPEN-FILE for
90-99 percent of the file I/O you do-the only time you need to use raw
OPEN and CLOSE calls is if you need to open a file in a function and
keep the stream around after the function returns.  In that case, you
must take care to eventually close the stream yourself, or you'll leak
file descriptors and may eventually end up unable to open any more
files.


File: pcl.info,  Node: 14-6,  Next: 14-7,  Prev: 14-5,  Up: Chapter 14

Filenames
=========

So far you've used strings to represent filenames.  However, using
strings as filenames ties your code to a particular operating system and
file system.  Likewise, if you programmatically construct names
according to the rules of a particular naming scheme (separating
directories with /, say), you also tie your code to a particular file
system.

   To avoid this kind of nonportability, Common Lisp provides another
representation of filenames: pathname objects.  Pathnames represent
filenames in a structured way that makes them easy to manipulate without
tying them to a particular filename syntax.  And the burden of
translating back and forth between strings in the local syntax-called
namestrings-and pathnames is placed on the Lisp implementation.

   Unfortunately, as with many abstractions designed to hide the details
of fundamentally different underlying systems, the pathname abstraction
introduces its own complications.  When pathnames were designed, the set
of file systems in general use was quite a bit more variegated than
those in common use today.  Consequently, some nooks and crannies of the
pathname abstraction make little sense if all you're concerned about is
representing Unix or Windows filenames.  However, once you understand
which parts of the pathname abstraction you can ignore as artifacts of
pathnames' evolutionary history, they do provide a convenient way to
manipulate filenames.6

   Most places a filename is called for, you can use either a namestring
or a pathname.  Which to use depends mostly on where the name
originated.  Filenames provided by the user-for example, as arguments or
as values in configuration files-will typically be namestrings, since
the user knows what operating system they're running on and shouldn't be
expected to care about the details of how Lisp represents filenames.
But programmatically generated filenames will be pathnames because you
can create them portably.  A stream returned by OPEN also represents a
filename, namely, the filename that was originally used to open the
stream.  Together these three types are collectively referred to as
pathname designators.  All the built-in functions that expect a filename
argument accept all three types of pathname designator.  For instance,
all the places in the previous section where you used a string to
represent a filename, you could also have passed a pathname object or a
stream.


File: pcl.info,  Node: 14-7,  Next: 14-8,  Prev: 14-6,  Up: Chapter 14

How Pathnames Represent Filenames
=================================

A pathname is a structured object that represents a filename using six
components: host, device, directory, name, type, and version.  Most of
these components take on atomic values, usually strings; only the
directory component is further structured, containing a list of
directory names (as strings) prefaced with the keyword :absolute or
:relative.  However, not all pathname components are needed on all
platforms-this is one of the reasons pathnames strike many new Lispers
as gratuitously complex.  On the other hand, you don't really need to
worry about which components may or may not be used to represent names
on a particular file system unless you need to create a new pathname
object from scratch, which you'll almost never need to do.  Instead,
you'll usually get hold of pathname objects either by letting the
implementation parse a file system-specific namestring into a pathname
object or by creating a new pathname that takes most of its components
from an existing pathname.

   For instance, to translate a namestring to a pathname, you use the
PATHNAME function.  It takes a pathname designator and returns an
equivalent pathname object.  When the designator is already a pathname,
it's simply returned.  When it's a stream, the original filename is
extracted and returned.  When the designator is a namestring, however,
it's parsed according to the local filename syntax.  The language
standard, as a platform-neutral document, doesn't specify any particular
mapping from namestring to pathname, but most implementations follow the
same conventions on a given operating system.

   On Unix file systems, only the directory, name, and type components
are typically used.  On Windows, one more component-usually the device
or host-holds the drive letter.  On these platforms, a namestring is
parsed by first splitting it into elements on the path separator-a slash
on Unix and a slash or backslash on Windows.  The drive letter on
Windows will be placed into either the device or the host component.
All but the last of the other name elements are placed in a list
starting with :absolute or :relative depending on whether the name
(ignoring the drive letter, if any) began with a path separator.  This
list becomes the directory component of the pathname.  The last element
is then split on the rightmost dot, if any, and the two parts put into
the name and type components of the pathname.7

   You can examine these individual components of a pathname with the
functions PATHNAME-DIRECTORY, PATHNAME-NAME, and PATHNAME-TYPE.

   (pathname-directory (pathname "/foo/bar/baz.txt")) ==> (:ABSOLUTE
"foo" "bar") (pathname-name (pathname "/foo/bar/baz.txt")) ==> "baz"
(pathname-type (pathname "/foo/bar/baz.txt")) ==> "txt" Three other
functions-PATHNAME-HOST, PATHNAME-DEVICE, and PATHNAME-VERSION-allow you
to get at the other three pathname components, though they're unlikely
to have interesting values on Unix.  On Windows either PATHNAME-HOST or
PATHNAME-DEVICE will return the drive letter.

   Like many other built-in objects, pathnames have their own read
syntax, #p followed by a double-quoted string.  This allows you to print
and read back s-expressions containing pathname objects, but because the
syntax depends on the namestring parsing algorithm, such data isn't
necessarily portable between operating systems.

   (pathname "/foo/bar/baz.txt") ==> #p"/foo/bar/baz.txt" To translate a
pathname back to a namestring-for instance, to present to the user-you
can use the function NAMESTRING, which takes a pathname designator and
returns a namestring.  Two other functions, DIRECTORY-NAMESTRING and
FILE-NAMESTRING, return a partial namestring.  DIRECTORY-NAMESTRING
combines the elements of the directory component into a local directory
name, and FILE-NAMESTRING combines the name and type components.8

   (namestring #p"/foo/bar/baz.txt") ==> "/foo/bar/baz.txt"
(directory-namestring #p"/foo/bar/baz.txt") ==> "/foo/bar/"
(file-namestring #p"/foo/bar/baz.txt") ==> "baz.txt"


File: pcl.info,  Node: 14-8,  Next: 14-9,  Prev: 14-7,  Up: Chapter 14

Constructing New Pathnames
==========================

You can construct arbitrary pathnames using the MAKE-PATHNAME function.
It takes one keyword argument for each pathname component and returns a
pathname with any supplied components filled in and the rest NIL.9

   (make-pathname :directory '(:absolute "foo" "bar") :name "baz" :type
"txt") ==> #p"/foo/bar/baz.txt" However, if you want your programs to be
portable, you probably don't want to make pathnames completely from
scratch: even though the pathname abstraction protects you from
unportable filename syntax, filenames can be unportable in other ways.
For instance, the filename /home/peter/foo.txt is no good on an OS X box
where /home/ is called /Users/.

   Another reason not to make pathnames completely from scratch is that
different implementations use the pathname components slightly
differently.  For instance, as mentioned previously, some Windows-based
Lisp implementations store the drive letter in the device component
while others store it in the host component.  If you write code like
this:

   (make-pathname :device "c" :directory '(:absolute "foo" "bar") :name
"baz") it will be correct on some implementations but not on others.

   Rather than making names from scratch, you can build a new pathname
based on an existing pathname with MAKE-PATHNAME's keyword parameter
:defaults.  With this parameter you can provide a pathname designator,
which will supply the values for any components not specified by other
arguments.  For example, the following expression creates a pathname
with an .html extension and all other components the same as the
pathname in the variable input-file:

   (make-pathname :type "html" :defaults input-file) Assuming the value
in input-file was a user-provided name, this code will be robust in the
face of operating system and implementation differences such as whether
filenames have drive letters in them and where they're stored in a
pathname if they do.10

   You can use the same technique to create a pathname with a different
directory component.

   (make-pathname :directory '(:relative "backups") :defaults
input-file) However, this will create a pathname whose whole directory
component is the relative directory backups/, regardless of any
directory component input-file may have had.  For example:

   (make-pathname :directory '(:relative "backups") :defaults
#p"/foo/bar/baz.txt") ==> #p"backups/baz.txt" Sometimes, though, you
want to combine two pathnames, at least one of which has a relative
directory component, by combining their directory components.  For
instance, suppose you have a relative pathname such as #p"foo/bar.html"
that you want to combine with an absolute pathname such as
#p"/www/html/" to get #p"/www/html/foo/bar.html".  In that case,
MAKE-PATHNAME won't do; instead, you want MERGE-PATHNAMES.

   MERGE-PATHNAMES takes two pathnames and merges them, filling in any
NIL components in the first pathname with the corresponding value from
the second pathname, much like MAKE-PATHNAME fills in any unspecified
components with components from the :defaults argument.  However,
MERGE-PATHNAMES treats the directory component specially: if the first
pathname's directory is relative, the directory component of the
resulting pathname will be the first pathname's directory relative to
the second pathname's directory.  Thus:

   (merge-pathnames #p"foo/bar.html" #p"/www/html/") ==>
#p"/www/html/foo/bar.html" The second pathname can also be relative, in
which case the resulting pathname will also be relative.

   (merge-pathnames #p"foo/bar.html" #p"html/") ==>
#p"html/foo/bar.html" To reverse this process and obtain a filename
relative to a particular root directory, you can use the handy function
ENOUGH-NAMESTRING.

   (enough-namestring #p"/www/html/foo/bar.html" #p"/www/") ==>
"html/foo/bar.html" You can then combine ENOUGH-NAMESTRING with
MERGE-PATHNAMES to create a pathname representing the same name but in a
different root.

   (merge-pathnames (enough-namestring #p"/www/html/foo/bar/baz.html"
#p"/www/") #p"/www-backups/") ==> #p"/www-backups/html/foo/bar/baz.html"
MERGE-PATHNAMES is also used internally by the standard functions that
actually access files in the file system to fill in incomplete
pathnames.  For instance, suppose you make a pathname with just a name
and a type.

   (make-pathname :name "foo" :type "txt") ==> #p"foo.txt" If you try to
use this pathname as an argument to OPEN, the missing components, such
as the directory, must be filled in before Lisp will be able to
translate the pathname to an actual filename.  Common Lisp will obtain
values for the missing components by merging the given pathname with the
value of the variable *DEFAULT-PATHNAME-DEFAULTS*.  The initial value of
this variable is determined by the implementation but is usually a
pathname with a directory component representing the directory where
Lisp was started and appropriate values for the host and device
components, if needed.  If invoked with just one argument,
MERGE-PATHNAMES will merge the argument with the value of
*DEFAULT-PATHNAME-DEFAULTS*.  For instance, if
*DEFAULT-PATHNAME-DEFAULTS* is #p"/home/peter/", then you'd get the
following:

   (merge-pathnames #p"foo.txt") ==> #p"/home/peter/foo.txt"


File: pcl.info,  Node: 14-9,  Next: 14-10,  Prev: 14-8,  Up: Chapter 14

Two Representations of Directory Names
======================================

When dealing with pathnames that name directories, you need to be aware
of one wrinkle.  Pathnames separate the directory and name components,
but Unix and Windows consider directories just another kind of file.
Thus, on those systems, every directory has two different pathname
representations.

   One representation, which I'll call file form, treats a directory
like any other file and puts the last element of the namestring into the
name and type components.  The other representation, directory form,
places all the elements of the name in the directory component, leaving
the name and type components NIL. If /foo/bar/ is a directory, then both
of the following pathnames name it.

   (make-pathname :directory '(:absolute "foo") :name "bar") ; file form
(make-pathname :directory '(:absolute "foo" "bar")) ; directory form
When you create pathnames with MAKE-PATHNAME, you can control which form
you get, but you need to be careful when dealing with namestrings.  All
current implementations create file form pathnames unless the namestring
ends with a path separator.  But you can't rely on user-supplied
namestrings necessarily being in one form or another.  For instance,
suppose you've prompted the user for a directory to save a file in and
they entered "/home/peter".  If you pass that value as the :defaults
argument of MAKE-PATHNAME like this:

   (make-pathname :name "foo" :type "txt" :defaults user-supplied-name)
you'll end up saving the file in /home/foo.txt rather than the intended
/home/peter/foo.txt because the "peter" in the namestring will be placed
in the name component when user-supplied-name is converted to a
pathname.  In the pathname portability library I'll discuss in the next
chapter, you'll write a function called pathname-as-directory that
converts a pathname to directory form.  With that function you can
reliably save the file in the directory indicated by the user.

   (make-pathname :name "foo" :type "txt" :defaults
(pathname-as-directory user-supplied-name))


File: pcl.info,  Node: 14-10,  Next: 14-11,  Prev: 14-9,  Up: Chapter 14

Interacting with the File System
================================

While the most common interaction with the file system is probably
OPENing files for reading and writing, you'll also occasionally want to
test whether a file exists, list the contents of a directory, delete and
rename files, create directories, and get information about a file such
as who owns it, when it was last modified, and its length.  This is
where the generality of the pathname abstraction begins to cause a bit
of pain: because the language standard doesn't specify how functions
that interact with the file system map to any specific file system,
implementers are left with a fair bit of leeway.

   That said, most of the functions that interact with the file system
are still pretty straightforward.  I'll discuss the standard functions
here and point out the ones that suffer from nonportability between
implementations.  In the next chapter you'll develop a pathname
portability library to smooth over some of those nonportability issues.

   To test whether a file exists in the file system corresponding to a
pathname designator-a pathname, namestring, or file stream-you can use
the function PROBE-FILE. If the file named by the pathname designator
exists, PROBE-FILE returns the file's truename, a pathname with any file
system-level translations such as resolving symbolic links performed.
Otherwise, it returns NIL. However, not all implementations support
using this function to test whether a directory exists.  Also, Common
Lisp doesn't provide a portable way to test whether a given file that
exists is a regular file or a directory.  In the next chapter you'll
wrap PROBE-FILE with a new function, file-exists-p, that can both test
whether a directory exists and tell you whether a given name is the name
of a file or directory.

   Similarly, the standard function for listing files in the file
system, DIRECTORY, works fine for simple cases, but the differences
between implementations make it tricky to use portably.  In the next
chapter you'll define a list-directory function that smoothes over some
of these differences.

   DELETE-FILE and RENAME-FILE do what their names suggest.  DELETE-FILE
takes a pathname designator and deletes the named file, returning true
if it succeeds.  Otherwise it signals a FILE-ERROR.11

   RENAME-FILE takes two pathname designators and renames the file named
by the first name to the second name.

   You can create directories with the function
ENSURE-DIRECTORIES-EXIST. It takes a pathname designator and ensures
that all the elements of the directory component exist and are
directories, creating them as necessary.  It returns the pathname it was
passed, which makes it convenient to use inline.

   (with-open-file (out (ensure-directories-exist name) :direction
:output) ...  ) Note that if you pass ENSURE-DIRECTORIES-EXIST a
directory name, it should be in directory form, or the leaf directory
won't be created.

   The functions FILE-WRITE-DATE and FILE-AUTHOR both take a pathname
designator.  FILE-WRITE-DATE returns the time in number of seconds since
midnight January 1, 1900, Greenwich mean time (GMT), that the file was
last written, and FILE-AUTHOR returns, on Unix and Windows, the file
owner.12

   To find the length of a file, you can use the function FILE-LENGTH.
For historical reasons FILE-LENGTH takes a stream as an argument rather
than a pathname.  In theory this allows FILE-LENGTH to return the length
in terms of the element type of the stream.  However, since on most
present-day operating systems, the only information available about the
length of a file, short of actually reading the whole file to measure
it, is its length in bytes, that's what most implementations return,
even when FILE-LENGTH is passed a character stream.  However, the
standard doesn't require this behavior, so for predictable results, the
best way to get the length of a file is to use a binary stream.13

   (with-open-file (in filename :element-type '(unsigned-byte 8))
(file-length in)) A related function that also takes an open file stream
as its argument is FILE-POSITION. When called with just a stream, this
function returns the current position in the file-the number of elements
that have been read from or written to the stream.  When called with two
arguments, the stream and a position designator, it sets the position of
the stream to the designated position.  The position designator must be
the keyword :start, the keyword :end, or a non-negative integer.  The
two keywords set the position of the stream to the start or end of the
file while an integer moves to the indicated position in the file.  With
a binary stream the position is simply a byte offset into the file.
However, for character streams things are a bit more complicated because
of character-encoding issues.  Your best bet, if you need to jump around
within a file of textual data, is to only ever pass, as a second
argument to the two-argument version of FILE-POSITION, a value
previously returned by the one-argument version of FILE-POSITION with
the same stream argument.


File: pcl.info,  Node: 14-11,  Next: Chapter 15,  Prev: 14-10,  Up: Chapter 14

Other Kinds of I/O
==================

In addition to file streams, Common Lisp supports other kinds of
streams, which can also be used with the various reading, writing, and
printing I/O functions.  For instance, you can read data from, or write
data to, a string using STRING-STREAMs, which you can create with the
functions MAKE-STRING-INPUT-STREAM and MAKE-STRING-OUTPUT-STREAM.

   MAKE-STRING-INPUT-STREAM takes a string and optional start and end
indices to bound the area of the string from which data should be read
and returns a character stream that you can pass to any of the
character-based input functions such as READ-CHAR, READ-LINE, or READ.
For example, if you have a string containing a floating-point literal in
Common Lisp's syntax, you can convert it to a float like this:

   (let ((s (make-string-input-stream "1.23"))) (unwind-protect (read s)
(close s))) Similarly, MAKE-STRING-OUTPUT-STREAM creates a stream you
can use with FORMAT, PRINT, WRITE-CHAR, WRITE-LINE, and so on.  It takes
no arguments.  Whatever you write, a string output stream will be
accumulated into a string that can then be obtained with the function
GET-OUTPUT-STREAM-STRING. Each time you call GET-OUTPUT-STREAM-STRING,
the stream's internal string is cleared so you can reuse an existing
string output stream.

   However, you'll rarely use these functions directly, because the
macros WITH-INPUT-FROM-STRING and WITH-OUTPUT-TO-STRING provide a more
convenient interface.  WITH-INPUT-FROM-STRING is similar to
WITH-OPEN-FILE-it creates a string input stream from a given string and
then executes the forms in its body with the stream bound to the
variable you provide.  For instance, instead of the LET form with the
explicit UNWIND-PROTECT, you'd probably write this:

   (with-input-from-string (s "1.23") (read s)) The
WITH-OUTPUT-TO-STRING macro is similar: it binds a newly created string
output stream to a variable you name and then executes its body.  After
all the body forms have been executed, WITH-OUTPUT-TO-STRING returns the
value that would be returned by GET-OUTPUT-STREAM-STRING.

   CL-USER> (with-output-to-string (out) (format out "hello, world ")
(format out "~s" (list 1 2 3))) "hello, world (1 2 3)" The other kinds
of streams defined in the language standard provide various kinds of
stream "plumbing," allowing you to plug together streams in almost any
configuration.  A BROADCAST-STREAM is an output stream that sends any
data written to it to a set of output streams provided as arguments to
its constructor function, MAKE-BROADCAST-STREAM.14 Conversely, a
CONCATENATED-STREAM is an input stream that takes its input from a set
of input streams, moving from stream to stream as it hits the end of
each stream.  CONCATENATED-STREAMs are constructed with the function
MAKE-CONCATENATED-STREAM, which takes any number of input streams as
arguments.

   Two kinds of bidirectional streams that can plug together streams in
a couple ways are TWO-WAY-STREAM and ECHO-STREAM. Their constructor
functions, MAKE-TWO-WAY-STREAM and MAKE-ECHO-STREAM, both take two
arguments, an input stream and an output stream, and return a stream of
the appropriate type, which you can use with both input and output
functions.

   In a TWO-WAY-STREAM every read you perform will return data read from
the underlying input stream, and every write will send data to the
underlying output stream.  An ECHO-STREAM works essentially the same way
except that all the data read from the underlying input stream is also
echoed to the output stream.  Thus, the output stream of an ECHO-STREAM
stream will contain a transcript of both sides of the conversation.

   Using these five kinds of streams, you can build almost any topology
of stream plumbing you want.

   Finally, although the Common Lisp standard doesn't say anything about
networking APIs, most implementations support socket programming and
typically implement sockets as another kind of stream, so you can use
all the regular I/O functions with them.15

   Now you're ready to move on to building a library that smoothes over
some of the differences between how the basic pathname functions behave
in different Common Lisp implementations.


File: pcl.info,  Node: Chapter 15,  Next: Chapter 16,  Prev: Chapter 14,  Up: Top

15. Practical: A Portable Pathname Library
==========================================

As I discussed in the previous chapter, Common Lisp provides an
abstraction, the pathname, that's supposed to insulate you from the
details of how different operating systems and file systems name files.
Pathnames provide a useful API for manipulating names as names, but when
it comes to the functions that actually interact with the file system,
things get a bit hairy.

   The root of the problem, as I mentioned, is that the pathname
abstraction was designed to represent filenames on a much wider variety
of file systems than are commonly used now.  Unfortunately, by making
pathnames abstract enough to account for a wide variety of file systems,
Common Lisp's designers left implementers with a fair number of choices
to make about how exactly to map the pathname abstraction onto any
particular file system.  Consequently, different implementers, each
implementing the pathname abstraction for the same file system, just by
making different choices at a few key junctions, could end up with
conforming implementations that nonetheless provide different behavior
for several of the main pathname-related functions.

   However, one way or another, all implementations provide the same
basic functionality, so it's not too hard to write a library that
provides a consistent interface for the most common operations across
different implementations.  That's your task for this chapter.  In
addition to giving you several useful functions that you'll use in
future chapters, writing this library will give you a chance to learn
how to write code that deals with differences between implementations.

* Menu:

* 15-1::       The API
* 15-2::       *FEATURES* and Read-Time Conditionalization
* 15-3::       Listing a Directory
* 15-4::       Testing a File's Existence
* 15-5::       Walking a Directory Tree


File: pcl.info,  Node: 15-1,  Next: 15-2,  Prev: Chapter 15,  Up: Chapter 15

The API
=======

The basic operations the library will support will be getting a list of
files in a directory and determining whether a file or directory with a
given name exists.  You'll also write a function for recursively walking
a directory hierarchy, calling a given function for each pathname in the
tree.

   In theory, these directory listing and file existence operations are
already provided by the standard functions DIRECTORY and PROBE-FILE.
However, as you'll see, there are enough different ways to implement
these functions-all within the bounds of valid interpretations of the
language standard-that you'll want to write new functions that provide a
consistent behavior across implementations.


File: pcl.info,  Node: 15-2,  Next: 15-3,  Prev: 15-1,  Up: Chapter 15

*FEATURES* and Read-Time Conditionalization
===========================================

Before you can implement this API in a library that will run correctly
on multiple Common Lisp implementations, I need to show you the
mechanism for writing implementation-specific code.

   While most of the code you write can be "portable" in the sense that
it will run the same on any conforming Common Lisp implementation, you
may occasionally need to rely on implementation-specific functionality
or to write slightly different bits of code for different
implementations.  To allow you to do so without totally destroying the
portability of your code, Common Lisp provides a mechanism, called
read-time conditionalization, that allows you to conditionally include
code based on various features such as what implementation it's being
run in.

   The mechanism consists of a variable *FEATURES* and two extra bits of
syntax understood by the Lisp reader.  *FEATURES* is a list of symbols;
each symbol represents a "feature" that's present in the implementation
or on the underlying platform.  These symbols are then used in feature
expressions that evaluate to true or false depending on whether the
symbols in the expression are present in *FEATURES*.  The simplest
feature expression is a single symbol; the expression is true if the
symbol is in *FEATURES* and false if it isn't.  Other feature
expressions are boolean expressions built out of NOT, AND, and OR
operators.  For instance, if you wanted to conditionalize some code to
be included only if the features foo and bar were present, you could
write the feature expression (and foo bar).

   The reader uses feature expressions in conjunction with two bits of
syntax, #+ and #-.  When the reader sees either of these bits of syntax,
it first reads a feature expression and then evaluates it as I just
described.  When a feature expression following a #+ is true, the reader
reads the next expression normally.  Otherwise it skips the next
expression, treating it as whitespace.  #- works the same way except it
reads the form if the feature expression is false and skips it if it's
true.

   The initial value of *FEATURES* is implementation dependent, and what
functionality is implied by the presence of any given symbol is likewise
defined by the implementation.  However, all implementations include at
least one symbol that indicates what implementation it is.  For
instance, Allegro Common Lisp includes the symbol :allegro, CLISP
includes :clisp, SBCL includes :sbcl, and CMUCL includes :cmu.  To avoid
dependencies on packages that may or may not exist in different
implementations, the symbols in *FEATURES* are usually keywords, and the
reader binds *PACKAGE* to the KEYWORD package while reading feature
expressions.  Thus, a name with no package qualification will be read as
a keyword symbol.  So, you could write a function that behaves slightly
differently in each of the implementations just mentioned like this:

   (defun foo () #+allegro (do-one-thing) #+sbcl (do-another-thing)
#+clisp (something-else) #+cmu (yet-another-version) #-(or allegro sbcl
clisp cmu) (error "Not implemented")) In Allegro that code will be read
as if it had been written like this:

   (defun foo () (do-one-thing)) while in SBCL the reader will read
this:

   (defun foo () (do-another-thing)) while in an implementation other
than one of the ones specifically conditionalized, it will read this:

   (defun foo () (error "Not implemented")) Because the
conditionalization happens in the reader, the compiler doesn't even see
expressions that are skipped.1 This means you pay no runtime cost for
having different versions for different implementations.  Also, when the
reader skips conditionalized expressions, it doesn't bother interning
symbols, so the skipped expressions can safely contain symbols from
packages that may not exist in other implementations.


File: pcl.info,  Node: 15-3,  Next: 15-4,  Prev: 15-2,  Up: Chapter 15

Listing a Directory
===================

You can implement the function for listing a single directory,
list-directory, as a thin wrapper around the standard function
DIRECTORY. DIRECTORY takes a special kind of pathname, called a wild
pathname, that has one or more components containing the special value
:wild and returns a list of pathnames representing files in the file
system that match the wild pathname.2 The matching algorithm-like most
things having to do with the interaction between Lisp and a particular
file system-isn't defined by the language standard, but most
implementations on Unix and Windows follow the same basic scheme.

   The DIRECTORY function has two problems that you need to address with
list-directory.  The main one is that certain aspects of its behavior
differ fairly significantly between different Common Lisp
implementations, even on the same operating system.  The other is that
while DIRECTORY provides a powerful interface for listing files, to use
it properly requires understanding some rather subtle points about the
pathname abstraction.  Between these subtleties and the idiosyncrasies
of different implementations, actually writing portable code that uses
DIRECTORY to do something as simple as listing all the files and
subdirectories in a single directory can be a frustrating experience.
You can deal with those subtleties and idiosyncrasies once and for all,
by writing list-directory, and forget them thereafter.

   One subtlety I discussed in Chapter 14 is the two ways to represent
the name of a directory as a pathname: directory form and file form.

   To get DIRECTORY to return a list of files in /home/peter/, you need
to pass it a wild pathname whose directory component is the directory
you want to list and whose name and type components are :wild.  Thus, to
get a listing of the files in /home/peter/, it might seem you could
write this:

   (directory (make-pathname :name :wild :type :wild :defaults
home-dir)) where home-dir is a pathname representing /home/peter/.  This
would work if home-dir were in directory form.  But if it were in file
form-for example, if it had been created by parsing the namestring
"/home/peter"-then that same expression would list all the files in
/home since the name component "peter" would be replaced with :wild.

   To avoid having to worry about explicitly converting between
representations, you can define list-directory to accept a nonwild
pathname in either form, which it will then convert to the appropriate
wild pathname.

   To help with this, you should define a few helper functions.  One,
component-present-p, will test whether a given component of a pathname
is "present," meaning neither NIL nor the special value :unspecific.3
Another, directory-pathname-p, tests whether a pathname is already in
directory form, and the third, pathname-as-directory, converts any
pathname to a directory form pathname.

   (defun component-present-p (value) (and value (not (eql value
:unspecific))))

   (defun directory-pathname-p (p) (and (not (component-present-p
(pathname-name p))) (not (component-present-p (pathname-type p))) p))

   (defun pathname-as-directory (name) (let ((pathname (pathname name)))
(when (wild-pathname-p pathname) (error "Can't reliably convert wild
pathnames."))  (if (not (directory-pathname-p name)) (make-pathname
:directory (append (or (pathname-directory pathname) (list :relative))
(list (file-namestring pathname))) :name nil :type nil :defaults
pathname) pathname))) Now it seems you could generate a wild pathname to
pass to DIRECTORY by calling MAKE-PATHNAME with a directory form name
returned by pathname-as-directory.  Unfortunately, it's not quite that
simple, thanks to a quirk in CLISP's implementation of DIRECTORY. In
CLISP, DIRECTORY won't return files with no extension unless the type
component of the wildcard is NIL rather than :wild.  So you can define a
function, directory-wildcard, that takes a pathname in either directory
or file form and returns a proper wildcard for the given implementation
using read-time conditionalization to make a pathname with a :wild type
component in all implementations except for CLISP and NIL in CLISP.

   (defun directory-wildcard (dirname) (make-pathname :name :wild :type
#-clisp :wild #+clisp nil :defaults (pathname-as-directory dirname)))
Note how each read-time conditional operates at the level of a single
expression After #-clisp, the expression :wild is either read or
skipped; likewise, after #+clisp, the NIL is read or skipped.

   Now you can take a first crack at the list-directory function.

   (defun list-directory (dirname) (when (wild-pathname-p dirname)
(error "Can only list concrete directory names."))  (directory
(directory-wildcard dirname))) As it stands, this function would work in
SBCL, CMUCL, and LispWorks.  Unfortunately, a couple more implementation
differences remain to be smoothed over.  One is that not all
implementations will return subdirectories of the given directory.
Allegro, SBCL, CMUCL, and LispWorks do.  OpenMCL doesn't by default but
will if you pass DIRECTORY a true value via the implementation-specific
keyword argument :directories.  CLISP's DIRECTORY returns subdirectories
only when it's passed a wildcard pathname with :wild as the last element
of the directory component and NIL name and type components.  In this
case, it returns only subdirectories, so you'll need to call DIRECTORY
twice with different wildcards and combine the results.

   Once you get all the implementations returning directories, you'll
discover they can also differ in whether they return the names of
directories in directory or file form.  You want list-directory to
always return directory names in directory form so you can differentiate
subdirectories from regular files based on just the name.  Except for
Allegro, all the implementations this library will support do that.
Allegro, on the other hand, requires you to pass DIRECTORY the
implementation-specific keyword argument :directories-are-files NIL to
get it to return directories in file form.

   Once you know how to make each implementation do what you want,
actually writing list-directory is simply a matter of combining the
different versions using read-time conditionals.

   (defun list-directory (dirname) (when (wild-pathname-p dirname)
(error "Can only list concrete directory names."))  (let ((wildcard
(directory-wildcard dirname)))

   #+(or sbcl cmu lispworks) (directory wildcard)

   #+openmcl (directory wildcard :directories t)

   #+allegro (directory wildcard :directories-are-files nil)

   #+clisp (nconc (directory wildcard) (directory
(clisp-subdirectories-wildcard wildcard)))

   #-(or sbcl cmu lispworks openmcl allegro clisp) (error
"list-directory not implemented"))) The function
clisp-subdirectories-wildcard isn't actually specific to CLISP, but
since it isn't needed by any other implementation, you can guard its
definition with a read-time conditional.  In this case, since the
expression following the #+ is the whole DEFUN, the whole function
definition will be included or not, depending on whether clisp is
present in *FEATURES*.

   #+clisp (defun clisp-subdirectories-wildcard (wildcard)
(make-pathname :directory (append (pathname-directory wildcard) (list
:wild)) :name nil :type nil :defaults wildcard))


File: pcl.info,  Node: 15-4,  Next: 15-5,  Prev: 15-3,  Up: Chapter 15

Testing a File's Existence
==========================

To replace PROBE-FILE, you can define a function called file-exists-p.
It should accept a pathname and return an equivalent pathname if the
file exists and NIL if it doesn't.  It should be able to accept the name
of a directory in either directory or file form but should always return
a directory form pathname if the file exists and is a directory.  This
will allow you to use file-exists-p, along with directory-pathname-p, to
test whether an arbitrary name is the name of a file or directory.

   In theory, file-exists-p is quite similar to the standard function
PROBE-FILE; indeed, in several implementations-SBCL, LispWorks, and
OpenMCL-PROBE-FILE already gives you the behavior you want for
file-exists-p.  But not all implementations of PROBE-FILE behave quite
the same.

   Allegro and CMUCL's PROBE-FILE functions are close to what you
need-they will accept the name of a directory in either form but,
instead of returning a directory form name, simply return the name in
the same form as the argument it was passed.  Luckily, if passed the
name of a nondirectory in directory form, they return NIL. So with those
implementations you can get the behavior you want by first passing the
name to PROBE-FILE in directory form-if the file exists and is a
directory, it will return the directory form name.  If that call returns
NIL, then you try again with a file form name.

   CLISP, on the other hand, once again has its own way of doing things.
Its PROBE-FILE immediately signals an error if passed a name in
directory form, regardless of whether a file or directory exists with
that name.  It also signals an error if passed a name in file form
that's actually the name of a directory.  For testing whether a
directory exists, CLISP provides its own function: probe-directory (in
the ext package).  This is almost the mirror image of PROBE-FILE: it
signals an error if passed a name in file form or if passed a name in
directory form that happens to name a file.  The only difference is it
returns T rather than a pathname when the named directory exists.

   But even in CLISP you can implement the desired semantics by wrapping
the calls to PROBE-FILE and probe-directory in IGNORE-ERRORS.4

   (defun file-exists-p (pathname) #+(or sbcl lispworks openmcl)
(probe-file pathname)

   #+(or allegro cmu) (or (probe-file (pathname-as-directory pathname))
(probe-file pathname))

   #+clisp (or (ignore-errors (probe-file (pathname-as-file pathname)))
(ignore-errors (let ((directory-form (pathname-as-directory pathname)))
(when (ext:probe-directory directory-form) directory-form))))

   #-(or sbcl cmu lispworks openmcl allegro clisp) (error "file-exists-p
not implemented")) The function pathname-as-file that you need for the
CLISP implementation of file-exists-p is the inverse of the previously
defined pathname-as-directory, returning a pathname that's the file form
equivalent of its argument.  This function, despite being needed here
only by CLISP, is generally useful, so define it for all implementations
and make it part of the library.

   (defun pathname-as-file (name) (let ((pathname (pathname name)))
(when (wild-pathname-p pathname) (error "Can't reliably convert wild
pathnames."))  (if (directory-pathname-p name) (let* ((directory
(pathname-directory pathname)) (name-and-type (pathname (first (last
directory))))) (make-pathname :directory (butlast directory) :name
(pathname-name name-and-type) :type (pathname-type name-and-type)
:defaults pathname)) pathname)))


File: pcl.info,  Node: 15-5,  Next: Chapter 16,  Prev: 15-4,  Up: Chapter 15

Walking a Directory Tree
========================

Finally, to round out this library, you can implement a function called
walk-directory.  Unlike the functions defined previously, this function
doesn't need to do much of anything to smooth over implementation
differences; it just needs to use the functions you've already defined.
However, it's quite handy, and you'll use it several times in subsequent
chapters.  It will take the name of a directory and a function and call
the function on the pathnames of all the files under the directory,
recursively.  It will also take two keyword arguments: :directories and
:test.  When :directories is true, it will call the function on the
pathnames of directories as well as regular files.  The :test argument,
if provided, specifies another function that's invoked on each pathname
before the main function is; the main function will be called only if
the test function returns true.

   (defun walk-directory (dirname fn &key directories (test (constantly
t))) (labels ((walk (name) (cond ((directory-pathname-p name) (when (and
directories (funcall test name)) (funcall fn name)) (dolist (x
(list-directory name)) (walk x))) ((funcall test name) (funcall fn
name))))) (walk (pathname-as-directory dirname)))) Now you have a useful
library of functions for dealing with pathnames.  As I mentioned, these
functions will come in handy in later chapters, particularly Chapters 23
and 27, where you'll use walk-directory to crawl through directory trees
containing spam messages and MP3 files.  But before we get to that,
though, I need to talk about object orientation, the topic of the next
two chapters.


File: pcl.info,  Node: Chapter 16,  Next: Chapter 17,  Prev: Chapter 15,  Up: Top

16. Object Reorientation: Generic Functions
===========================================

Because the invention of Lisp predated the rise of object-oriented
programming by a couple decades, (1) new Lispers are sometimes surprised
to discover what a thoroughly object-oriented language Common Lisp is.
Common Lisp's immediate predecessors were developed at a time when
object orientation was an exciting new idea and there were many
experiments with ways to incorporate the ideas of object orientation,
especially as manifested in Smalltalk, into Lisp.  As part of the Common
Lisp standardization, a synthesis of several of these experiments
emerged under the name Common Lisp Object System, or CLOS. The ANSI
standard incorporated CLOS into the language, so it no longer really
makes sense to speak of CLOS as a separate entity.

   The features CLOS contributed to Common Lisp range from those that
can hardly be avoided to relatively esoteric manifestations of Lisp's
language-as-language-building-tool philosophy.  Complete coverage of all
these features is beyond the scope of this book, but in this chapter and
the next I'll describe the bread-and-butter features and give an
overview of Common Lisp's approach to objects.

   You should note at the outset that Common Lisp's object system offers
a fairly different embodiment of the principles of object orientation
than many other languages.  If you have a deep understanding of the
fundamental ideas behind object orientation, you'll likely appreciate
the particularly powerful and general way Common Lisp manifests those
ideas.  On the other hand, if your experience with object orientation
has been largely with a single language, you may find Common Lisp's
approach somewhat foreign; you should try to avoid assuming that there's
only one way for a language to support object orientation.  (2) If you
have little object-oriented programming experience, you should have no
trouble understanding the explanations here, though it may help to
ignore the occasional comparisons to the way other languages do things.

* Menu:

* 16-1::   Generic Functions and Classes
* 16-2::   Generic Functions and Methods
* 16-3::   DEFGENERIC
* 16-4::   DEFMETHOD
* 16-5::   Method Combination
* 16-6::   The Standard Method Combination
* 16-7::   Other Method Combinations
* 16-8::   Multimethods
* 16-9::   To Be Continued . . .

   ---------- Footnotes ----------

   (1) 1

   (2) 2


File: pcl.info,  Node: 16-1,  Next: 16-2,  Prev: Chapter 16,  Up: Chapter 16

Generic Functions and Classes
=============================

The fundamental idea of object orientation is that a powerful way to
organize a program is to define data types and then associate operations
with those data types.  In particular, you want to be able to invoke an
operation and have the exact behavior determined by the type of the
object or objects on which the operation was invoked.  The classic
example used, seemingly by all introductions to object orientation, is
an operation draw that can be applied to objects representing various
geometric shapes.  Different implementations of the draw operation can
be provided for drawing circles, triangles, and squares, and a call to
draw will actually result in drawing a circle, triangle, or square,
depending on the type of the object to which the draw operation is
applied.  The different implementations of draw are defined separately,
and new versions can be defined that draw other shapes without having to
change the code of either the caller or any of the other draw
implementations.  This feature of object orientation goes by the fancy
Greek name polymorphism, meaning "many forms," because a single
conceptual operation, such as drawing an object, can take many different
concrete forms.

   Common Lisp, like most object-oriented languages today, is
class-based; all objects are instances of a particular class.  (1) The
class of an object determines its representation-built-in classes such
as NUMBER and STRING have opaque representations accessible only via the
standard functions for manipulating those types, while instances of
user-defined classes, as you'll see in the next chapter, consist of
named parts called slots.

   Classes are arranged in a hierarchy, a taxonomy for all objects.  A
class can be defined as a subclass of other classes, called its
superclasses.  A class inherits part of its definition from its
superclasses and instances of a class are also considered instances of
the superclasses.  In Common Lisp, the hierarchy of classes has a single
root, the class T, which is a direct or indirect superclass of every
other class.  Thus, every datum in Common Lisp is an instance of T. (2)
Common Lisp also supports multiple inheritance-a single class can have
multiple direct superclasses.

   Outside the Lisp family, almost all object-oriented languages follow
the basic pattern established by Simula of having behavior associated
with classes through methods or member functions that belong to a
particular class.  In these languages, a method is invoked on a
particular object, and the class of that object determines what code
runs.  This model of method invocation is called-after the Smalltalk
terminology-message passing.  Conceptually, method invocation in a
message-passing system starts by sending a message containing the name
of the method to run and any arguments to the object on which the method
is being invoked.  The object then uses its class to look up the method
associated with the name in the message and runs it.  Because each class
can have its own method for a given name, the same message, sent to
different objects, can invoke different methods.

   Early Lisp object systems worked in a similar way, providing a
special function SEND that could be used to send a message to a
particular object.  However, this wasn't entirely satisfactory, as it
made method invocations different from normal function calls.
Syntactically method invocations were written like this:

     (send object 'foo)

   rather than like this:

     (foo object)

   More significantly, because methods weren't functions, they couldn't
be passed as arguments to higher-order functions such as MAPCAR; if one
wanted to call a method on all the elements of a list with MAPCAR, one
had to write this:

     (mapcar #'(lambda (object) (send object 'foo)) objects)

   rather than this:

     (mapcar #'foo objects)

   Eventually the folks working on Lisp object systems unified methods
with functions by creating a new kind of function called a generic
function.  In addition to solving the problems just described, generic
functions opened up new possibilities for the object system, including
many features that simply don't make sense in a message-passing object
system.

   Generic functions are the heart of Common Lisp's object system and
the topic of the rest of this chapter.  While I can't talk about generic
functions without some mention of classes, for now I'll focus on how to
define and use generic functions.  In the next chapter I'll show you how
to define your own classes.

   ---------- Footnotes ----------

   (1) 3

   (2) 4


File: pcl.info,  Node: 16-2,  Next: 16-3,  Prev: 16-1,  Up: Chapter 16

Generic Functions and Methods
=============================

A generic function defines an abstract operation, specifying its name
and a parameter list but no implementation.  Here, for example, is how
you might define a generic function, draw, that will be used to draw
different kinds of shapes on the screen:

     (defgeneric draw (shape)
       (:documentation "Draw the given shape on the screen."))

   I'll discuss the syntax of DEFGENERIC in the next section; for now
just note that this definition doesn't contain any actual code.

   A generic function is generic in the sense that it can-at least in
theory-accept any objects as arguments.  (1) However, by itself a
generic function can't actually do anything; if you just define a
generic function, no matter what arguments you call it with, it will
signal an error.  The actual implementation of a generic function is
provided by methods.  Each method provides an implementation of the
generic function for particular classes of arguments.  Perhaps the
biggest difference between a generic function-based system and a
message-passing system is that methods don't belong to classes; they
belong to the generic function, which is responsible for determining
what method or methods to run in response to a particular invocation.

   Methods indicate what kinds of arguments they can handle by
specializing the required parameters defined by the generic function.
For instance, on the generic function draw, you might define one method
that specializes the shape parameter for objects that are instances of
the class circle while another method specializes shape for objects that
are instances of the class triangle.  They would look like this, eliding
the actual drawing code:

     (defmethod draw ((shape circle))
       ...)

     (defmethod draw ((shape triangle))
       ...)

   When a generic function is invoked, it compares the actual arguments
it was passed with the specializers of each of its methods to find the
applicable methods-those methods whose specializers are compatible with
the actual arguments.  If you invoke draw, passing an instance of
circle, the method that specialized shape on the class circle is
applicable, while if you pass it a triangle, then the method that
specializes shape on the class triangle applies.  In simple cases, only
one method will be applicable, and it will handle the invocation.  In
more complex cases, there may be multiple methods that apply; they're
then combined, as I'll discuss in the section "Method Combination," into
a single effective method that handles the invocation.

   You can specialize a parameter in two ways-usually you'll specify a
class that the argument must be an instance of.  Because instances of a
class are also considered instances of that class's superclasses, a
method with a parameter specialized on a particular class can be
applicable whenever the corresponding argument is a direct instance of
the specializing class or of any of its subclasses.  The other kind of
specializer is a so-called EQL specializer, which specifies a particular
object to which the method applies.

   When a generic function has only methods specialized on a single
parameter and all the specializers are class specializers, the result of
invoking a generic function is quite similar to the result of invoking a
method in a message-passing system-the combination of the name of the
operation and the class of the object on which it's invoked determines
what method to run.

   However, reversing the order of lookup opens up possibilities not
found in message-passing systems.  Generic functions support methods
that specialize on multiple parameters, provide a framework that makes
multiple inheritance much more manageable, and let you use declarative
constructs to control how methods are combined into an effective method,
supporting several common usage patterns without a lot of boilerplate
code.  I'll discuss those topics in a moment.  But first you need to
look at the basics of the two macros used to define the generic
functions DEFGENERIC and DEFMETHOD.

   ---------- Footnotes ----------

   (1) 5


File: pcl.info,  Node: 16-3,  Next: 16-4,  Prev: 16-2,  Up: Chapter 16

DEFGENERIC
==========

To give you a feel for these macros and the various facilities they
support, I'll show you some code you might write as part of a banking
application-or, rather, a toy banking application; the point is to look
at a few language features, not to learn how to really write banking
software.  For instance, this code doesn't even pretend to deal with
such issues as multiple currencies let alone audit trails and
transactional integrity.

   Because I'm not going to discuss how to define new classes until the
next chapter, for now you can just assume that certain classes already
exist: for starters, assume there's a class bank-account and that it has
two subclasses, checking-account and savings-account.  The class
hierarchy looks like this:

 [image src="imgs/account-hierarchy.png" ]

   The first generic function will be withdraw, which decreases the
account balance by a specified amount.  If the balance is less than the
amount, it should signal an error and leave the balance unchanged.  You
can start by defining the generic function with DEFGENERIC.

   The basic form of DEFGENERIC is similar to DEFUN except with no body.
The parameter list of DEFGENERIC specifies the parameters that must be
accepted by all the methods that will be defined on the generic
function.  In the place of the body, a DEFGENERIC can contain various
options.  One option you should always include is :documentation, which
you use to provide a string describing the purpose of the generic
function.  Because a generic function is purely abstract, it's important
to be clear to both users and implementers what it's for.  Thus, you
might define withdraw like this:

     (defgeneric withdraw (account amount)
       (:documentation "Withdraw the specified amount from the account.

   Signal an error if the current balance is less than amount."))


File: pcl.info,  Node: 16-4,  Next: 16-5,  Prev: 16-3,  Up: Chapter 16

DEFMETHOD
=========

Now you're ready to use DEFMETHOD to define methods that implement
withdraw.  (1)

   A method's parameter list must be congruent with its generic
function's.  In this case, that means all methods defined on withdraw
must have exactly two required parameters.  More generally, methods must
have the same number of required and optional parameters and must be
capable of accepting any arguments corresponding to any &rest or &key
parameters specified by the generic function.  (2)

   Since the basics of withdrawing are the same for all accounts, you
can define a method that specializes the account parameter on the
bank-account class.  You can assume the function balance returns the
current balance of the account and can be used with SETF-and thus with
DECF-to set the balance.  The function ERROR is a standard function used
to signal an error, which I'll discuss in greater detail in Chapter 19.
Using those two functions, you can define a basic withdraw method that
looks like this:

     (defmethod withdraw ((account bank-account) amount)
       (when (< (balance account) amount)
         (error "Account overdrawn."))
       (decf (balance account) amount))

   As this code suggests, the form of DEFMETHOD is even more like that
of DEFUN than DEFGENERIC's is.  The only difference is that the required
parameters can be specialized by replacing the parameter name with a
two-element list.  The first element is the name of the parameter, and
the second element is the specializer, either the name of a class or an
EQL specializer, the form of which I'll discuss in a moment.  The
parameter name can be anything-it doesn't have to match the name used in
the generic function, though it often will.

   This method will apply whenever the first argument to withdraw is an
instance of bank-account.  The second parameter, amount, is implicitly
specialized on T, and since all objects are instances of T, it doesn't
affect the applicability of the method.

   Now suppose all checking accounts have overdraft protection.  That
is, each checking account is linked to another bank account that's drawn
upon when the balance of the checking account itself can't cover a
withdrawal.  You can assume that the function overdraft-account takes a
checking-account object and returns a bank-account object representing
the linked account.

   Thus, withdrawing from a checking-account object requires a few extra
steps compared to withdrawing from a standard bank-account object.  You
must first check whether the amount being withdrawn is greater than the
account's current balance and, if it is, transfer the difference from
the overdraft account.  Then you can proceed as with a standard
bank-account object.

   So what you'd like to do is define a method on withdraw that
specializes on checking-account to handle the transfer and then lets the
method specialized on bank-account take control.  Such a method might
look like this:

     (defmethod withdraw ((account checking-account) amount)
       (let ((overdraft (- amount (balance account))))
         (when (plusp overdraft)
           (withdraw (overdraft-account account) overdraft)
           (incf (balance account) overdraft)))
       (call-next-method))

   The function CALL-NEXT-METHOD is part of the generic function
machinery used to combine applicable methods.  It indicates that control
should be passed from this method to the method specialized on
bank-account.  (3) When it's called with no arguments, as it is here,
the next method is invoked with whatever arguments were originally
passed to the generic function.  It can also be called with arguments,
which will then be passed onto the next method.

   You aren't required to invoke CALL-NEXT-METHOD in every method.
However, if you don't, the new method is then responsible for completely
implementing the desired behavior of the generic function.  For example,
if you had a subclass of bank-account, proxy-account, that didn't
actually keep track of its own balance but instead delegated withdrawals
to another account, you might write a method like this (assuming a
function, proxied-account, that returns the proxied account):

     (defmethod withdraw ((proxy proxy-account) amount)
       (withdraw (proxied-account proxy) amount))

   Finally, DEFMETHOD also allows you to create methods specialized on a
particular object with an EQL specializer.  For example, suppose the
banking app is going to be deployed in a particularly corrupt bank.
Suppose the variable *account-of-bank-president* holds a reference to a
particular bank account that belongs-as the name suggests-to the bank's
president.  Further suppose the variable *bank* represents the bank as a
whole, and the function embezzle steals money from the bank.  The bank
president might ask you to "fix" withdraw to handle his account
specially.

     (defmethod withdraw ((account (eql *account-of-bank-president*)) amount)
       (let ((overdraft (- amount (balance account))))
         (when (plusp overdraft)
           (incf (balance account) (embezzle *bank* overdraft)))
       (call-next-method)))

   Note, however, that the form in the EQL specializer that provides the
object to specialize on-*account-of-bank-president* in this case-is
evaluated once, when the DEFMETHOD is evaluated.  This method will be
specialized on the value of *account-of-bank-president* at the time the
method is defined; changing the variable later won't change the method.

   ---------- Footnotes ----------

   (1) 6

   (2) 7

   (3) 8


File: pcl.info,  Node: 16-5,  Next: 16-6,  Prev: 16-4,  Up: Chapter 16

Method Combination
==================

Outside the body of a method, CALL-NEXT-METHOD has no meaning.  Within a
method, it's given a meaning by the generic function machinery that
builds an effective method each time the generic function is invoked
using all the methods applicable to that particular invocation.  This
notion of building an effective method by combining applicable methods
is the heart of the generic function concept and is the thing that
allows generic functions to support facilities not found in
message-passing systems.  So it's worth taking a closer look at what's
really happening.  Folks with the message-passing model deeply ingrained
in their consciousness should pay particular attention because generic
functions turn method dispatching inside out compared to message
passing, making the generic function, rather than the class, the prime
mover.

   Conceptually, the effective method is built in three steps: First,
the generic function builds a list of applicable methods based on the
actual arguments it was passed.  Second, the list of applicable methods
is sorted according to the specificity of their parameter specializers.
Finally, methods are taken in order from the sorted list and their code
combined to produce the effective method.  (1)

   To find applicable methods, the generic function compares the actual
arguments with the corresponding parameter specializers in each of its
methods.  A method is applicable if, and only if, all the specializers
are compatible with the corresponding arguments.

   When the specializer is the name of a class, it's compatible if it
names the actual class of the argument or one of its superclasses.
(Recall that parameters without explicit specializers are implicitly
specialized on the class T so will be compatible with any argument.)  An
EQL specializer is compatible only when the argument is the same object
as was specified in the specializer.

   Because all the arguments are checked against the corresponding
specializers, they all affect whether a method is applicable.  Methods
that explicitly specialize more than one parameter are called
multimethods; I'll discuss them in the section "Multimethods."

   After the applicable methods have been found, the generic function
machinery needs to sort them before it can combine them into an
effective method.  To order two applicable methods, the generic function
compares their parameter specializers from left to right, (2) and the
first specializer that's different between the two methods determines
their ordering, with the method with the more specific specializer
coming first.

   Because only applicable methods are being sorted, you know all class
specializers will name classes that the corresponding argument is
actually an instance of.  In the typical case, if two class specializers
differ, one will be a subclass of the other.  In that case, the
specializer naming the subclass is considered more specific.  This is
why the method that specialized account on checking-account was
considered more specific than the method that specialized it on
bank-account.

   Multiple inheritance slightly complicates the notion of specificity
since the actual argument may be an instance of two classes, neither of
which is a subclass of the other.  If such classes are used as parameter
specializers, the generic function can't order them using only the rule
that subclasses are more specific than their superclasses.  In the next
chapter I'll discuss how the notion of specificity is extended to deal
with multiple inheritance.  For now, suffice it to say that there's a
deterministic algorithm for ordering class specializers.

   Finally, an EQL specializer is always more specific than any class
specializer, and because only applicable methods are being considered,
if more than one method has an EQL specializer for a particular
parameter, they must all have the same EQL specializer.  The comparison
of those methods will thus be decided based on other parameters.

   ---------- Footnotes ----------

   (1) 9

   (2) 10


File: pcl.info,  Node: 16-6,  Next: 16-7,  Prev: 16-5,  Up: Chapter 16

The Standard Method Combination
===============================

Now that you understand how the applicable methods are found and sorted,
you're ready to take a closer look at the last step-how the sorted list
of methods is combined into a single effective method.  By default,
generic functions use what's called the standard method combination.
The standard method combination combines methods so that
CALL-NEXT-METHOD works as you've already seen-the most specific method
runs first, and each method can pass control to the next most specific
method via CALL-NEXT-METHOD.

   However, there's a bit more to it than that.  The methods I've been
discussing so far are called primary methods.  Primary methods, as their
name suggests, are responsible for providing the primary implementation
of a generic function.  The standard method combination also supports
three kinds of auxiliary methods: :before, :after, and :around methods.
An auxiliary method definition is written with DEFMETHOD like a primary
method but with a method qualifier, which names the type of method,
between the name of the method and the parameter list.  For instance, a
:before method on withdraw that specializes the account parameter on the
class bank-account would start like this:

     (defmethod withdraw :before ((account bank-account) amount) ...)

   Each kind of auxiliary method is combined into the effective method
in a different way.  All the applicable :before methods-not just the
most specific-are run as part of the effective method.  They run, as
their name suggests, before the most specific primary method and are run
in most-specific-first order.  Thus, :before methods can be used to do
any preparation needed to ensure that the primary method can run.  For
instance, you could've used a :before method specialized on
checking-account to implement the overdraft protection on checking
accounts like this:

     (defmethod withdraw :before ((account checking-account) amount)
       (let ((overdraft (- amount (balance account))))
         (when (plusp overdraft)
           (withdraw (overdraft-account account) overdraft)
           (incf (balance account) overdraft))))

   This :before method has three advantages over a primary method.  One
is that it makes it immediately obvious how the method changes the
overall behavior of the withdraw function-it's not going to interfere
with the main behavior or change the result returned.

   The next advantage is that a primary method specialized on a class
more specific than checking-account won't interfere with this :before
method, making it easier for an author of a subclass of checking-account
to extend the behavior of withdraw while keeping part of the old
behavior.

   Lastly, since a :before method doesn't have to call CALL-NEXT-METHOD
to pass control to the remaining methods, it's impossible to introduce a
bug by forgetting to.

   The other auxiliary methods also fit into the effective method in
ways suggested by their names.  All the :after methods run after the
primary methods in most-specific-last order, that is, the reverse of the
:before methods.  Thus, the :before and :after methods combine to create
a sort of nested wrapping around the core functionality provided by the
primary methods-each more-specific :before method will get a chance to
set things up so the less-specific :before methods and primary methods
can run successfully, and each more-specific :after method will get a
chance to clean up after all the primary methods and less-specific
:after methods.

   Finally, :around methods are combined much like primary methods
except they're run "around" all the other methods.  That is, the code
from the most specific :around method is run before anything else.
Within the body of an :around method, CALL-NEXT-METHOD will lead to the
code of the next most specific :around method or, in the least specific
:around method, to the complex of :before, primary, and :after methods.
Almost all :around methods will contain such a call to CALL-NEXT-METHOD
because an :around method that doesn't will completely hijack the
implementation of the generic function from all the methods except for
more-specific :around methods.

   Occasionally that kind of hijacking is called for, but typically
:around methods are used to establish some dynamic context in which the
rest of the methods will run-to bind a dynamic variable, for example, or
to establish an error handler (as I'll discuss in Chapter 19).  About
the only time it's appropriate for an :around method to not call
CALL-NEXT-METHOD is when it returns a result cached from a previous call
to CALL-NEXT-METHOD. At any rate, an :around method that doesn't call
CALL-NEXT-METHOD is responsible for correctly implementing the semantics
of the generic function for all classes of arguments to which the method
may apply, including future subclasses.

   Auxiliary methods are just a convenient way to express certain common
patterns more concisely and concretely.  They don't actually allow you
to do anything you couldn't do by combining primary methods with
diligent adherence to a few coding conventions and some extra typing.
Perhaps their biggest benefit is that they provide a uniform framework
for extending generic functions.  Often a library will define a generic
function and provide a default primary method, allowing users of the
library to customize its behavior by defining appropriate auxiliary
methods.


File: pcl.info,  Node: 16-7,  Next: 16-8,  Prev: 16-6,  Up: Chapter 16

Other Method Combinations
=========================

In addition to the standard method combination, the language specifies
nine other built-in method combinations known as the simple built-in
method combinations.  You can also define custom method combinations,
though that's a fairly esoteric feature and beyond the scope of this
book.  I'll briefly cover how to use the simple built-in combinations to
give you a sense of the possibilities.

   All the simple combinations follow the same pattern: instead of
invoking the most specific primary method and letting it invoke
less-specific primary methods via CALL-NEXT-METHOD, the simple method
combinations produce an effective method that contains the code of all
the primary methods, one after another, all wrapped in a call to the
function, macro, or special operator that gives the method combination
its name.  The nine combinations are named for the operators: +, AND,
OR, LIST, APPEND, NCONC, MIN, MAX, and PROGN. The simple combinations
also support only two kinds of methods, primary methods, which are
combined as just described, and :around methods, which work like :around
methods in the standard method combination.

   For example, a generic function that uses the + method combination
will return the sum of all the results returned by its primary methods.
Note that the AND and OR method combinations won't necessarily run all
the primary methods because of those macros' short-circuiting behavior-a
generic function using the AND combination will return NIL as soon as
one of the methods does and will return the value of the last method
otherwise.  Similarly, the OR combination will return the first non-NIL
value returned by any of the methods.

   To define a generic function that uses a particular method
combination, you include a :method-combination option in the DEFGENERIC
form.  The value supplied with this option is the name of the method
combination you want to use.  For example, to define a generic function,
priority, that returns the sum of values returned by individual methods
using the + method combination, you might write this:

     (defgeneric priority (job)
       (:documentation "Return the priority at which the job should be run.")
       (:method-combination +))

   By default all these method combinations combine the primary methods
in most-specific-first order.  However, you can reverse the order by
including the keyword :most-specific-last after the name of the method
combination in the DEFGENERIC form.  The order probably doesn't matter
if you're using the + combination unless the methods have side effects,
but for demonstration purposes you can change priority to use
most-specific-last order like this:

     (defgeneric priority (job)
       (:documentation "Return the priority at which the job should be run.")
       (:method-combination + :most-specific-last))

   The primary methods on a generic function that uses one of these
combinations must be qualified with the name of the method combination.
Thus, a primary method defined on priority might look like this:

     (defmethod priority + ((job express-job)) 10)

   This makes it obvious when you see a method definition that it's part
of a particular kind of generic function.

   All the simple built-in method combinations also support :around
methods that work like :around methods in the standard method
combination: the most specific :around method runs before any other
methods, and CALL-NEXT-METHOD is used to pass control to
less-and-less-specific :around methods until it reaches the combined
primary methods.  The :most-specific-last option doesn't affect the
order of :around methods.  And, as I mentioned before, the built-in
method combinations don't support :before or :after methods.

   Like the standard method combination, these method combinations don't
allow you to do anything you couldn't do "by hand."  Rather, they allow
you to express what you want and let the language take care of wiring
everything together for you, making your code both more concise and more
expressive.

   That said, probably 99 percent of the time, the standard method
combination will be exactly what you want.  Of the remaining 1 percent,
probably 99 percent of them will be handled by one of the simple
built-in method combinations.  If you run into one of the 1 percent of 1
percent of cases where none of the built-in combinations suffices, you
can look up DEFINE-METHOD-COMBINATION in your favorite Common Lisp
reference.


File: pcl.info,  Node: 16-8,  Next: 16-9,  Prev: 16-7,  Up: Chapter 16

Multimethods
============

Methods that explicitly specialize more than one of the generic
function's required parameters are called multimethods.  Multimethods
are where generic functions and message passing really part ways.
Multimethods don't fit into message-passing languages because they don't
belong to a particular class; instead, each multimethod defines a part
of the implementations of a given generic function that applies when the
generic function is invoked with arguments that match all the method's
specialized parameters.

   Multimethods are perfect for all those situations where, in a
message-passing language, you struggle to decide to which class a
certain behavior ought to belong.  Is the sound a drum makes when it's
hit with a drumstick a function of what kind of drum it is or what kind
of stick you use to hit it?  Both, of course.  To model this situation
in Common Lisp, you simply define a generic function beat that takes two
arguments.

     (defgeneric beat (drum stick)
       (:documentation
        "Produce a sound by hitting the given drum with the given stick."))

   Then you can define various multimethods to implement beat for the
combinations you care about.  For example:

     (defmethod beat ((drum snare-drum) (stick wooden-drumstick)) ...)
     (defmethod beat ((drum snare-drum) (stick brush)) ...)
     (defmethod beat ((drum snare-drum) (stick soft-mallet)) ...)
     (defmethod beat ((drum tom-tom) (stick wooden-drumstick)) ...)
     (defmethod beat ((drum tom-tom) (stick brush)) ...)
     (defmethod beat ((drum tom-tom) (stick soft-mallet)) ...)

   Multimethods don't help with the combinatorial explosion-if you need
to model five kinds of drums and six kinds of sticks, and every
combination makes a different sound, there's no way around it; you need
thirty different methods to implement all the combinations, with or
without multimethods.  What multimethods do save you from is having to
write a bunch of dispatching code by letting you use the same built-in
polymorphic dispatching that's so useful when dealing with methods
specialized on a single parameter.  (1)

   Multimethods also save you from having to tightly couple one set of
classes with the other.  In the drum/stick example, nothing requires the
implementation of the drum classes to know about the various classes of
drumstick, and nothing requires the drumstick classes to know anything
about the various classes of drum.  The multimethods connect the
otherwise independent classes to describe their joint behavior without
requiring any cooperation from the classes themselves.

   ---------- Footnotes ----------

   (1) 11


File: pcl.info,  Node: 16-9,  Next: Chapter 17,  Prev: 16-8,  Up: Chapter 16

To Be Continued . . .
=====================

I've covered the basics-and a bit beyond-of generic functions, the verbs
of Common Lisp's object system.  In the next chapter I'll show you how
to define your own classes.


File: pcl.info,  Node: Chapter 17,  Next: Chapter 18,  Prev: Chapter 16,  Up: Top

17. Object Reorientation: Classes
=================================

If generic functions are the verbs of the object system, classes are the
nouns.  As I mentioned in the previous chapter, all values in a Common
Lisp program are instances of some class.  Furthermore, all classes are
organized into a single hierarchy rooted at the class T.

   The class hierarchy consists of two major families of classes,
built-in and user-defined classes.  Classes that represent the data
types you've been learning about up until now, classes such as INTEGER,
STRING, and LIST, are all built-in.  They live in their own section of
the class hierarchy, arranged into appropriate sub- and superclass
relationships, and are manipulated by the functions I've been discussing
for much of the book up until now.  You can't subclass these classes,
but, as you saw in the previous chapter, you can define methods that
specialize on them, effectively extending the behavior of those
classes.1

   But when you want to create new nouns-for instance, the classes used
in the previous chapter for representing bank accounts-you need to
define your own classes.  That's the subject of this chapter.

* Menu:

* 17-1::   DEFCLASS
* 17-2::   Slot Specifiers
* 17-3::   Object Initialization
* 17-4::   Accessor Functions
* 17-5::   WITH-SLOTS and WITH-ACCESSORS
* 17-6::   Class-Allocated Slots
* 17-7::   Slots and Inheritance
* 17-8::   Multiple Inheritance
* 17-9::   Good Object-Oriented Design


File: pcl.info,  Node: 17-1,  Next: 17-2,  Prev: Chapter 17,  Up: Chapter 17

DEFCLASS
========

You create user-defined classes with the DEFCLASS macro.  Because
behaviors are associated with a class by defining generic functions and
methods specialized on the class, DEFCLASS is responsible only for
defining the class as a data type.

   The three facets of the class as a data type are its name, its
relation to other classes, and the names of the slots that make up
instances of the class.2 The basic form of a DEFCLASS is quite simple.

   (defclass name (direct-superclass-name*) (slot-specifier*))

   As with functions and variables, you can use any symbol as the name
of a new class.3 Class names are in a separate namespace from both
functions and variables, so you can have a class, function, and variable
all with the same name.  You'll use the class name as the argument to
MAKE-INSTANCE, the function that creates new instances of user-defined
classes.

   The direct-superclass-names specify the classes of which the new
class is a subclass.  If no superclasses are listed, the new class will
directly subclass STANDARD-OBJECT. Any classes listed must be other
user-defined classes, which ensures that each new class is ultimately
descended from STANDARD-OBJECT. STANDARD-OBJECT in turn subclasses T, so
all user-defined classes are part of the single class hierarchy that
also contains all the built-in classes.

   Eliding the slot specifiers for a moment, the DEFCLASS forms of some
of the classes you used in the previous chapter might look like this:

   (defclass bank-account () ...)

   (defclass checking-account (bank-account) ...)

   (defclass savings-account (bank-account) ...)  I'll discuss in the
section "Multiple Inheritance" what it means to list more than one
direct superclass in direct-superclass-names.


File: pcl.info,  Node: 17-2,  Next: 17-3,  Prev: 17-1,  Up: Chapter 17

Slot Specifiers
===============

The bulk of a DEFCLASS form consists of the list of slot specifiers.
Each slot specifier defines a slot that will be part of each instance of
the class.  Each slot in an instance is a place that can hold a value,
which can be accessed using the SLOT-VALUE function.  SLOT-VALUE takes
an object and the name of a slot as arguments and returns the value of
the named slot in the given object.  It can be used with SETF to set the
value of a slot in an object.

   A class also inherits slot specifiers from its superclasses, so the
set of slots actually present in any object is the union of all the
slots specified in a class's DEFCLASS form and those specified in all
its superclasses.

   At the minimum, a slot specifier names the slot, in which case the
slot specifier can be just a name.  For instance, you could define a
bank-account class with two slots, customer-name and balance, like this:

   (defclass bank-account () (customer-name balance)) Each instance of
this class will contain two slots, one to hold the name of the customer
the account belongs to and another to hold the current balance.  With
this definition, you can create new bank-account objects using
MAKE-INSTANCE.

   (make-instance 'bank-account) ==> #<BANK-ACCOUNT  #x724b93ba> The
argument to MAKE-INSTANCE is the name of the class to instantiate, and
the value returned is the new object.4 The printed representation of an
object is determined by the generic function PRINT-OBJECT. In this case,
the applicable method will be one provided by the implementation,
specialized on STANDARD-OBJECT. Since not every object can be printed so
that it can be read back, the STANDARD-OBJECT print method uses the #<>
syntax, which will cause the reader to signal an error if it tries to
read it.  The rest of the representation is implementation-defined but
will typically be something like the output just shown, including the
name of the class and some distinguishing value such as the address of
the object in memory.  In Chapter 23 you'll see an example of how to
define a method on PRINT-OBJECT to make objects of a certain class be
printed in a more informative form.

   Using the definition of bank-account just given, new objects will be
created with their slots unbound.  Any attempt to get the value of an
unbound slot signals an error, so you must set a slot before you can
read it.

   (defparameter *account* (make-instance 'bank-account)) ==> *ACCOUNT*
(setf (slot-value *account* 'customer-name) "John Doe") ==> "John Doe"
(setf (slot-value *account* 'balance) 1000) ==> 1000 Now you can access
the value of the slots.

   (slot-value *account* 'customer-name) ==> "John Doe" (slot-value
*account* 'balance) ==> 1000


File: pcl.info,  Node: 17-3,  Next: 17-4,  Prev: 17-2,  Up: Chapter 17

Object Initialization
=====================

Since you can't do much with an object with unbound slots, it'd be nice
to be able to create objects with their slots already initialized.
Common Lisp provides three ways to control the initial value of slots.
The first two involve adding options to the slot specifier in the
DEFCLASS form: with the :initarg option, you can specify a name that can
then be used as a keyword parameter to MAKE-INSTANCE and whose argument
will be stored in the slot.  A second option, :initform, lets you
specify a Lisp expression that will be used to compute a value for the
slot if no :initarg argument is passed to MAKE-INSTANCE. Finally, for
complete control over the initialization, you can define a method on the
generic function INITIALIZE-INSTANCE, which is called by MAKE-INSTANCE.5

   A slot specifier that includes options such as :initarg or :initform
is written as a list starting with the name of the slot followed by the
options.  For example, if you want to modify the definition of
bank-account to allow callers of MAKE-INSTANCE to pass the customer name
and the initial balance and to provide a default value of zero dollars
for the balance, you'd write this:

   (defclass bank-account () ((customer-name :initarg :customer-name)
(balance :initarg :balance :initform 0))) Now you can create an account
and specify the slot values at the same time.

   (defparameter *account* (make-instance 'bank-account :customer-name
"John Doe" :balance 1000))

   (slot-value *account* 'customer-name) ==> "John Doe" (slot-value
*account* 'balance) ==> 1000 If you don't supply a :balance argument to
MAKE-INSTANCE, the SLOT-VALUE of balance will be computed by evaluating
the form specified with the :initform option.  But if you don't supply a
:customer-name argument, the customer-name slot will be unbound, and an
attempt to read it before you set it will signal an error.

   (slot-value (make-instance 'bank-account) 'balance) ==> 0 (slot-value
(make-instance 'bank-account) 'customer-name) ==> error If you want to
ensure that the customer name is supplied when the account is created,
you can signal an error in the initform since it will be evaluated only
if an initarg isn't supplied.  You can also use initforms that generate
a different value each time they're evaluated-the initform is evaluated
anew for each object.  To experiment with these techniques, you can
modify the customer-name slot specifier and add a new slot,
account-number, that's initialized with the value of an ever-increasing
counter.

   (defvar *account-numbers* 0)

   (defclass bank-account () ((customer-name :initarg :customer-name
:initform (error "Must supply a customer name."))  (balance :initarg
:balance :initform 0) (account-number :initform (incf
*account-numbers*)))) Most of the time the combination of :initarg and
:initform options will be sufficient to properly initialize an object.
However, while an initform can be any Lisp expression, it has no access
to the object being initialized, so it can't initialize one slot based
on the value of another.  For that you need to define a method on the
generic function INITIALIZE-INSTANCE.

   The primary method on INITIALIZE-INSTANCE specialized on
STANDARD-OBJECT takes care of initializing slots based on their :initarg
and :initform options.  Since you don't want to disturb that, the most
common way to add custom initialization code is to define an :after
method specialized on your class.6 For instance, suppose you want to add
a slot account-type that needs to be set to one of the values :gold,
:silver, or :bronze based on the account's initial balance.  You might
change your class definition to this, adding the account-type slot with
no options:

   (defclass bank-account () ((customer-name :initarg :customer-name
:initform (error "Must supply a customer name."))  (balance :initarg
:balance :initform 0) (account-number :initform (incf
*account-numbers*)) account-type)) Then you can define an :after method
on INITIALIZE-INSTANCE that sets the account-type slot based on the
value that has been stored in the balance slot.7

   (defmethod initialize-instance :after ((account bank-account) &key)
(let ((balance (slot-value account 'balance))) (setf (slot-value account
'account-type) (cond ((>= balance 100000) :gold) ((>= balance 50000)
:silver) (t :bronze))))) The &key in the parameter list is required to
keep the method's parameter list congruent with the generic
function's-the parameter list specified for the INITIALIZE-INSTANCE
generic function includes &key in order to allow individual methods to
supply their own keyword parameters but doesn't require any particular
ones.  Thus, every method must specify &key even if it doesn't specify
any &key parameters.

   On the other hand, if an INITIALIZE-INSTANCE method specialized on a
particular class does specify a &key parameter, that parameter becomes a
legal parameter to MAKE-INSTANCE when creating an instance of that
class.  For instance, if the bank sometimes pays a percentage of the
initial balance as a bonus when an account is opened, you could
implement that using a method on INITIALIZE-INSTANCE that takes a
keyword argument to specify the percentage of the bonus like this:

   (defmethod initialize-instance :after ((account bank-account) &key
opening-bonus-percentage) (when opening-bonus-percentage (incf
(slot-value account 'balance) (* (slot-value account 'balance) (/
opening-bonus-percentage 100))))) By defining this INITIALIZE-INSTANCE
method, you make :opening-bonus-percentage a legal argument to
MAKE-INSTANCE when creating a bank-account object.

   CL-USER> (defparameter *acct* (make-instance 'bank-account
:customer-name "Sally Sue" :balance 1000 :opening-bonus-percentage 5))
*ACCT* CL-USER> (slot-value *acct* 'balance) 1050


File: pcl.info,  Node: 17-4,  Next: 17-5,  Prev: 17-3,  Up: Chapter 17

Accessor Functions
==================

Between MAKE-INSTANCE and SLOT-VALUE, you have all the tools you need
for creating and manipulating instances of your classes.  Everything
else you might want to do can be implemented in terms of those two
functions.  However, as anyone familiar with the principles of good
object-oriented programming practices knows, directly accessing the
slots (or fields or member variables) of an object can lead to fragile
code.  The problem is that directly accessing slots ties your code too
tightly to the concrete structure of your class.  For example, suppose
you decide to change the definition of bank-account so that, instead of
storing the current balance as a number, you store a list of
time-stamped withdrawals and deposits.  Code that directly accesses the
balance slot will likely break if you change the class definition to
remove the slot or to store the new list in the old slot.  On the other
hand, if you define a function, balance, that accesses the slot, you can
redefine it later to preserve its behavior even if the internal
representation changes.  And code that uses such a function will
continue to work without modification.

   Another advantage to using accessor functions rather than direct
access to slots via SLOT-VALUE is that they let you limit the ways
outside code can modify a slot.8 It may be fine for users of the
bank-account class to get the current balance, but you may want all
modifications to the balance to go through other functions you'll
provide, such as deposit and withdraw.  If clients know they're supposed
to manipulate objects only through the published functional API, you can
provide a balance function but not make it SETFable if you want the
balance to be read-only.

   Finally, using accessor functions makes your code tidier since it
helps you avoid lots of uses of the rather verbose SLOT-VALUE function.

   It's trivial to define a function that reads the value of the balance
slot.

   (defun balance (account) (slot-value account 'balance)) However, if
you know you're going to define subclasses of bank-account, it might be
a good idea to define balance as a generic function.  That way, you can
provide different methods on balance for those subclasses or extend its
definition with auxiliary methods.  So you might write this instead:

   (defgeneric balance (account))

   (defmethod balance ((account bank-account)) (slot-value account
'balance)) As I just discussed, you don't want callers to be able to
directly set the balance, but for other slots, such as customer-name,
you may also want to provide a function to set them.  The cleanest way
to define such a function is as a SETF function.

   A SETF function is a way to extend SETF, defining a new kind of place
that it knows how to set.  The name of a SETF function is a two-item
list whose first element is the symbol setf and whose second element is
a symbol, typically the name of a function used to access the place the
SETF function will set.  A SETF function can take any number of
arguments, but the first argument is always the value to be assigned to
the place.9 You could, for instance, define a SETF function to set the
customer-name slot in a bank-account like this:

   (defun (setf customer-name) (name account) (setf (slot-value account
'customer-name) name)) After evaluating that definition, an expression
like the following one:

   (setf (customer-name my-account) "Sally Sue") will be compiled as a
call to the SETF function you just defined with "Sally Sue" as the first
argument and the value of my-account as the second argument.

   Of course, as with reader functions, you'll probably want your SETF
function to be generic, so you'd actually define it like this:

   (defgeneric (setf customer-name) (value account))

   (defmethod (setf customer-name) (value (account bank-account)) (setf
(slot-value account 'customer-name) value)) And of course you'll also
want to define a reader function for customer-name.

   (defgeneric customer-name (account))

   (defmethod customer-name ((account bank-account)) (slot-value account
'customer-name)) This allows you to write the following:

   (setf (customer-name *account*) "Sally Sue") ==> "Sally Sue"

   (customer-name *account*) ==> "Sally Sue" There's nothing hard about
writing these accessor functions, but it wouldn't be in keeping with The
Lisp Way to have to write them all by hand.  Thus, DEFCLASS supports
three slot options that allow you to automatically create reader and
writer functions for a specific slot.

   The :reader option specifies a name to be used as the name of a
generic function that accepts an object as its single argument.  When
the DEFCLASS is evaluated, the generic function is created, if it
doesn't already exist.  Then a method specializing its single argument
on the new class and returning the value of the slot is added to the
generic function.  The name can be anything, but it's typical to name it
the same as the slot itself.  Thus, instead of explicitly writing the
balance generic function and method as shown previously, you could
change the slot specifier for the balance slot in the definition of
bank-account to this:

   (balance :initarg :balance :initform 0 :reader balance) The :writer
option is used to create a generic function and method for setting the
value of a slot.  The function and method created follow the
requirements for a SETF function, taking the new value as the first
argument and returning it as the result, so you can define a SETF
function by providing a name such as (setf customer-name).  For
instance, you could provide reader and writer methods for customer-name
equivalent to the ones you just wrote by changing the slot specifier to
this:

   (customer-name :initarg :customer-name :initform (error "Must supply
a customer name.")  :reader customer-name :writer (setf customer-name))
Since it's quite common to want both reader and writer functions,
DEFCLASS also provides an option, :accessor, that creates both a reader
function and the corresponding SETF function.  So instead of the slot
specifier just shown, you'd typically write this:

   (customer-name :initarg :customer-name :initform (error "Must supply
a customer name.")  :accessor customer-name) Finally, one last slot
option you should know about is the :documentation option, which you can
use to provide a string that documents the purpose of the slot.  Putting
it all together and adding a reader method for the account-number and
account-type slots, the DEFCLASS form for the bank-account class would
look like this:

   (defclass bank-account () ((customer-name :initarg :customer-name
:initform (error "Must supply a customer name.")  :accessor
customer-name :documentation "Customer's name") (balance :initarg
:balance :initform 0 :reader balance :documentation "Current account
balance") (account-number :initform (incf *account-numbers*) :reader
account-number :documentation "Account number, unique within a bank.")
(account-type :reader account-type :documentation "Type of account, one
of :gold, :silver, or :bronze.")))


File: pcl.info,  Node: 17-5,  Next: 17-6,  Prev: 17-4,  Up: Chapter 17

WITH-SLOTS and WITH-ACCESSORS
=============================

While using accessor functions will make your code easier to maintain,
they can still be a bit verbose.  And there will be times, when writing
methods that implement the low-level behaviors of a class, that you may
specifically want to access slots directly to set a slot that has no
writer function or to get at the slot value without causing any
auxiliary methods defined on the reader function to run.

   This is what SLOT-VALUE is for; however, it's still quite verbose.
To make matters worse, a function or method that accesses the same slot
several times can become clogged with calls to accessor functions and
SLOT-VALUE. For example, even a fairly simple method such as the
following, which assesses a penalty on a bank-account if its balance
falls below a certain minimum, is cluttered with calls to balance and
SLOT-VALUE:

   (defmethod assess-low-balance-penalty ((account bank-account)) (when
(< (balance account) *minimum-balance*) (decf (slot-value account
'balance) (* (balance account) .01)))) And if you decide you want to
directly access the slot value in order to avoid running auxiliary
methods, it gets even more cluttered.

   (defmethod assess-low-balance-penalty ((account bank-account)) (when
(< (slot-value account 'balance) *minimum-balance*) (decf (slot-value
account 'balance) (* (slot-value account 'balance) .01)))) Two standard
macros, WITH-SLOTS and WITH-ACCESSORS, can help tidy up this clutter.
Both macros create a block of code in which simple variable names can be
used to refer to slots on a particular object.  WITH-SLOTS provides
direct access to the slots, as if by SLOT-VALUE, while WITH-ACCESSORS
provides a shorthand for accessor methods.

   The basic form of WITH-SLOTS is as follows:

   (with-slots (slot*) instance-form body-form*) Each element of slots
can be either the name of a slot, which is also used as a variable name,
or a two-item list where the first item is a name to use as a variable
and the second is the name of the slot.  The instance-form is evaluated
once to produce the object whose slots will be accessed.  Within the
body, each occurrence of one of the variable names is translated to a
call to SLOT-VALUE with the object and the appropriate slot name as
arguments.10 Thus, you can write assess-low-balance-penalty like this:

   (defmethod assess-low-balance-penalty ((account bank-account))
(with-slots (balance) account (when (< balance *minimum-balance*) (decf
balance (* balance .01))))) or, using the two-item list form, like this:

   (defmethod assess-low-balance-penalty ((account bank-account))
(with-slots ((bal balance)) account (when (< bal *minimum-balance*)
(decf bal (* bal .01))))) If you had defined balance with an :accessor
rather than just a :reader, then you could also use WITH-ACCESSORS. The
form of WITH-ACCESSORS is the same as WITH-SLOTS except each element of
the slot list is a two-item list containing a variable name and the name
of an accessor function.  Within the body of WITH-ACCESSORS, a reference
to one of the variables is equivalent to a call to the corresponding
accessor function.  If the accessor function is SETFable, then so is the
variable.

   (defmethod assess-low-balance-penalty ((account bank-account))
(with-accessors ((balance balance)) account (when (< balance
*minimum-balance*) (decf balance (* balance .01))))) The first balance
is the name of the variable, and the second is the name of the accessor
function; they don't have to be the same.  You could, for instance,
write a method to merge two accounts using two calls to WITH-ACCESSORS,
one for each account.

   (defmethod merge-accounts ((account1 bank-account) (account2
bank-account)) (with-accessors ((balance1 balance)) account1
(with-accessors ((balance2 balance)) account2 (incf balance1 balance2)
(setf balance2 0)))) The choice of whether to use WITH-SLOTS versus
WITH-ACCESSORS is the same as the choice between SLOT-VALUE and an
accessor function: low-level code that provides the basic functionality
of a class may use SLOT-VALUE or WITH-SLOTS to directly manipulate slots
in ways not supported by accessor functions or to explicitly avoid the
effects of auxiliary methods that may have been defined on the accessor
functions.  But you should generally use accessor functions or
WITH-ACCESSORS unless you have a specific reason not to.


File: pcl.info,  Node: 17-6,  Next: 17-7,  Prev: 17-5,  Up: Chapter 17

Class-Allocated Slots
=====================

The last slot option you need to know about is :allocation.  The value
of :allocation can be either :instance or :class and defaults to
:instance if not specified.  When a slot has :class allocation, the slot
has only a single value, which is stored in the class and shared by all
instances.

   However, :class slots are accessed the same as :instance
slots-they're accessed with SLOT-VALUE or an accessor function, which
means you can access the slot value only through an instance of the
class even though it isn't actually stored in the instance.  The
:initform and :initarg options have essentially the same effect except
the initform is evaluated once when the class is defined rather than
each time an instance is created.  On the other hand, passing an initarg
to MAKE-INSTANCE will set the value, affecting all instances of the
class.

   Because you can't get at a class-allocated slot without an instance
of the class, class-allocated slots aren't really equivalent to static
or class fields in languages such as Java, C++, and Python.11 Rather,
class-allocated slots are used primarily to save space; if you're going
to create many instances of a class and all instances are going to have
a reference to the same object-say, a pool of shared resources-you can
save the cost of each instance having its own reference by making the
slot class-allocated.


File: pcl.info,  Node: 17-7,  Next: 17-8,  Prev: 17-6,  Up: Chapter 17

Slots and Inheritance
=====================

As I discussed in the previous chapter, classes inherit behavior from
their superclasses thanks to the generic function machinery-a method
specialized on class A is applicable not only to direct instances of A
but also to instances of A's subclasses.  Classes also inherit slots
from their superclasses, but the mechanism is slightly different.

   In Common Lisp a given object can have only one slot with a
particular name.  However, it's possible that more than one class in the
inheritance hierarchy of a given class will specify a slot with a
particular name.  This can happen either because a subclass includes a
slot specifier with the same name as a slot specified in a superclass or
because multiple superclasses specify slots with the same name.

   Common Lisp resolves these situations by merging all the specifiers
with the same name from the new class and all its superclasses to create
a single specifier for each unique slot name.  When merging specifiers,
different slot options are treated differently.  For instance, since a
slot can have only a single default value, if multiple classes specify
an :initform, the new class uses the one from the most specific class.
This allows a subclass to specify a different default value than the one
it would otherwise inherit.

   On the other hand, :initargs needn't be exclusive-each :initarg
option in a slot specifier creates a keyword parameter that can be used
to initialize the slot; multiple parameters don't create a conflict, so
the new slot specifier contains all the :initargs.  Callers of
MAKE-INSTANCE can use any of the :initargs to initialize the slot.  If a
caller passes multiple keyword arguments that initialize the same slot,
then the leftmost argument in the call to MAKE-INSTANCE is used.

   Inherited :reader, :writer, and :accessor options aren't included in
the merged slot specifier since the methods created by the superclass's
DEFCLASS will already apply to the new class.  The new class can,
however, create its own accessor functions by supplying its own :reader,
:writer, or :accessor options.

   Finally, the :allocation option is, like :initform, determined by the
most specific class that specifies the slot.  Thus, it's possible for
all instances of one class to share a :class slot while instances of a
subclass may each have their own :instance slot of the same name.  And a
sub-subclass may then redefine it back to :class slot, so all instances
of that class will again share a single slot.  In the latter case, the
slot shared by instances of the sub-subclass is different than the slot
shared by the original superclass.

   For instance, suppose you have these classes:

   (defclass foo () ((a :initarg :a :initform "A" :accessor a) (b
:initarg :b :initform "B" :accessor b)))

   (defclass bar (foo) ((a :initform (error "Must supply a value for
a")) (b :initarg :the-b :accessor the-b :allocation :class))) When
instantiating the class bar, you can use the inherited initarg, :a, to
specify a value for the slot a and, in fact, must do so to avoid an
error, since the :initform supplied by bar supersedes the one inherited
from foo.  To initialize the b slot, you can use either the inherited
initarg :b or the new initarg :the-b.  However, because of the
:allocation option on the b slot in bar, the value specified will be
stored in the slot shared by all instances of bar.  That same slot can
be accessed either with the method on the generic function b that
specializes on foo or with the new method on the generic function the-b
that specializes directly on bar.  To access the a slot on either a foo
or a bar, you'll continue to use the generic function a.

   Usually merging slot definitions works quite nicely.  However, it's
important to be aware when using multiple inheritance that two unrelated
slots that happen to have the same name can be merged into a single slot
in the new class.  Thus, methods specialized on different classes could
end up manipulating the same slot when applied to a class that extends
those classes.  This isn't much of a problem in practice since, as
you'll see in Chapter 21, you can use the package system to avoid
collisions between names in independently developed pieces of code.


File: pcl.info,  Node: 17-8,  Next: 17-9,  Prev: 17-7,  Up: Chapter 17

Multiple Inheritance
====================

All the classes you've seen so far have had only a single direct
superclass.  Common Lisp also supports multiple inheritance-a class can
have multiple direct superclasses, inheriting applicable methods and
slot specifiers from all of them.

   Multiple inheritance doesn't dramatically change any of the
mechanisms of inheritance I've discussed so far-every user-defined class
already has multiple superclasses since they all extend STANDARD-OBJECT,
which extends T, and so have at least two superclasses.  The wrinkle
that multiple inheritance adds is that a class can have more than one
direct superclass.  This complicates the notion of class specificity
that's used both when building the effective methods for a generic
function and when merging inherited slot specifiers.

   That is, if classes could have only a single direct superclass,
ordering classes by specificity would be trivial-a class and all its
superclasses could be ordered in a straight line starting from the class
itself, followed by its single direct superclass, followed by its direct
superclass, all the way up to T. But when a class has multiple direct
superclasses, those superclasses are typically not related to each
other-indeed, if one was a subclass of another, you wouldn't need to
subclass both directly.  In that case, the rule that subclasses are more
specific than their superclasses isn't enough to order all the
superclasses.  So Common Lisp uses a second rule that sorts unrelated
superclasses according to the order they're listed in the DEFCLASS's
direct superclass list-classes earlier in the list are considered more
specific than classes later in the list.  This rule is admittedly
somewhat arbitrary but does allow every class to have a linear class
precedence list, which can be used to determine which superclasses
should be considered more specific than others.  Note, however, there's
no global ordering of classes-each class has its own class precedence
list, and the same classes can appear in different orders in different
classes' class precedence lists.

   To see how this works, let's add a class to the banking app:
money-market-account.  A money market account combines the
characteristics of a checking account and a savings account: a customer
can write checks against it, but it also earns interest.  You might
define it like this:

   (defclass money-market-account (checking-account savings-account) ())
The class precedence list for money-market-account will be as follows:

   (money-market-account checking-account savings-account bank-account
standard-object t) Note how this list satisfies both rules: every class
appears before all its superclasses, and checking-account and
savings-account appear in the order specified in DEFCLASS.

   This class defines no slots of its own but will inherit slots from
both of its direct superclasses, including the slots they inherit from
their superclasses.  Likewise, any method that's applicable to any class
in the class precedence list will be applicable to a
money-market-account object.  Because all slot specifiers for the same
slot are merged, it doesn't matter that money-market-account inherits
the same slot specifiers from bank-account twice.  12

   Multiple inheritance is easiest to understand when the different
superclasses provide completely independent slots and behaviors.  For
instance, money-market-account will inherit slots and behaviors for
dealing with checks from checking-account and slots and behaviors for
computing interest from savings-account.  You don't have to worry about
the class precedence list for methods and slots inherited from only one
superclass or another.

   However, it's also possible to inherit different methods for the same
generic function from different superclasses.  In that case, the class
precedence list does come into play.  For instance, suppose the banking
application defined a generic function print-statement used to generate
monthly statements.  Presumably there would already be methods for
print-statement specialized on both checking-account and
savings-account.  Both of these methods will be applicable to instances
of money-market-account, but the one specialized on checking-account
will be considered more specific than the one on savings-account because
checking-account precedes savings-account in money-market-account's
class precedence list.

   Assuming the inherited methods are all primary methods and you
haven't defined any other methods, the method specialized on
checking-account will be used if you invoke print-statement on
money-market-account.  However, that won't necessarily give you the
behavior you want since you probably want a money market account's
statement to contain elements of both a checking account and a savings
account statement.

   You can modify the behavior of print-statement for
money-market-accounts in a couple ways.  One straightforward way is to
define a new primary method specialized on money-market-account.  This
gives you the most control over the new behavior but will probably
require more new code than some other options I'll discuss in a moment.
The problem is that while you can use CALL-NEXT-METHOD to call "up" to
the next most specific method, namely, the one specialized on
checking-account, there's no way to invoke a particular less-specific
method, such as the one specialized on savings-account.  Thus, if you
want to be able to reuse the code that prints the savings-account part
of the statement, you'll need to break that code into a separate
function, which you can then call directly from both the
money-market-account and savings-account print-statement methods.

   Another possibility is to write the primary methods of all three
classes to call CALL-NEXT-METHOD. Then the method specialized on
money-market-account will use CALL-NEXT-METHOD to invoke the method
specialized on checking-account.  When that method calls
CALL-NEXT-METHOD, it will result in running the savings-account method
since it will be the next most specific method according to
money-market-account's class precedence list.

   Of course, if you're going to rely on a coding convention-that every
method calls CALL-NEXT-METHOD-to ensure all the applicable methods run
at some point, you should think about using auxiliary methods instead.
In this case, instead of defining primary methods on print-statement for
checking-account and savings-account, you can define those methods as
:after methods, defining a single primary method on bank-account.  Then,
print-statement, called on a money-market-account, will print a basic
account statement, output by the primary method specialized on
bank-account, followed by details output by the :after methods
specialized on savings-account and checking-account.  And if you want to
add details specific to money-market-accounts, you can define an :after
method specialized on money-market-account, which will run last of all.

   The advantage of using auxiliary methods is that it makes it quite
clear which methods are primarily responsible for implementing the
generic function and which ones are only contributing additional bits of
functionality.  The disadvantage is that you don't get fine-grained
control over the order in which the auxiliary methods run-if you wanted
the checking-account part of the statement to print before the
savings-account part, you'd have to change the order in which the
money-market-account subclasses those classes.  But that's a fairly
dramatic change that could affect other methods and inherited slots.  In
general, if you find yourself twiddling the order of the direct
superclass list as a way of fine-tuning the behavior of specific
methods, you probably need to step back and rethink your approach.

   On the other hand, if you don't care exactly what the order is but
want it to be consistent across several generic functions, then using
auxiliary methods may be just the thing.  For example, if in addition to
print-statement you have a print-detailed-statement generic function,
you can implement both functions using :after methods on the various
subclasses of bank-account, and the order of the parts of both a regular
and a detailed statement will be the same.


File: pcl.info,  Node: 17-9,  Next: Chapter 18,  Prev: 17-8,  Up: Chapter 17

Good Object-Oriented Design
===========================

That's about it for the main features of Common Lisp's object system.
If you have lots of experience with object-oriented programming, you can
probably see how Common Lisp's features can be used to implement good
object-oriented designs.  However, if you have less experience with
object orientation, you may need to spend some time absorbing the
object-oriented way of thinking.  Unfortunately, that's a fairly large
topic and beyond the scope of this book.  Or, as the man page for Perl's
object system puts it, "Now you need just to go off and buy a book about
object-oriented design methodology and bang your forehead with it for
the next six months or so."  Or you can wait for some of the practical
chapters, later in this book, where you'll see several examples of how
these features are used in practice.  For now, however, you're ready to
take a break from all this theory of object orientation and turn to the
rather different topic of how to make good use of Common Lisp's
powerful, but sometimes cryptic, FORMAT function.


File: pcl.info,  Node: Chapter 18,  Next: Chapter 19,  Prev: Chapter 17,  Up: Top

18. A Few FORMAT Recipes
========================

Common Lisp's FORMAT function is-along with the extended LOOP macro-one
of the two Common Lisp features that inspires a strong emotional
response in a lot of Common Lisp users.  Some love it; others hate it.1

   FORMAT's fans love it for its great power and concision, while its
detractors hate it because of the potential for misuse and its opacity.
Complex FORMAT control strings sometimes bear a suspicious resemblance
to line noise, but FORMAT remains popular with Common Lispers who like
to be able to generate little bits of human-readable output without
having to clutter their code with lots of output-generating code.  While
FORMAT's control strings can be cryptic, at least a single FORMAT
expression doesn't clutter things up too badly.  For instance, suppose
you want to print the values in a list delimited with commas.  You could
write this:

   (loop for cons on list do (format t "~a" (car cons)) when (cdr cons)
do (format t ", ")) That's not too bad, but anyone reading this code has
to mentally parse it just to figure out that all it's doing is printing
the contents of list to standard output.  On the other hand, you can
tell at a glance that the following expression is printing list, in some
form, to standard output:

   (format t "~{~a~^, ~}" list) If you care exactly what form the output
will take, then you'll have to examine the control string, but if all
you want is a first-order approximation of what this line of code is
doing, that's immediately available.

   At any rate, you should have at least a reading knowledge of FORMAT,
and it's worth getting a sense of what it can do before you affiliate
yourself with the pro- or anti-FORMAT camp.  It's also important to
understand at least the basics of FORMAT because other standard
functions, such as the condition-signaling functions discussed in the
next chapter, use FORMAT-style control strings to generate output.

   To further complicate matters, FORMAT supports three quite different
kinds of formatting: printing tables of data, pretty-printing
s-expressions, and generating human-readable messages with interpolated
values.  Printing tables of data as text is a bit pass these days;
it's one of those reminders that Lisp is nearly as old as FORTRAN. In
fact, several of the directives you can use to print floating-point
values in fixed-width fields were based quite directly on FORTRAN edit
descriptors, which are used in FORTRAN to read and print columns of data
arranged in fixed-width fields.  However, using Common Lisp as a FORTRAN
replacement is beyond the scope of this book, so I won't discuss those
aspects of FORMAT.

   Pretty-printing is likewise beyond the scope of this book-not because
it's pass but just because it's too big a topic.  Briefly, the Common
Lisp pretty printer is a customizable system for printing
block-structured data such as-but not limited to-s-expressions while
varying indentation and dynamically adding line breaks as needed.  It's
a great thing when you need it, but it's not often needed in day-to-day
programming.2

   Instead, I'll focus on the parts of FORMAT you can use to generate
human-readable strings with interpolated values.  Even limiting the
scope in that way, there's still a fair bit to cover.  You shouldn't
feel obliged to remember every detail described in this chapter.  You
can get quite far with just a few FORMAT idioms.  I'll describe the most
important features of FORMAT first; it's up to you how much of a FORMAT
wizard you want to become.

* Menu:

* 18-1::         The FORMAT Function
* 18-2::         FORMAT Directives
* 18-3::         Basic Formatting
* 18-4::         Character and Integer Directives
* 18-5::         Floating-Point Directives
* 18-6::         English-Language Directives
* 18-7::         Conditional Formatting
* 18-8::         Iteration
* 18-9::         Hop, Skip, Jump
* 18-10::        And More . . .


File: pcl.info,  Node: 18-1,  Next: 18-2,  Prev: Chapter 18,  Up: Chapter 18

The FORMAT Function
===================

As you've seen in previous chapters, the FORMAT function takes two
required arguments: a destination for its output and a control string
that contains literal text and embedded directives.  Any additional
arguments provide the values used by the directives in the control
string that interpolate values into the output.  I'll refer to these
arguments as format arguments.

   The first argument to FORMAT, the destination for the output, can be
T, NIL, a stream, or a string with a fill pointer.  T is shorthand for
the stream *STANDARD-OUTPUT*, while NIL causes FORMAT to generate its
output to a string, which it then returns.3 If the destination is a
stream, the output is written to the stream.  And if the destination is
a string with a fill pointer, the formatted output is added to the end
of the string and the fill pointer is adjusted appropriately.  Except
when the destination is NIL and it returns a string, FORMAT returns NIL.

   The second argument, the control string, is, in essence, a program in
the FORMAT language.  The FORMAT language isn't Lispy at all-its basic
syntax is based on characters, not s-expressions, and it's optimized for
compactness rather than easy comprehension.  This is why a complex
FORMAT control string can end up looking like line noise.

   Most of FORMAT's directives simply interpolate an argument into the
output in one form or another.  Some directives, such as ~%, which
causes FORMAT to emit a newline, don't consume any arguments.  And
others, as you'll see, can consume more than one argument.  One
directive even allows you to jump around in the list of arguments in
order to process the same argument more than once or to skip certain
arguments in certain situations.  But before I discuss specific
directives, let's look at the general syntax of a directive.


File: pcl.info,  Node: 18-2,  Next: 18-3,  Prev: 18-1,  Up: Chapter 18

FORMAT Directives
=================

All directives start with a tilde (~) and end with a single character
that identifies the directive.  You can write the character in either
upper- or lowercase.  Some directives take prefix parameters, which are
written immediately following the tilde, separated by commas, and used
to control things such as how many digits to print after the decimal
point when printing a floating-point number.  For example, the ~$
directive, one of the directives used to print floating-point values, by
default prints two digits following the decimal point.

   CL-USER> (format t "~$" pi) 3.14 NIL However, with a prefix
parameter, you can specify that it should print its argument to, say,
five decimal places like this:

   CL-USER> (format t "~5$" pi) 3.14159 NIL The values of prefix
parameters are either numbers, written in decimal, or characters,
written as a single quote followed by the desired character.  The value
of a prefix parameter can also be derived from the format arguments in
two ways: A prefix parameter of v causes FORMAT to consume one format
argument and use its value for the prefix parameter.  And a prefix
parameter of # will be evaluated as the number of remaining format
arguments.  For example:

   CL-USER> (format t "~v$" 3 pi) 3.142 NIL CL-USER> (format t "~#$" pi)
3.1 NIL I'll give some more realistic examples of how you can use the #
argument in the section "Conditional Formatting."

   You can also omit prefix parameters altogether.  However, if you want
to specify one parameter but not the ones before it, you must include a
comma for each unspecified parameter.  For instance, the ~F directive,
another directive for printing floating-point values, also takes a
parameter to control the number of decimal places to print, but it's the
second parameter rather than the first.  If you want to use ~F to print
a number to five decimal places, you can write this:

   CL-USER> (format t "~,5f" pi) 3.14159 NIL You can also modify the
behavior of some directives with colon and at-sign modifiers, which are
placed after any prefix parameters and before the directive's
identifying character.  These modifiers change the behavior of the
directive in small ways.  For instance, with a colon modifier, the ~D
directive used to output integers in decimal emits the number with
commas separating every three digits, while the at-sign modifier causes
~D to include a plus sign when the number is positive.

   CL-USER> (format t "~d" 1000000) 1000000 NIL CL-USER> (format t "~:d"
1000000) 1,000,000 NIL CL-USER> (format t "~@d" 1000000) +1000000 NIL
When it makes sense, you can combine the colon and at-sign modifiers to
get both modifications.

   CL-USER> (format t "~:@d" 1000000) +1,000,000 NIL In directives where
the two modified behaviors can't be meaningfully combined, using both
modifiers is either undefined or given a third meaning.


File: pcl.info,  Node: 18-3,  Next: 18-4,  Prev: 18-2,  Up: Chapter 18

Basic Formatting
================

Now you're ready to look at specific directives.  I'll start with
several of the most commonly used directives, including some you've seen
in previous chapters.

   The most general-purpose directive is ~A, which consumes one format
argument of any type and outputs it in aesthetic (human-readable) form.
For example, strings are output without quotation marks or escape
characters, and numbers are output in a natural way for the type of
number.  If you just want to emit a value for human consumption, this
directive is your best bet.

   (format nil "The value is: ~a" 10) ==> "The value is: 10" (format nil
"The value is: ~a" "foo") ==> "The value is: foo" (format nil "The value
is: ~a" (list 1 2 3)) ==> "The value is: (1 2 3)" A closely related
directive, ~S, likewise consumes one format argument of any type and
outputs it.  However, ~S tries to generate output that can be read back
in with READ. Thus, strings will be enclosed in quotation marks, symbols
will be package-qualified when necessary, and so on.  Objects that don't
have a READable representation are printed with the unreadable object
syntax, #<>.  With a colon modifier, both the ~A and ~S directives emit
NIL as () rather than NIL. Both the ~A and ~S directives also take up to
four prefix parameters, which can be used to control whether padding is
added after (or before with the at-sign modifier) the value, but those
parameters are only really useful for generating tabular data.

   The other two most frequently used directives are ~%, which emits a
newline, and ~&, which emits a fresh line.  The difference between the
two is that ~% always emits a newline, while ~& emits one only if it's
not already at the beginning of a line.  This is handy when writing
loosely coupled functions that each generate a piece of output and that
need to be combined in different ways.  For instance, if one function
generates output that ends with a newline (~%) and another function
generates some output that starts with a fresh line (~&), you don't have
to worry about getting an extra blank line if you call them one after
the other.  Both of these directives can take a single prefix parameter
that specifies the number of newlines to emit.  The ~% directive will
simply emit that many newline characters, while the ~& directive will
emit either n - 1 or n newlines, depending on whether it starts at the
beginning of a line.

   Less frequently used is the related ~~ directive, which causes FORMAT
to emit a literal tilde.  Like the ~% and ~& directives, it can be
parameterized with a number that controls how many tildes to emit.


File: pcl.info,  Node: 18-4,  Next: 18-5,  Prev: 18-3,  Up: Chapter 18

Character and Integer Directives
================================

In addition to the general-purpose directives, ~A and ~S, FORMAT
supports several directives that can be used to emit values of specific
types in particular ways.  One of the simplest of these is the ~C
directive, which is used to emit characters.  It takes no prefix
arguments but can be modified with the colon and at-sign modifiers.
Unmodified, its behavior is no different from ~A except that it works
only with characters.  The modified versions are more useful.  With a
colon modifier, ~:C outputs nonprinting characters such as space, tab,
and newline by name.  This is useful if you want to emit a message to
the user about some character.  For instance, the following:

   (format t "Syntax error.  Unexpected character: ~:c" char) can emit
messages like this:

   Syntax error.  Unexpected character: a but also like the following:

   Syntax error.  Unexpected character: Space With the at-sign modifier,
~@C will emit the character in Lisp's literal character syntax.

   CL-USER> (format t "~#\a NIL With both the colon and at-sign
modifiers, the ~C directive can print extra information about how to
enter the character at the keyboard if it requires special key
combinations.  For instance, on the Macintosh, in certain applications
you can enter a null character (character code 0 in ASCII or in any
ASCII superset such as ISO-8859-1 or Unicode) by pressing the Control
key and typing .  In OpenMCL, if you print the null character with the
~:C directive, it tells you this:

   (format nil "~:However, not all Lisps implement this aspect of the ~C
directive.  And even if they do, it may or may not be accurate-for
instance, if you're running OpenMCL in SLIME, the C- key chord is
intercepted by Emacs, invoking set-mark-command.4

   Format directives dedicated to emitting numbers are another important
category.  While you can use the ~A and ~S directives to emit numbers,
if you want fine control over how they're printed, you need to use one
of the number-specific directives.  The numeric directives can be
divided into two subcategories: directives for formatting integer values
and directives for formatting floating-point values.

   Five closely related directives format integer values: ~D, ~X, ~O,
~B, and ~R. The most frequently used is the ~D directive, which outputs
integers in base 10.

   (format nil "~d" 1000000) ==> "1000000" As I mentioned previously,
with a colon modifier it adds commas.

   (format nil "~:d" 1000000) ==> "1,000,000" And with an at-sign
modifier, it always prints a sign.

   (format nil "~@d" 1000000) ==> "+1000000" And the two modifiers can
be combined.

   (format nil "~:@d" 1000000) ==> "+1,000,000" The first prefix
parameter can specify a minimum width for the output, and the second
parameter can specify a padding character to use.  The default padding
character is space, and padding is always inserted before the number
itself.

   (format nil "~12d" 1000000) ==> " 1000000" (format nil "~12,'0d"
1000000) ==> "000001000000" These parameters are handy for formatting
things such as dates in a fixed-width format.

   (format nil "~4,'0d-~2,'0d-~2,'0d" 2005 6 10) ==> "2005-06-10" The
third and fourth parameters are used in conjunction with the colon
modifier: the third parameter specifies the character to use as the
separator between groups and digits, and the fourth parameter specifies
the number of digits per group.  These parameters default to a comma and
the number 3.  Thus, you can use the directive ~:D without parameters to
output large integers in standard format for the United States but can
change the comma to a period and the grouping from 3 to 4 with ~,,'.,4D.

   (format nil "~:d" 100000000) ==> "100,000,000" (format nil
"~,,'.,4:d" 100000000) ==> "1.0000.0000" Note that you must use commas
to hold the places of the unspecified width and padding character
parameters, allowing them to keep their default values.

   The ~X, ~O, and ~B directives work just like the ~D directive except
they emit numbers in hexadecimal (base 16), octal (base 8), and binary
(base 2).

   (format nil "~x" 1000000) ==> "f4240" (format nil "~o" 1000000) ==>
"3641100" (format nil "~b" 1000000) ==> "11110100001001000000" Finally,
the ~R directive is the general radix directive.  Its first parameter is
a number between 2 and 36 (inclusive) that indicates what base to use.
The remaining parameters are the same as the four parameters accepted by
the ~D, ~X, ~O, and ~B directives, and the colon and at-sign modifiers
modify its behavior in the same way.  The ~R directive also has some
special behavior when used with no prefix parameters, which I'll discuss
in the section "English-Language Directives."


File: pcl.info,  Node: 18-5,  Next: 18-6,  Prev: 18-4,  Up: Chapter 18

Floating-Point Directives
=========================

Four directives format floating-point values: ~F, ~E, ~G, and ~$.  The
first three of these are the directives based on FORTRAN's edit
descriptors.  I'll skip most of the details of those directives since
they mostly have to do with formatting floating-point values for use in
tabular form.  However, you can use the ~F, ~E, and ~$ directives to
interpolate floating-point values into text.  The ~G, or general,
floating-point directive, on the other hand, combines aspects of the ~F
and ~E directives in a way that only really makes sense for generating
tabular output.

   The ~F directive emits its argument, which should be a number,5 in
decimal format, possibly controlling the number of digits after the
decimal point.  The ~F directive is, however, allowed to use
computerized scientific notation if the number is sufficiently large or
small.  The ~E directive, on the other hand, always emits numbers in
computerized scientific notation.  Both of these directives take a
number of prefix parameters, but you need to worry only about the
second, which controls the number of digits to print after the decimal
point.

   (format nil "~f" pi) ==> "3.141592653589793d0" (format nil "~,4f" pi)
==> "3.1416" (format nil "~e" pi) ==> "3.141592653589793d+0" (format nil
"~,4e" pi) ==> "3.1416d+0" The ~$, or monetary, directive is similar to
~F but a bit simpler.  As its name suggests, it's intended for emitting
monetary units.  With no parameters, it's basically equivalent to ~,2F.
To modify the number of digits printed after the decimal point, you use
the first parameter, while the second parameter controls the minimum
number of digits to print before the decimal point.

   (format nil "~$" pi) ==> "3.14" (format nil "~2,4$" pi) ==> "0003.14"
All three directives, ~F, ~E, and ~$, can be made to always print a
sign, plus or minus, with the at-sign modifier.6


File: pcl.info,  Node: 18-6,  Next: 18-7,  Prev: 18-5,  Up: Chapter 18

English-Language Directives
===========================

Some of the handiest FORMAT directives for generating human-readable
messages are the ones for emitting English text.  These directives allow
you to emit numbers as English words, to emit plural markers based on
the value of a format argument, and to apply case conversions to
sections of FORMAT's output.

   The ~R directive, which I discussed in "Character and Integer
Directives," when used with no base specified, prints numbers as English
words or Roman numerals.  When used with no prefix parameter and no
modifiers, it emits the number in words as a cardinal number.

   (format nil "~r" 1234) ==> "one thousand two hundred thirty-four"
With the colon modifier, it emits the number as an ordinal.

   (format nil "~:r" 1234) ==> "one thousand two hundred thirty-fourth"
And with an at-sign modifier, it emits the number as a Roman numeral;
with both an at-sign and a colon, it emits "old-style" Roman numerals in
which fours and nines are written as IIII and VIIII instead of IV and
IX.

   (format nil "~@r" 1234) ==> "MCCXXXIV" (format nil "~:@r" 1234) ==>
"MCCXXXIIII" For numbers too large to be represented in the given form,
~R behaves like ~D.

   To help you generate messages with words properly pluralized, FORMAT
provides the ~P directive, which simply emits an s unless the
corresponding argument is 1.

   (format nil "file~p" 1) ==> "file" (format nil "file~p" 10) ==>
"files" (format nil "file~p" 0) ==> "files" Typically, however, you'll
use ~P with the colon modifier, which causes it to reprocess the
previous format argument.

   (format nil "~r file~:p" 1) ==> "one file" (format nil "~r file~:p"
10) ==> "ten files" (format nil "~r file~:p" 0) ==> "zero files" With
the at-sign modifier, which can be combined with the colon modifier, ~P
emits either y or ies.

   (format nil "~r famil~:@p" 1) ==> "one family" (format nil "~r
famil~:@p" 10) ==> "ten families" (format nil "~r famil~:@p" 0) ==>
"zero families" Obviously, ~P can't solve all pluralization problems and
is no help for generating messages in other languages, but it's handy
for the cases it does handle.  And the ~[ directive, which I'll discuss
in a moment, gives you a more flexible way to conditionalize parts of
FORMAT's output.

   The last directive for dealing with emitting English text is ~(,
which allows you to control the case of text in the output.  Each ~( is
paired with a ~), and all the output generated by the portion of the
control string between the two markers will be converted to all
lowercase.

   (format nil "~(~a~)" "FOO") ==> "foo" (format nil "~(~@r~)" 124) ==>
"cxxiv" You can modify ~( with an at sign to make it capitalize the
first word in a section of text, with a colon to make it to capitalize
all words, and with both modifiers to convert all text to uppercase.  (A
word for the purpose of this directive is a sequence of alphanumeric
characters delimited by nonalphanumeric characters or the ends of the
text.)

   (format nil "~(~a~)" "tHe Quick BROWN foX") ==> "the quick brown fox"
(format nil "~@(~a~)" "tHe Quick BROWN foX") ==> "The quick brown fox"
(format nil "~:(~a~)" "tHe Quick BROWN foX") ==> "The Quick Brown Fox"
(format nil "~:@(~a~)" "tHe Quick BROWN foX") ==> "THE QUICK BROWN FOX"


File: pcl.info,  Node: 18-7,  Next: 18-8,  Prev: 18-6,  Up: Chapter 18

Conditional Formatting
======================

In addition to directives that interpolate arguments and modify other
output, FORMAT provides several directives that implement simple control
constructs within the control string.  One of these, which you used in
Chapter 9, is the conditional directive ~[.  This directive is closed by
a corresponding ~], and in between are a number of clauses separated by
~;.  The job of the ~[ directive is to pick one of the clauses, which is
then processed by FORMAT. With no modifiers or parameters, the clause is
selected by numeric index; the ~[ directive consumes a format argument,
which should be a number, and takes the nth (zero-based) clause where N
is the value of the argument.

   (format nil "~[cero~;uno~;dos~]" 0) ==> "cero" (format nil
"~[cero~;uno~;dos~]" 1) ==> "uno" (format nil "~[cero~;uno~;dos~]" 2)
==> "dos" If the value of the argument is greater than the number of
clauses, nothing is printed.

   (format nil "~[cero~;uno~;dos~]" 3) ==> "" However, if the last
clause separator is ~:; instead of ~;, then the last clause serves as a
default clause.

   (format nil "~[cero~;uno~;dos~:;mucho~]" 3) ==> "mucho" (format nil
"~[cero~;uno~;dos~:;mucho~]" 100) ==> "mucho" It's also possible to
specify the clause to be selected using a prefix parameter.  While it'd
be silly to use a literal value in the control string, recall that #
used as a prefix parameter means the number of arguments remaining to be
processed.  Thus, you can define a format string such as the following:

   (defparameter *list-etc* "~#[NONE~;~a~;~a and ~a~:;~a, ~a~]~#[~; and
~a~:;, ~a, etc~].")  and then use it like this:

   (format nil *list-etc*) ==> "NONE." (format nil *list-etc* 'a) ==>
"A." (format nil *list-etc* 'a 'b) ==> "A and B." (format nil *list-etc*
'a 'b 'c) ==> "A, B and C." (format nil *list-etc* 'a 'b 'c 'd) ==> "A,
B, C, etc."  (format nil *list-etc* 'a 'b 'c 'd 'e) ==> "A, B, C, etc."
Note that the control string actually contains two ~[~] directives-both
of which use # to select the clause to use.  The first consumes between
zero and two arguments, while the second consumes one more, if
available.  FORMAT will silently ignore any arguments not consumed while
processing the control string.

   With a colon modifier, the ~[ can contain only two clauses; the
directive consumes a single argument and processes the first clause if
the argument is NIL and the second clause is otherwise.  You used this
variant of ~[ in Chapter 9 to generate pass/fail messages, like this:

   (format t "~:[FAIL~;pass~]" test-result) Note that either clause can
be empty, but the directive must contain a ~;.

   Finally, with an at-sign modifier, the ~[ directive can have only one
clause.  The directive consumes one argument and, if it's non-NIL,
processes the clause after backing up to make the argument available to
be consumed again.

   (format nil "~@[x = ~a ~]~@[y = ~a~]" 10 20) ==> "x = 10 y = 20"
(format nil "~@[x = ~a ~]~@[y = ~a~]" 10 nil) ==> "x = 10 " (format nil
"~@[x = ~a ~]~@[y = ~a~]" nil 20) ==> "y = 20" (format nil "~@[x = ~a
~]~@[y = ~a~]" nil nil) ==> ""


File: pcl.info,  Node: 18-8,  Next: 18-9,  Prev: 18-7,  Up: Chapter 18

Iteration
=========

Another FORMAT directive that you've seen already, in passing, is the
iteration directive ~{.  This directive tells FORMAT to iterate over the
elements of a list or over the implicit list of the format arguments.

   With no modifiers, ~{ consumes one format argument, which must be a
list.  Like the ~[ directive, which is always paired with a ~]
directive, the ~{ directive is always paired with a closing ~}.  The
text between the two markers is processed as a control string, which
draws its arguments from the list consumed by the ~{ directive.  FORMAT
will repeatedly process this control string for as long as the list
being iterated over has elements left.  In the following example, the ~{
consumes the single format argument, the list (1 2 3), and then
processes the control string "~a, ", repeating until all the elements of
the list have been consumed.

   (format nil "~{~a, ~}" (list 1 2 3)) ==> "1, 2, 3, " However, it's
annoying that in the output the last element of the list is followed by
a comma and a space.  You can fix that with the ~^ directive; within the
body of a ~{ directive, the ~^ causes the iteration to stop immediately,
without processing the rest of the control string, when no elements
remain in the list.  Thus, to avoid printing the comma and space after
the last element of a list, you can precede them with a ~^.

   (format nil "~{~a~^, ~}" (list 1 2 3)) ==> "1, 2, 3" The first two
times through the iteration, there are still unprocessed elements in the
list when the ~^ is processed.  The third time through, however, after
the ~a directive consumes the 3, the ~^ will cause FORMAT to break out
of the iteration without printing the comma and space.

   With an at-sign modifier, ~{ processes the remaining format arguments
as a list.

   (format nil "~@{~a~^, ~}" 1 2 3) ==> "1, 2, 3" Within the body of a
~{...~}, the special prefix parameter # refers to the number of items
remaining to be processed in the list rather than the number of
remaining format arguments.  You can use that, along with the ~[
directive, to print a comma-separated list with an "and" before the last
item like this:

   (format nil "~{~a~#[~;, and ~:;, ~]~}" (list 1 2 3)) ==> "1, 2, and
3" However, that doesn't really work right if the list is two items long
because it adds an extra comma.

   (format nil "~{~a~#[~;, and ~:;, ~]~}" (list 1 2)) ==> "1, and 2" You
could fix that in a bunch of ways.  The following takes advantage of the
behavior of ~@{ when nested inside another ~{ or ~@{ directive-it
iterates over whatever items remain in the list being iterated over by
the outer ~{.  You can combine that with a ~#[ directive to make the
following control string for formatting lists according to English
grammar:

   (defparameter *english-list* "~{~#[~;~a~;~a and ~a~:;~@{~a~#[~;, and
~:;, ~]~}~]~}")

   (format nil *english-list* '()) ==> "" (format nil *english-list*
'(1)) ==> "1" (format nil *english-list* '(1 2)) ==> "1 and 2" (format
nil *english-list* '(1 2 3)) ==> "1, 2, and 3" (format nil
*english-list* '(1 2 3 4)) ==> "1, 2, 3, and 4" While that control
string verges on being "write-only" code, it's not too hard to
understand if you take it a bit at a time.  The outer ~{...~} will
consume and iterate over a list.  The whole body of the iteration then
consists of a ~#[...~]; the output generated each time through the
iteration will thus depend on the number of items left to be processed
from the list.  Splitting apart the ~#[...~] directive on the ~; clause
separators, you can see that it's made up of four clauses, the last of
which is a default clause because it's preceded by a ~:; rather than a
plain ~;.  The first clause, for when there are zero elements to be
processed, is empty, which makes sense-if there are no more elements to
be processed, the iteration would've stopped already.  The second clause
handles the case of one element with a simple ~a directive.  Two
elements are handled with "~a and ~a".  And the default clause, which
handles three or more elements, consists of another iteration directive,
this time using ~@{ to iterate over the remaining elements of the list
being processed by the outer ~{.  And the body of that iteration is the
control string that can handle a list of three or more elements
correctly, which is fine in this context.  Because the ~@{ loop consumes
all the remaining list items, the outer loop iterates only once.

   If you wanted to print something special such as "<empty>" when the
list was empty, you have a couple ways to do it.  Perhaps the easiest is
to put the text you want into the first (zeroth) clause of the outer ~#[
and then add a colon modifier to the closing ~} of the outer
iteration-the colon forces the iteration to be run at least once, even
if the list is empty, at which point FORMAT processes the zeroth clause
of the conditional directive.

   (defparameter *english-list* "~{~#[<empty>~;~a~;~a and
~a~:;~@{~a~#[~;, and ~:;, ~]~}~]~:}")

   (format nil *english-list* '()) ==> "<empty>" Amazingly, the ~{
directive provides even more variations with different combinations of
prefix parameters and modifiers.  I won't discuss them other than to say
you can use an integer prefix parameter to limit the maximum number of
iterations and that, with a colon modifier, each element of the list
(either an actual list or the list constructed by the ~@{ directive)
must itself be a list whose elements will then be used as arguments to
the control string in the ~:{...~} directive.

